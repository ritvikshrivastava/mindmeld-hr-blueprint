{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Functions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>General Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a Value is Nan\n",
    "# param x - Value to check\n",
    "# return boolean - If it is a Nan\n",
    "def is_nan(x):\n",
    "    return (x is np.nan or x != x)\n",
    "\n",
    "# Check All Values in List are Nan\n",
    "# param x - List to check\n",
    "# return boolean - If it is all Nan\n",
    "def list_is_nan(x):\n",
    "    for i in x:\n",
    "        if not is_nan(i): return False\n",
    "    return True\n",
    "\n",
    "# Converts names to single string\n",
    "# param names (list) - List of names in the format [['Mia', 'Brown'],[..]]\n",
    "# return unique (list) - List of names in the format ['Mia Brown', ..]\n",
    "def name_to_str(names):\n",
    "    return [\",\".join(name).replace(\",\", \" \") for name in names]\n",
    "\n",
    "# Converts names to single string\n",
    "# param names (list) - List of names in the format ['Mia Brown', ..]\n",
    "# return names_list (list) - List of names in the format [['Mia', 'Brown'],[..]]\n",
    "def str_name_to_list(names):\n",
    "    for i in range(len(names)):\n",
    "        full_name = names[i].split()\n",
    "        names[i] = [full_name[0], full_name[len(full_name) - 1]]\n",
    "    return names\n",
    "\n",
    "# Extracts All of the Elements in a List of (One or Two D) Lists\n",
    "# param two_d_list (list) List of (One or Two D) Lists\n",
    "# return new_elems (list) List of elements\n",
    "def extract_2d_list(two_d_list):\n",
    "    elems, new_elems = [], []\n",
    "    for elem in two_d_list: elems.extend(elem)\n",
    "    for elem in elems:\n",
    "        if isinstance(elem, list): new_elems.extend(elem)\n",
    "        else: new_elems.append(elem)\n",
    "    return new_elems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get Unique Values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Names of Employees in the HR Dataset\n",
    "# param df (dataframe) - Dataframe with names\n",
    "# param column (str) - Column can be 'Employee Name' or 'Manager Name'\n",
    "# Returns names (list) - Array of names (['First', 'Last'])\n",
    "def get_names(df, column='Employee Name'):\n",
    "    names = [df[[column]].iloc[i][0] for i in range(df.shape[0] - 1)]\n",
    "    for i in range(len(names)):\n",
    "        try:\n",
    "            full_name = names[i].split(',')\n",
    "            first = full_name[1].strip().split()[0]\n",
    "            last = full_name[0]\n",
    "            names[i] = [first, last]\n",
    "        except:\n",
    "            names[i] = ['Jeremy', 'Prater']\n",
    "    return names\n",
    "\n",
    "# Filter to list of unique names\n",
    "# param names (list) - List of names in the format [['Mia', 'Brown'],[..]]\n",
    "# param avoid (list) - List of names to avoid duplicates of\n",
    "# return unique (list) - List of names in the format [['Mia', 'Brown'],[..]]\n",
    "def filter_names_helper(names, avoid = []):\n",
    "    unique = []\n",
    "    first, last = [], []\n",
    "    if(len(avoid) != 0):\n",
    "        first = [n[0] for n in avoid]\n",
    "        last = [n[1] for n in avoid]\n",
    "    for name in names:\n",
    "        if((name[0] not in first) and (name[1] not in last)):\n",
    "            first.append(name[0])\n",
    "            last.append(name[1])\n",
    "            unique.append(name)\n",
    "    return unique\n",
    "\n",
    "# Filter to list of unique names that don't overlap with manager names\n",
    "# param df (dataframe) - Dataframe with names \n",
    "# return unique (list) - List of names in the format [['Mia', 'Brown'],[..]]\n",
    "def get_filtered_names(df):\n",
    "    managers = str_name_to_list(get_uniq_str(df, \"Manager Name\"))\n",
    "    managers = filter_names_helper(managers)\n",
    "    survey_users = [['Mia','Brown'], ['Ivan','Rogers'], ['Julia','Soto'], ['Nan','Singh']]\n",
    "    user_names = get_names(hr_data)\n",
    "    user_names = filter_names_helper(user_names, avoid=survey_users)\n",
    "    user_names = filter_names_helper(user_names, avoid=managers)\n",
    "    user_names.extend(survey_users)\n",
    "    return user_names\n",
    "\n",
    "# Update Name Synonyms\n",
    "def name_syn_update(ent_dict):\n",
    "    syn_names = []\n",
    "    for name in ent_dict['name'][0]:\n",
    "        name_splt = name.split()\n",
    "        name_syn = [name.lower(), name_splt[0], name_splt[0].lower(),\n",
    "                    name_splt[1], name_splt[1].lower()]\n",
    "        syn_names.append(name_syn)\n",
    "    return syn_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Unique Names of Employees in the HR Dataset\n",
    "# param df (dataframe) - Dataframe with names\n",
    "# return unique (list) - List of names in the format ['Mia Brown', ..]\n",
    "def get_uniq_names(df):\n",
    "    return filter_names(get_names(df))\n",
    "\n",
    "# Get Unique String Values of a Dataframe Column\n",
    "# param df (dataframe) - Source Dataframe\n",
    "# param col_name (str) - Name of Column to get unique values'\n",
    "# return uniq_arr (arr) - Array of Unique Values\n",
    "def get_uniq_str(df, col_name):\n",
    "    return [i.lower().strip() for i in df[col_name].unique()[:-1]]\n",
    "\n",
    "# Get Unique String Values of a Dataframe Column\n",
    "# param df (dataframe) - Source Dataframe\n",
    "# param col_name (str) - Name of Column to get unique values'\n",
    "# return uniq_arr (arr) - Array of Unique Values\n",
    "def get_uniq_num(df, col_name):\n",
    "    return [str(int(i)) for i in df[col_name].unique()[:-1]]\n",
    "\n",
    "# Generate a Dictionary with Unique Values for Select Columns\n",
    "# param df (dataframe) - Source Dataframe\n",
    "# return uniq (dict) - Dictionary that maps entities to unique values\n",
    "def gen_uniq_dict(df):\n",
    "    # Get Unique Values of Relevant Columns\n",
    "    uniq = {}\n",
    "    # Predefined\n",
    "    uniq['name'] = name_to_str(get_filtered_names(df))\n",
    "    uniq['sex'] = ['male', 'female']\n",
    "    uniq['employment_status'] = ['active', 'voluntarily terminated', 'terminated for a cause',\n",
    "                          'on a leave of absence' + 'going to start work in the future']\n",
    "    uniq['performance_score'] = ['fully meet performance expecations', 'are too early to review', \n",
    "                         'meet 90-day expectations', 'are exceptional', 'need improvement', 'exeed expecations']\n",
    "    # Custom Preprocessing\n",
    "    uniq['state'] = hr_data['State'].unique()[:-1]\n",
    "    # Standard Preprocessing \n",
    "    uniq['age'] = get_uniq_num(hr_data, 'Age')\n",
    "    uniq['maritaldesc'] = get_uniq_str(hr_data, \"MaritalDesc\")\n",
    "    uniq['citizendesc'] = get_uniq_str(hr_data, \"CitizenDesc\")\n",
    "    uniq['racedesc'] = get_uniq_str(hr_data, \"RaceDesc\")\n",
    "    uniq['department'] = get_uniq_str(hr_data, \"Department\")\n",
    "    uniq['position'] = get_uniq_str(hr_data, \"Position\")\n",
    "    #uniq['manager'] = name_to_str(str_name_to_list(get_uniq_str(hr_data, \"Manager Name\")))\n",
    "    uniq['employee_source'] = get_uniq_str(hr_data, \"Employee Source\")\n",
    "    return uniq\n",
    "\n",
    "# Generate a Dictionary with Unique Values for Select Columns\n",
    "# param uniq (dict) - Dictionary that maps entities to unique values\n",
    "# param ent_dict (dict) - Dictionary that Contains Entity Information\n",
    "# return uniq (dict) - Dictionary that maps entities to unique values\n",
    "def uniq_dict_update(uniq, ent_dict):\n",
    "    uniq['money'] = ent_dict['money'][1][0]\n",
    "    uniq['time_interval'] = extract_2d_list(ent_dict['time_interval'])\n",
    "    uniq['time_recur'] = extract_2d_list(ent_dict['time_recur'])\n",
    "    uniq['function'] = extract_2d_list(ent_dict['function'])\n",
    "    uniq['extreme'] = extract_2d_list(ent_dict['extreme'])\n",
    "    uniq['employment_action'] = extract_2d_list(ent_dict['employment_action'])\n",
    "    uniq['date_compare'] = extract_2d_list(ent_dict['date_compare'])\n",
    "    uniq['manager'] = extract_2d_list(ent_dict['manager'])\n",
    "    return uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_2d_list(ent_dict['manager'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load, Parse and Clean Entity Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load entity data frame from CSV\n",
    "# param path (str) - Path to csv\n",
    "# return ent_df (dataframe) - Entity Info Dataframe\n",
    "def load_ent(path):\n",
    "    df = pd.read_csv(path).iloc[:, :4]\n",
    "    ct = 0\n",
    "    while (ct < len(df) and not list_is_nan(df.iloc[ct, :].values)): ct += 1\n",
    "    return df.iloc[:ct, :]\n",
    "\n",
    "# Parse CSV that contains [Entity, Options, Synonyms, Gazetteer]\n",
    "# param ent_df (dataframe) - Contains the columns listed above\n",
    "# return ent_dict (dict) - Uncleaned dictionary where the keys are the entities\n",
    "#                          and the values are [options (arr), synonyms (arr), gazetteer (arr)]\n",
    "def ent_parse(ent_df):\n",
    "    ent_dict = {}\n",
    "    ct = 0\n",
    "    curr_ent = ''\n",
    "    while(ct < len(ent_df)):\n",
    "        row = ent_df.iloc[ct]\n",
    "        # update curr_ent if new entity\n",
    "        if(not is_nan(row['Entity'])): \n",
    "            curr_ent = row['Entity']\n",
    "            ent_dict[curr_ent] = [[], [], []]\n",
    "        # check if options is a list\n",
    "        if(not is_nan(row['Options']) and row['Options'].count(',') > 2):\n",
    "            ent_dict[curr_ent][0] = row['Options']\n",
    "            if(not is_nan(row['Synonyms'])): \n",
    "                ent_dict[curr_ent][1] = row['Synonyms'].split(',')\n",
    "            if(not is_nan(row[3])): ent_dict[curr_ent][2] = row['Gazetteer']\n",
    "        # single entry in option column\n",
    "        else:\n",
    "            ent_dict[curr_ent][0].append(row['Options'])\n",
    "            ent_dict[curr_ent][1].append(row['Synonyms'])\n",
    "            ent_dict[curr_ent][2].append(row['Gazetteer'])\n",
    "        ct += 1\n",
    "    return ent_dict\n",
    "\n",
    "# Cleans the gazetteers of the ent dictionary\n",
    "# param ent_dict (dictionary) - Entity Dictionary\n",
    "# return ent_dict (dictionary) - Cleaned Entity Dictionary\n",
    "def clean_options(ent_dict):\n",
    "    for i in ent_dict.keys():\n",
    "        old_opt = ent_dict[i][0]\n",
    "        new_opt = []\n",
    "        for word in old_opt:\n",
    "            if(not is_nan(word)):\n",
    "                new_opt.append(word.replace(\"'\", \"\").replace(\",\", \"\"))\n",
    "        ent_dict[i][0] = new_opt\n",
    "    return ent_dict\n",
    "\n",
    "# Cleans the gazetteers of the ent dictionary\n",
    "# param ent_dict (dictionary) - Entity Dictionary\n",
    "# return ent_dict (dictionary) - Cleaned Entity Dictionary\n",
    "def clean_synonyms(ent_dict):\n",
    "    for i in ent_dict.keys():\n",
    "        old_syn = ent_dict[i][1]\n",
    "        new_syn = []\n",
    "        if(len(old_syn) != 0):\n",
    "            for j in old_syn:\n",
    "                if(not is_nan(j)): new_syn.append([string.strip() for string in j.split(',')])\n",
    "                else: new_syn.append(j)\n",
    "        ent_dict[i][1] = new_syn\n",
    "    return ent_dict\n",
    "\n",
    "# Cleans the gazetteers of the ent dictionary\n",
    "# param ent_dict (dictionary) - Entity Dictionary\n",
    "# return ent_dict (dictionary) - Cleaned Entity Dictionary\n",
    "def clean_gazetteer(ent_dict):\n",
    "    for i in ent_dict.keys():\n",
    "        old_gaz = ent_dict[i][2]\n",
    "        clean_gaz = []\n",
    "        if (len(old_gaz) != 0):        \n",
    "            if (type(old_gaz) is str): clean_gaz = old_gaz.split(',')\n",
    "            elif(not is_nan(old_gaz[0])): clean_gaz = (old_gaz[0].split(','))\n",
    "        ent_dict[i][2] = [i.strip() for i in clean_gaz]\n",
    "    return ent_dict\n",
    "\n",
    "# Cleans an Entity Dictionary\n",
    "# ent_dict (dict) - Uncleaned dictionary of parsed entity information\n",
    "# uniq (dict) - Dictionary that maps entities to unique values\n",
    "# return cleaned_ent_dict (dict) - Cleaned dictionary\n",
    "def clean_ent_dict(ent_dict, uniq):\n",
    "    ent_dict = clean_options(ent_dict)\n",
    "    ent_dict = clean_synonyms(ent_dict)\n",
    "    ent_dict = clean_gazetteer(ent_dict)\n",
    "    ent_dict['name'][0] = uniq['name']\n",
    "    ent_dict['state'][0] = uniq['state']\n",
    "    ent_dict['age'][0] = uniq['age']\n",
    "    return ent_dict\n",
    "\n",
    "# Parse and Clean Entity Data\n",
    "# Parse CSV that contains [Entity, Options, Synonyms, Gazetteer]\n",
    "# param ent_df (dataframe) - Contains the columns listed above\n",
    "def parse_clean_ent(ent_df, uniq):\n",
    "    ent = ent_parse(ent_df)\n",
    "    return clean_ent_dict(ent, uniq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>File Generation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a list into a text file\n",
    "# param folder (str) - Name of the folder to write the file\n",
    "# param lines (list) - List of values to write to file\n",
    "def list_to_txt_file(folder, lines):\n",
    "    directory = 'hr_assistant/entities/' + folder + '/'\n",
    "    if not os.path.exists(directory): os.makedirs(directory)\n",
    "    with open(directory + 'gazetteer.txt', 'w+') as filehandle:  \n",
    "        filehandle.writelines(\"%s\\n\" % line for line in lines)\n",
    "        \n",
    "# Convert a dict into a json file\n",
    "# param folder (str) - Name of the folder to write the file\n",
    "# param dict (dict) - Json dict to write to file\n",
    "def dict_to_json_file(folder, json_dict):\n",
    "    directory = 'hr_assistant/entities/' + folder + '/'\n",
    "    if not os.path.exists(directory): os.makedirs(directory)\n",
    "    with open(directory + \"mapping.json\", \"w+\") as f:\n",
    "        json_str = json.dumps(json_dict, indent=4)\n",
    "        f.write(json_str)\n",
    "        \n",
    "# Generate a Mapping JSON Dict to create Mapping.json file\n",
    "# param ent_dict (dict) - Dictionary that maps entities to options, synonyms, and gazetteer\n",
    "# param entity (str) - The entity to generate the gazetteer list for\n",
    "# return json_dict (dict) - Json Dict in the proper format for mapping.json\n",
    "def gen_map_json(ent_dict, entity):\n",
    "    opt = ent_dict[entity][0]\n",
    "    syn = ent_dict[entity][1]\n",
    "    # Check if the Options and the Synonyms Align\n",
    "    if(len(opt) != len(syn)): syn = [[] for i in range(len(opt))]\n",
    "    return gen_map_json_helper(opt, syn)\n",
    "\n",
    "# Helper function to Generate a Mapping JSON Dictionary\n",
    "# param options (list) - Array of options\n",
    "# param synonyms (2d list) - Array of synonym arrays corresponding to options\n",
    "# return json_dict (dict) - Json Dict in the proper format for mapping.json\n",
    "def gen_map_json_helper(options, synonyms):\n",
    "    json_dict = {}\n",
    "    json_dict['entities'] = []\n",
    "    for i in range(len(options)):\n",
    "        new_dict = {}\n",
    "        if(is_nan(synonyms[i])): new_dict['whitelist'] = []\n",
    "        else: new_dict['whitelist'] = synonyms[i]\n",
    "        new_dict['cname'] = options[i]\n",
    "        json_dict['entities'].append(new_dict)\n",
    "    return json_dict\n",
    "\n",
    "# Create Mapping.json files for Every Entity in an Entity Dictionary\n",
    "# param ent_dict (dict) - Dictionary that maps entities to options, synonyms, and gazetteer\n",
    "def gen_map_json_files(ent_dict):\n",
    "    for entity in ent_dict.keys():\n",
    "        json_dict = gen_map_json(ent_dict, entity)\n",
    "        if(not is_nan(json_dict)): dict_to_json_file(entity, json_dict)\n",
    "\n",
    "# Collect All Synonyms for a Single Entity in Entity Dict\n",
    "# param ent_dict (dict) - Dictionary that maps entities to options, synonyms, and gazetteer\n",
    "# param entity (str) - The entity to get Synyonyms for\n",
    "# return synonyms (list) - List of Synonyms of Specified entity\n",
    "def get_synonyms(ent_dict, entity):\n",
    "    synonyms = []\n",
    "    for syn in ent_dict[entity][1]:\n",
    "        if(not is_nan(syn)): synonyms.extend(syn)\n",
    "    return synonyms\n",
    "\n",
    "# Generate a Gazetter List for an Entity\n",
    "# param ent_dict (dict) - Dictionary that maps entities to options, synonyms, and gazetteer\n",
    "# param entity (str) - The entity to generate the gazetteer list for\n",
    "# return gaz (list) - List of gazetteer word relevant to the entity\n",
    "def gen_gaz_list(ent_dict, entity):\n",
    "    gaz = []\n",
    "    gaz.extend(ent_dict[entity][0])\n",
    "    gaz.extend(get_synonyms(ent_dict, entity))\n",
    "    gaz.extend(ent_dict[entity][2])\n",
    "    return gaz\n",
    "\n",
    "# Create Gazetteer Files for Every Entity in an Entity Dictionary\n",
    "# param ent_dict (dict) - Dictionary that maps entities to options, synonyms, and gazetteer\n",
    "def gen_gazetteers(ent_dict):\n",
    "    for entity in ent_dict.keys():\n",
    "        gaz_list = gen_gaz_list(ent_dict, entity)\n",
    "        list_to_txt_file(entity, gaz_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Debug Labelling</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all labels in a sentence\n",
    "# pram text (str) String that may or may not contain labels in the form of {ent_type|ent}\n",
    "# return labels (list) List of labels found in the text\n",
    "def get_labels(text):\n",
    "    chars = list(text)\n",
    "    start, stop = 0, 0\n",
    "    labels = []\n",
    "    positions = []\n",
    "    for i in range(len(chars)):\n",
    "        if chars[i] == '{': \n",
    "            start = i\n",
    "        if chars[i] == '}':\n",
    "            stop = i\n",
    "            txt = chars[start:(stop + 1)]\n",
    "            labels.append(\"\".join(chars[start:(stop + 1)]))\n",
    "            positions.append([start, stop])\n",
    "    return labels, positions\n",
    "\n",
    "# Given a list of labels, Seperate Key and Values\n",
    "# param labels (list) List of labels found in the text\n",
    "# return kv (2d list) List of the Keys list and Values list [[key_array], [value_array]]\n",
    "def get_kv(labels):\n",
    "    k = []\n",
    "    v = []\n",
    "    for label in labels:\n",
    "        if '|' in label:\n",
    "            k.append(label.split('|')[0].replace(\"{\", \"\"))\n",
    "            v.append(label.split('|')[1].replace(\"}\", \"\"))\n",
    "    return [k,v]\n",
    "\n",
    "# Check if a Synonym Exists in a Sentence that it is labelled\n",
    "# param sentence (str) String that may or may not contain labels in the form of {ent_type|ent}\n",
    "# param ent_dict (dict) - Dictionary that maps entities to options, synonyms, and gazetteer\n",
    "# param kv_labels (2d list) List of the Keys list and Values list [[key_array], [value_array]]\n",
    "# param col (str) Column in the dataframe\n",
    "# param idx (int) Index of the Current Sentence in the Dataframe\n",
    "def label_chk_helper(sentence, ent_dict, kv_labels, col, idx):\n",
    "    sent_split = [word.lower() for word in sentence.split()]\n",
    "    for ent in ent_dict:\n",
    "        # Check for 'Entity Options' in text\n",
    "        options = ent_dict[ent][0]\n",
    "        for opt in options:\n",
    "            if opt in sent_split and opt not in kv_labels[0] and opt not in kv_labels[1]:\n",
    "                print(\"POTENTIAL OPTION-MISSING LABEL\")\n",
    "                print(\"OPTION: \" + opt)\n",
    "                print(\"ENTITY: \" + ent)\n",
    "                print(\"SENTENCE: \" + sentence)\n",
    "                print(\"Column: \" + col)\n",
    "                print(\"Index: \" + str(idx + 2))\n",
    "                print(\"==========================================\")\n",
    "        # Check for 'Synonym Options' in text\n",
    "        syns = get_synonyms(ent_dict, ent)\n",
    "        for syn in syns:\n",
    "            if syn.lower() in sent_split and syn not in kv_labels[0]:\n",
    "                print(\"POTENTIAL SYNONYM-MISSING LABEL\")\n",
    "                print(\"SYNONYM: \" + syn)\n",
    "                print(\"ENTITY: \" + ent)\n",
    "                print(\"SENTENCE: \" + sentence)\n",
    "                print(\"Column: \" + col)\n",
    "                print(\"Index: \" + str(idx + 2))\n",
    "                print(\"==========================================\")\n",
    "                \n",
    "# Finds mismatches between labels in the Dataframe\n",
    "# param kv_labels (2d list) List of the Keys list and Values list [[key_array], [value_array]]\n",
    "# param sentence (str) String that may or may not contain labels in the form of {ent_type|ent}\n",
    "# param l_dict (dict) Dictionary that keeps track of entity label mappings passed in from the main function\n",
    "# param col (str) Column in the dataframe\n",
    "# param idx (int) Index of the Current Sentence in the Dataframe\n",
    "def chk_mismatch(labels, sentence, l_dict, col, idx):\n",
    "    if(len(labels[0]) != 0):\n",
    "        for ct in range(len(labels[0])):\n",
    "            k = labels[0][ct]\n",
    "            v = labels[1][ct]\n",
    "            \n",
    "            if k in l_dict: \n",
    "                if l_dict[k] != v:\n",
    "                    print(\"POTENTIAL MISMATCH for: \" + k)\n",
    "                    print(\"CURRENT LABEL: \" + v)\n",
    "                    print(\"IN DICT: \" + l_dict[k])\n",
    "                    print(\"SENTENCE: \" + sentence)\n",
    "                    print(\"Column: \" + col)\n",
    "                    print(\"Index: \" + str(idx + 2))\n",
    "                    print(\"==========================================\")\n",
    "            else: l_dict[k] = v  \n",
    "\n",
    "# Check if the Synonyms to Entities Were not Labelled in Training\n",
    "# param df (dataframe) - Dataframe where each column is an intent and each row has sentence examples\n",
    "# param ent_dict (dict) - Dictionary that contains entities as keys and synonyms\n",
    "def label_chk(df, ent_dict):\n",
    "    for col in df:\n",
    "        print(col.upper() + \"=============================================================\")\n",
    "        idx = 2\n",
    "        nan = is_nan(df[col][idx])\n",
    "        l_dict = {}\n",
    "        while(idx < len(df)):\n",
    "            if(is_nan(df[col][idx])): break\n",
    "            sentence = df[col][idx]\n",
    "            labels, pos = get_labels(sentence)\n",
    "            labels = get_kv(labels)\n",
    "            label_chk_helper(sentence, ent_dict, labels, col, idx)\n",
    "            chk_mismatch(labels, sentence, l_dict, col, idx)\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Workflow</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Load Data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee Name</th>\n",
       "      <th>Employee Number</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>MaritalDesc</th>\n",
       "      <th>CitizenDesc</th>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <th>...</th>\n",
       "      <th>Date of Hire</th>\n",
       "      <th>Date of Termination</th>\n",
       "      <th>Reason For Term</th>\n",
       "      <th>Employment Status</th>\n",
       "      <th>Department</th>\n",
       "      <th>Position</th>\n",
       "      <th>Pay Rate</th>\n",
       "      <th>Manager Name</th>\n",
       "      <th>Employee Source</th>\n",
       "      <th>Performance Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brown, Mia</td>\n",
       "      <td>1.103024e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>11/24/1985</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>10/27/2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Admin Offices</td>\n",
       "      <td>Accountant I</td>\n",
       "      <td>28.50</td>\n",
       "      <td>Brandon R. LeBlanc</td>\n",
       "      <td>Diversity Job Fair</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LaRotonda, William</td>\n",
       "      <td>1.106027e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>4/26/1984</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1/6/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Admin Offices</td>\n",
       "      <td>Accountant I</td>\n",
       "      <td>23.00</td>\n",
       "      <td>Brandon R. LeBlanc</td>\n",
       "      <td>Website Banner Ads</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steans, Tyrone</td>\n",
       "      <td>1.302053e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2703.0</td>\n",
       "      <td>9/1/1986</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>9/29/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Admin Offices</td>\n",
       "      <td>Accountant I</td>\n",
       "      <td>29.00</td>\n",
       "      <td>Brandon R. LeBlanc</td>\n",
       "      <td>Internet Search</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Howard, Estelle</td>\n",
       "      <td>1.211051e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>9/16/1985</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>2/16/2015</td>\n",
       "      <td>4/15/2015</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Admin Offices</td>\n",
       "      <td>Administrative Assistant</td>\n",
       "      <td>21.50</td>\n",
       "      <td>Brandon R. LeBlanc</td>\n",
       "      <td>Pay Per Click - Google</td>\n",
       "      <td>N/A- too early to review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Singh, Nan</td>\n",
       "      <td>1.307060e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2330.0</td>\n",
       "      <td>5/19/1988</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>5/1/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Admin Offices</td>\n",
       "      <td>Administrative Assistant</td>\n",
       "      <td>16.56</td>\n",
       "      <td>Brandon R. LeBlanc</td>\n",
       "      <td>Website Banner Ads</td>\n",
       "      <td>N/A- too early to review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Smith, Leigh Ann</td>\n",
       "      <td>7.110077e+08</td>\n",
       "      <td>MA</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>6/14/1987</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>9/26/2011</td>\n",
       "      <td>9/25/2013</td>\n",
       "      <td>career change</td>\n",
       "      <td>Voluntarily Terminated</td>\n",
       "      <td>Admin Offices</td>\n",
       "      <td>Administrative Assistant</td>\n",
       "      <td>20.50</td>\n",
       "      <td>Brandon R. LeBlanc</td>\n",
       "      <td>Diversity Job Fair</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LeBlanc, Brandon  R</td>\n",
       "      <td>1.102024e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>6/10/1984</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1/5/2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Admin Offices</td>\n",
       "      <td>Shared Services Manager</td>\n",
       "      <td>55.00</td>\n",
       "      <td>Janet King</td>\n",
       "      <td>Monster.com</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Quinn, Sean</td>\n",
       "      <td>1.206043e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2045.0</td>\n",
       "      <td>11/6/1984</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>Eligible NonCitizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>2/21/2011</td>\n",
       "      <td>8/15/2015</td>\n",
       "      <td>career change</td>\n",
       "      <td>Voluntarily Terminated</td>\n",
       "      <td>Admin Offices</td>\n",
       "      <td>Shared Services Manager</td>\n",
       "      <td>55.00</td>\n",
       "      <td>Janet King</td>\n",
       "      <td>Diversity Job Fair</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Boutwell, Bonalyn</td>\n",
       "      <td>1.307060e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2468.0</td>\n",
       "      <td>4/4/1987</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>2/16/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Admin Offices</td>\n",
       "      <td>Sr. Accountant</td>\n",
       "      <td>34.95</td>\n",
       "      <td>Brandon R. LeBlanc</td>\n",
       "      <td>Diversity Job Fair</td>\n",
       "      <td>90-day meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Foster-Baker, Amy</td>\n",
       "      <td>1.201031e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>4/16/1979</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>1/5/2009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Admin Offices</td>\n",
       "      <td>Sr. Accountant</td>\n",
       "      <td>34.95</td>\n",
       "      <td>Board of Directors</td>\n",
       "      <td>Other</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>King, Janet</td>\n",
       "      <td>1.001495e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>9/21/1954</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>7/2/2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Executive Office</td>\n",
       "      <td>President &amp; CEO</td>\n",
       "      <td>80.00</td>\n",
       "      <td>Board of Directors</td>\n",
       "      <td>Pay Per Click - Google</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Zamora, Jennifer</td>\n",
       "      <td>1.112031e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>8/30/1979</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>4/10/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>CIO</td>\n",
       "      <td>65.00</td>\n",
       "      <td>Janet King</td>\n",
       "      <td>Employee Referral</td>\n",
       "      <td>Exceptional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Becker, Renee</td>\n",
       "      <td>1.102024e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>4/4/1986</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>7/7/2014</td>\n",
       "      <td>9/12/2015</td>\n",
       "      <td>performance</td>\n",
       "      <td>Terminated for Cause</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>Database Administrator</td>\n",
       "      <td>43.00</td>\n",
       "      <td>Simon Roup</td>\n",
       "      <td>Search Engine - Google Bing Yahoo</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Goble, Taisha</td>\n",
       "      <td>9.050137e+08</td>\n",
       "      <td>MA</td>\n",
       "      <td>2127.0</td>\n",
       "      <td>10/23/1971</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>2/16/2015</td>\n",
       "      <td>3/15/2015</td>\n",
       "      <td>no-call, no-show</td>\n",
       "      <td>Terminated for Cause</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>Database Administrator</td>\n",
       "      <td>48.50</td>\n",
       "      <td>Simon Roup</td>\n",
       "      <td>Glassdoor</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hernandez, Daniff</td>\n",
       "      <td>1.410071e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>8/7/1986</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>2/16/2015</td>\n",
       "      <td>2/22/2015</td>\n",
       "      <td>no-call, no-show</td>\n",
       "      <td>Terminated for Cause</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>Database Administrator</td>\n",
       "      <td>40.10</td>\n",
       "      <td>Simon Roup</td>\n",
       "      <td>Employee Referral</td>\n",
       "      <td>N/A- too early to review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Horton, Jayne</td>\n",
       "      <td>1.105026e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2493.0</td>\n",
       "      <td>2/21/1984</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>3/30/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>Database Administrator</td>\n",
       "      <td>34.00</td>\n",
       "      <td>Simon Roup</td>\n",
       "      <td>Glassdoor</td>\n",
       "      <td>N/A- too early to review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Johnson, Noelle</td>\n",
       "      <td>1.003018e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2301.0</td>\n",
       "      <td>11/7/1986</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Leave of Absence</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>Database Administrator</td>\n",
       "      <td>40.00</td>\n",
       "      <td>Simon Roup</td>\n",
       "      <td>Glassdoor</td>\n",
       "      <td>90-day meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Murray, Thomas</td>\n",
       "      <td>1.406068e+09</td>\n",
       "      <td>TX</td>\n",
       "      <td>78230.0</td>\n",
       "      <td>7/4/1988</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>11/10/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>Database Administrator</td>\n",
       "      <td>35.50</td>\n",
       "      <td>Simon Roup</td>\n",
       "      <td>Diversity Job Fair</td>\n",
       "      <td>Exceptional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pearson, Randall</td>\n",
       "      <td>1.102024e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2747.0</td>\n",
       "      <td>9/5/1984</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>12/1/2014</td>\n",
       "      <td>5/1/2016</td>\n",
       "      <td>performance</td>\n",
       "      <td>Voluntarily Terminated</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>Database Administrator</td>\n",
       "      <td>41.00</td>\n",
       "      <td>Simon Roup</td>\n",
       "      <td>Employee Referral</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Petrowsky, Thelma</td>\n",
       "      <td>1.108028e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>9/16/1984</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>11/10/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>Database Administrator</td>\n",
       "      <td>42.75</td>\n",
       "      <td>Simon Roup</td>\n",
       "      <td>Employee Referral</td>\n",
       "      <td>Exceptional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Roby, Lori</td>\n",
       "      <td>1.407069e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>10/11/1981</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>2/16/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>Database Administrator</td>\n",
       "      <td>39.55</td>\n",
       "      <td>Simon Roup</td>\n",
       "      <td>Employee Referral</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Rogers, Ivan</td>\n",
       "      <td>1.203032e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>8/26/1986</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>3/30/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>Database Administrator</td>\n",
       "      <td>42.20</td>\n",
       "      <td>Simon Roup</td>\n",
       "      <td>Pay Per Click - Google</td>\n",
       "      <td>N/A- too early to review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Salter, Jason</td>\n",
       "      <td>1.111030e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2452.0</td>\n",
       "      <td>12/17/1987</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>10/31/2015</td>\n",
       "      <td>hours</td>\n",
       "      <td>Voluntarily Terminated</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>Database Administrator</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Simon Roup</td>\n",
       "      <td>Vendor Referral</td>\n",
       "      <td>90-day meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Simard, Kramer</td>\n",
       "      <td>8.080103e+08</td>\n",
       "      <td>MA</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>2/8/1970</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>Database Administrator</td>\n",
       "      <td>30.20</td>\n",
       "      <td>Simon Roup</td>\n",
       "      <td>Employee Referral</td>\n",
       "      <td>90-day meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Zhou, Julia</td>\n",
       "      <td>1.110030e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2148.0</td>\n",
       "      <td>2/24/1979</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>3/30/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>Database Administrator</td>\n",
       "      <td>31.40</td>\n",
       "      <td>Simon Roup</td>\n",
       "      <td>Employee Referral</td>\n",
       "      <td>90-day meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Foss, Jason</td>\n",
       "      <td>1.192991e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>7/5/1980</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>4/15/2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>IT Director</td>\n",
       "      <td>65.00</td>\n",
       "      <td>Jennifer Zamora</td>\n",
       "      <td>Professional Society</td>\n",
       "      <td>Exceptional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Roup,Simon</td>\n",
       "      <td>1.106027e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2481.0</td>\n",
       "      <td>4/5/1973</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1/20/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>IT Manager - DB</td>\n",
       "      <td>62.00</td>\n",
       "      <td>Jennifer Zamora</td>\n",
       "      <td>Professional Society</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Ruiz, Ricardo</td>\n",
       "      <td>1.001175e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>1/4/1964</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>11/4/2015</td>\n",
       "      <td>hours</td>\n",
       "      <td>Voluntarily Terminated</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>IT Manager - DB</td>\n",
       "      <td>21.00</td>\n",
       "      <td>Jennifer Zamora</td>\n",
       "      <td>Diversity Job Fair</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Monroe, Peter</td>\n",
       "      <td>1.011023e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2134.0</td>\n",
       "      <td>10/5/1986</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>Eligible NonCitizen</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>2/15/2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>IT Manager - Infra</td>\n",
       "      <td>63.00</td>\n",
       "      <td>Jennifer Zamora</td>\n",
       "      <td>Diversity Job Fair</td>\n",
       "      <td>Needs Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dougall, Eric</td>\n",
       "      <td>1.101024e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>7/9/1970</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1/5/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>IT/IS</td>\n",
       "      <td>IT Manager - Support</td>\n",
       "      <td>64.00</td>\n",
       "      <td>Jennifer Zamora</td>\n",
       "      <td>Professional Society</td>\n",
       "      <td>Exceeds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Jeremy Prater</td>\n",
       "      <td>1.001085e+09</td>\n",
       "      <td>NV</td>\n",
       "      <td>89139.0</td>\n",
       "      <td>5/9/1974</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>5/12/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>56.00</td>\n",
       "      <td>Lynn Daneault</td>\n",
       "      <td>Website Banner Ads</td>\n",
       "      <td>PIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Khemmich, Bartholemew</td>\n",
       "      <td>1.104025e+09</td>\n",
       "      <td>CO</td>\n",
       "      <td>80820.0</td>\n",
       "      <td>11/27/1979</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>8/19/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>55.00</td>\n",
       "      <td>Lynn Daneault</td>\n",
       "      <td>Pay Per Click - Google</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Leruth, Giovanni</td>\n",
       "      <td>1.412072e+09</td>\n",
       "      <td>UT</td>\n",
       "      <td>84111.0</td>\n",
       "      <td>12/27/1988</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Separated</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>4/30/2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>55.00</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>Website Banner Ads</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Martins, Joseph</td>\n",
       "      <td>1.209049e+09</td>\n",
       "      <td>TX</td>\n",
       "      <td>78207.0</td>\n",
       "      <td>6/11/1970</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>Eligible NonCitizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>5/14/2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>56.00</td>\n",
       "      <td>Lynn Daneault</td>\n",
       "      <td>Employee Referral</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>McKinzie, Jac</td>\n",
       "      <td>1.209049e+09</td>\n",
       "      <td>TX</td>\n",
       "      <td>78789.0</td>\n",
       "      <td>7/1/1984</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>7/6/2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - Has not started yet</td>\n",
       "      <td>Future Start</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>55.00</td>\n",
       "      <td>Lynn Daneault</td>\n",
       "      <td>Website Banner Ads</td>\n",
       "      <td>N/A- too early to review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Mullaney, Howard</td>\n",
       "      <td>1.306058e+09</td>\n",
       "      <td>AL</td>\n",
       "      <td>36006.0</td>\n",
       "      <td>11/2/1975</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>9/29/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>55.00</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>Internet Search</td>\n",
       "      <td>Needs Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Nguyen, Dheepa</td>\n",
       "      <td>1.111031e+09</td>\n",
       "      <td>GA</td>\n",
       "      <td>30428.0</td>\n",
       "      <td>3/31/1989</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>7/8/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>55.00</td>\n",
       "      <td>Lynn Daneault</td>\n",
       "      <td>Pay Per Click - Google</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Onque, Jasmine</td>\n",
       "      <td>1.501072e+09</td>\n",
       "      <td>FL</td>\n",
       "      <td>33174.0</td>\n",
       "      <td>5/11/1990</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>9/30/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>57.00</td>\n",
       "      <td>Lynn Daneault</td>\n",
       "      <td>Pay Per Click - Google</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Ozark, Travis</td>\n",
       "      <td>8.120118e+08</td>\n",
       "      <td>NC</td>\n",
       "      <td>27229.0</td>\n",
       "      <td>5/19/1982</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>55.00</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>Website Banner Ads</td>\n",
       "      <td>90-day meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Potts, Xana</td>\n",
       "      <td>1.102024e+09</td>\n",
       "      <td>KY</td>\n",
       "      <td>40220.0</td>\n",
       "      <td>8/29/1988</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>55.00</td>\n",
       "      <td>Lynn Daneault</td>\n",
       "      <td>Website Banner Ads</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Riordan, Michael</td>\n",
       "      <td>1.502073e+09</td>\n",
       "      <td>ND</td>\n",
       "      <td>58782.0</td>\n",
       "      <td>1/15/1968</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Separated</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1/9/2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>55.00</td>\n",
       "      <td>Lynn Daneault</td>\n",
       "      <td>Billboard</td>\n",
       "      <td>Exceeds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Strong, Caitrin</td>\n",
       "      <td>1.411071e+09</td>\n",
       "      <td>MT</td>\n",
       "      <td>59102.0</td>\n",
       "      <td>5/12/1989</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>9/27/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>54.00</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>Professional Society</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Terry, Sharlene</td>\n",
       "      <td>1.401065e+09</td>\n",
       "      <td>OR</td>\n",
       "      <td>97756.0</td>\n",
       "      <td>5/7/1965</td>\n",
       "      <td>52.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>9/29/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>55.00</td>\n",
       "      <td>Lynn Daneault</td>\n",
       "      <td>Monster.com</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Valentin,Jackie</td>\n",
       "      <td>1.312064e+09</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85006.0</td>\n",
       "      <td>5/23/1991</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>7/5/2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>55.00</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>Other</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Villanueva, Noah</td>\n",
       "      <td>1.111031e+09</td>\n",
       "      <td>ME</td>\n",
       "      <td>4063.0</td>\n",
       "      <td>7/11/1989</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>3/5/2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>56.00</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>Website Banner Ads</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Houlihan, Debra</td>\n",
       "      <td>1.009022e+09</td>\n",
       "      <td>RI</td>\n",
       "      <td>2908.0</td>\n",
       "      <td>3/17/1966</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>5/5/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Director of Sales</td>\n",
       "      <td>60.00</td>\n",
       "      <td>Janet King</td>\n",
       "      <td>MBTA ads</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Daneault, Lynn</td>\n",
       "      <td>1.402065e+09</td>\n",
       "      <td>VT</td>\n",
       "      <td>5473.0</td>\n",
       "      <td>4/19/1990</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>5/5/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Sales Manager</td>\n",
       "      <td>54.00</td>\n",
       "      <td>Debra Houlihan</td>\n",
       "      <td>Pay Per Click - Google</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Kampew, Donysha</td>\n",
       "      <td>1.109029e+09</td>\n",
       "      <td>PA</td>\n",
       "      <td>19444.0</td>\n",
       "      <td>11/11/1989</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>11/7/2011</td>\n",
       "      <td>4/24/2014</td>\n",
       "      <td>maternity leave - did not return</td>\n",
       "      <td>Voluntarily Terminated</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Sales Manager</td>\n",
       "      <td>60.25</td>\n",
       "      <td>Debra Houlihan</td>\n",
       "      <td>Social Networks - Facebook Twitter etc</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Smith, John</td>\n",
       "      <td>1.499903e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>8/16/1984</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>5/18/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Sales Manager</td>\n",
       "      <td>56.00</td>\n",
       "      <td>Debra Houlihan</td>\n",
       "      <td>Diversity Job Fair</td>\n",
       "      <td>Needs Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Andreola, Colby</td>\n",
       "      <td>1.107027e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>5/24/1979</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>11/10/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>47.60</td>\n",
       "      <td>Alex Sweetwater</td>\n",
       "      <td>Vendor Referral</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Carabbio, Judith</td>\n",
       "      <td>1.101024e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2132.0</td>\n",
       "      <td>4/5/1987</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>11/11/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>56.00</td>\n",
       "      <td>Alex Sweetwater</td>\n",
       "      <td>Pay Per Click - Google</td>\n",
       "      <td>90-day meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Del Bosque, Keyla</td>\n",
       "      <td>1.203032e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2176.0</td>\n",
       "      <td>7/5/1979</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>57.12</td>\n",
       "      <td>Alex Sweetwater</td>\n",
       "      <td>Monster.com</td>\n",
       "      <td>90-day meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Exantus, Susan</td>\n",
       "      <td>1.401065e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>1749.0</td>\n",
       "      <td>5/15/1987</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>5/2/2011</td>\n",
       "      <td>6/5/2013</td>\n",
       "      <td>attendance</td>\n",
       "      <td>Terminated for Cause</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>48.50</td>\n",
       "      <td>Alex Sweetwater</td>\n",
       "      <td>Billboard</td>\n",
       "      <td>Needs Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Martin, Sandra</td>\n",
       "      <td>1.303055e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2135.0</td>\n",
       "      <td>11/7/1987</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Separated</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>11/11/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>55.51</td>\n",
       "      <td>Alex Sweetwater</td>\n",
       "      <td>Search Engine - Google Bing Yahoo</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Patronick, Luke</td>\n",
       "      <td>1.112031e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>2/20/1979</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>11/7/2011</td>\n",
       "      <td>9/7/2015</td>\n",
       "      <td>Another position</td>\n",
       "      <td>Voluntarily Terminated</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>52.25</td>\n",
       "      <td>Alex Sweetwater</td>\n",
       "      <td>Diversity Job Fair</td>\n",
       "      <td>Exceeds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Saada, Adell</td>\n",
       "      <td>1.012023e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2132.0</td>\n",
       "      <td>7/24/1986</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>11/5/2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>49.25</td>\n",
       "      <td>Alex Sweetwater</td>\n",
       "      <td>Pay Per Click - Google</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Szabo, Andrew</td>\n",
       "      <td>1.201031e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>5/6/1983</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>7/7/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>48.00</td>\n",
       "      <td>Alex Sweetwater</td>\n",
       "      <td>MBTA ads</td>\n",
       "      <td>Exceptional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>True, Edward</td>\n",
       "      <td>1.102024e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2451.0</td>\n",
       "      <td>6/14/1983</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>Non-Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>2/18/2013</td>\n",
       "      <td>4/15/2014</td>\n",
       "      <td>medical issues</td>\n",
       "      <td>Voluntarily Terminated</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>45.42</td>\n",
       "      <td>Alex Sweetwater</td>\n",
       "      <td>Diversity Job Fair</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Sweetwater, Alex</td>\n",
       "      <td>1.001645e+09</td>\n",
       "      <td>MA</td>\n",
       "      <td>2184.0</td>\n",
       "      <td>11/22/1966</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>US Citizen</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>8/15/2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A - still employed</td>\n",
       "      <td>Active</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>Software Engineering Manager</td>\n",
       "      <td>27.00</td>\n",
       "      <td>Jennifer Zamora</td>\n",
       "      <td>Search Engine - Google Bing Yahoo</td>\n",
       "      <td>Fully Meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Employee Name  Employee Number State      Zip         DOB   Age  \\\n",
       "0               Brown, Mia     1.103024e+09    MA   1450.0  11/24/1985  32.0   \n",
       "1     LaRotonda, William       1.106027e+09    MA   1460.0   4/26/1984  33.0   \n",
       "2         Steans, Tyrone       1.302053e+09    MA   2703.0    9/1/1986  31.0   \n",
       "3          Howard, Estelle     1.211051e+09    MA   2170.0   9/16/1985  32.0   \n",
       "4              Singh, Nan      1.307060e+09    MA   2330.0   5/19/1988  29.0   \n",
       "5         Smith, Leigh Ann     7.110077e+08    MA   1844.0   6/14/1987  30.0   \n",
       "6      LeBlanc, Brandon  R     1.102024e+09    MA   1460.0   6/10/1984  33.0   \n",
       "7              Quinn, Sean     1.206043e+09    MA   2045.0   11/6/1984  33.0   \n",
       "8        Boutwell, Bonalyn     1.307060e+09    MA   2468.0    4/4/1987  30.0   \n",
       "9        Foster-Baker, Amy     1.201031e+09    MA   2050.0   4/16/1979  38.0   \n",
       "10             King, Janet     1.001495e+09    MA   1902.0   9/21/1954  63.0   \n",
       "11        Zamora, Jennifer     1.112031e+09    MA   2067.0   8/30/1979  38.0   \n",
       "12           Becker, Renee     1.102024e+09    MA   2026.0    4/4/1986  31.0   \n",
       "13           Goble, Taisha     9.050137e+08    MA   2127.0  10/23/1971  46.0   \n",
       "14       Hernandez, Daniff     1.410071e+09    MA   1960.0    8/7/1986  31.0   \n",
       "15           Horton, Jayne     1.105026e+09    MA   2493.0   2/21/1984  33.0   \n",
       "16        Johnson, Noelle      1.003018e+09    MA   2301.0   11/7/1986  31.0   \n",
       "17          Murray, Thomas     1.406068e+09    TX  78230.0    7/4/1988  29.0   \n",
       "18        Pearson, Randall     1.102024e+09    MA   2747.0    9/5/1984  33.0   \n",
       "19       Petrowsky, Thelma     1.108028e+09    MA   1886.0   9/16/1984  33.0   \n",
       "20             Roby, Lori      1.407069e+09    MA   1886.0  10/11/1981  36.0   \n",
       "21            Rogers, Ivan     1.203032e+09    MA   1810.0   8/26/1986  31.0   \n",
       "22           Salter, Jason     1.111030e+09    MA   2452.0  12/17/1987  30.0   \n",
       "23          Simard, Kramer     8.080103e+08    MA   2110.0    2/8/1970  47.0   \n",
       "24             Zhou, Julia     1.110030e+09    MA   2148.0   2/24/1979  38.0   \n",
       "25             Foss, Jason     1.192991e+09    MA   1460.0    7/5/1980  37.0   \n",
       "26              Roup,Simon     1.106027e+09    MA   2481.0    4/5/1973  44.0   \n",
       "27           Ruiz, Ricardo     1.001175e+09    MA   1915.0    1/4/1964  54.0   \n",
       "28           Monroe, Peter     1.011023e+09    MA   2134.0   10/5/1986  31.0   \n",
       "29           Dougall, Eric     1.101024e+09    MA   1886.0    7/9/1970  47.0   \n",
       "..                     ...              ...   ...      ...         ...   ...   \n",
       "272          Jeremy Prater     1.001085e+09    NV  89139.0    5/9/1974  43.0   \n",
       "273  Khemmich, Bartholemew     1.104025e+09    CO  80820.0  11/27/1979  38.0   \n",
       "274       Leruth, Giovanni     1.412072e+09    UT  84111.0  12/27/1988  29.0   \n",
       "275        Martins, Joseph     1.209049e+09    TX  78207.0   6/11/1970  47.0   \n",
       "276          McKinzie, Jac     1.209049e+09    TX  78789.0    7/1/1984  33.0   \n",
       "277       Mullaney, Howard     1.306058e+09    AL  36006.0   11/2/1975  42.0   \n",
       "278         Nguyen, Dheepa     1.111031e+09    GA  30428.0   3/31/1989  28.0   \n",
       "279         Onque, Jasmine     1.501072e+09    FL  33174.0   5/11/1990  27.0   \n",
       "280          Ozark, Travis     8.120118e+08    NC  27229.0   5/19/1982  35.0   \n",
       "281            Potts, Xana     1.102024e+09    KY  40220.0   8/29/1988  29.0   \n",
       "282       Riordan, Michael     1.502073e+09    ND  58782.0   1/15/1968  50.0   \n",
       "283        Strong, Caitrin     1.411071e+09    MT  59102.0   5/12/1989  28.0   \n",
       "284       Terry, Sharlene      1.401065e+09    OR  97756.0    5/7/1965  52.0   \n",
       "285        Valentin,Jackie     1.312064e+09    AZ  85006.0   5/23/1991  26.0   \n",
       "286       Villanueva, Noah     1.111031e+09    ME   4063.0   7/11/1989  28.0   \n",
       "287        Houlihan, Debra     1.009022e+09    RI   2908.0   3/17/1966  51.0   \n",
       "288         Daneault, Lynn     1.402065e+09    VT   5473.0   4/19/1990  27.0   \n",
       "289    Kampew, Donysha         1.109029e+09    PA  19444.0  11/11/1989  28.0   \n",
       "290            Smith, John     1.499903e+09    MA   1886.0   8/16/1984  33.0   \n",
       "291        Andreola, Colby     1.107027e+09    MA   2110.0   5/24/1979  38.0   \n",
       "292       Carabbio, Judith     1.101024e+09    MA   2132.0    4/5/1987  30.0   \n",
       "293      Del Bosque, Keyla     1.203032e+09    MA   2176.0    7/5/1979  38.0   \n",
       "294         Exantus, Susan     1.401065e+09    MA   1749.0   5/15/1987  30.0   \n",
       "295         Martin, Sandra     1.303055e+09    MA   2135.0   11/7/1987  30.0   \n",
       "296        Patronick, Luke     1.112031e+09    MA   1844.0   2/20/1979  38.0   \n",
       "297           Saada, Adell     1.012023e+09    MA   2132.0   7/24/1986  31.0   \n",
       "298          Szabo, Andrew     1.201031e+09    MA   2140.0    5/6/1983  34.0   \n",
       "299           True, Edward     1.102024e+09    MA   2451.0   6/14/1983  34.0   \n",
       "300       Sweetwater, Alex     1.001645e+09    MA   2184.0  11/22/1966  51.0   \n",
       "301                    NaN              NaN   NaN      NaN         NaN   NaN   \n",
       "\n",
       "        Sex MaritalDesc          CitizenDesc Hispanic/Latino  ...  \\\n",
       "0    Female     Married           US Citizen              No  ...   \n",
       "1      Male    Divorced           US Citizen              No  ...   \n",
       "2      Male      Single           US Citizen              No  ...   \n",
       "3    Female     Married           US Citizen              No  ...   \n",
       "4    Female      Single           US Citizen              No  ...   \n",
       "5    Female     Married           US Citizen              No  ...   \n",
       "6      Male     Married           US Citizen              No  ...   \n",
       "7      Male     Married  Eligible NonCitizen              No  ...   \n",
       "8    Female     Married           US Citizen              No  ...   \n",
       "9    Female     Married           US Citizen              no  ...   \n",
       "10   Female     Married           US Citizen             Yes  ...   \n",
       "11   Female      Single           US Citizen              No  ...   \n",
       "12   Female      Single           US Citizen             Yes  ...   \n",
       "13   Female      Single           US Citizen              No  ...   \n",
       "14     Male     Married           US Citizen              No  ...   \n",
       "15   Female      Single           US Citizen              No  ...   \n",
       "16   Female     Married           US Citizen              No  ...   \n",
       "17     Male    Divorced           US Citizen              No  ...   \n",
       "18     Male     Married           US Citizen              No  ...   \n",
       "19   Female     Married           US Citizen              No  ...   \n",
       "20   Female     Married           US Citizen              No  ...   \n",
       "21     Male     Married           US Citizen              No  ...   \n",
       "22     Male    Divorced           US Citizen              No  ...   \n",
       "23     Male     Married           US Citizen             Yes  ...   \n",
       "24   Female      Single           US Citizen              No  ...   \n",
       "25     Male      Single           US Citizen              No  ...   \n",
       "26     Male      Single           US Citizen              No  ...   \n",
       "27     Male    Divorced           US Citizen              No  ...   \n",
       "28     Male     Married  Eligible NonCitizen             Yes  ...   \n",
       "29     Male      Single           US Citizen              No  ...   \n",
       "..      ...         ...                  ...             ...  ...   \n",
       "272    Male     Married           US Citizen              No  ...   \n",
       "273    Male      Single           US Citizen              No  ...   \n",
       "274    Male   Separated           US Citizen              No  ...   \n",
       "275    Male      Single  Eligible NonCitizen              No  ...   \n",
       "276    Male     Married           US Citizen              No  ...   \n",
       "277    Male      Single           US Citizen              No  ...   \n",
       "278  Female      Single           US Citizen              No  ...   \n",
       "279  Female      Single           US Citizen             Yes  ...   \n",
       "280    Male      Single           US Citizen              No  ...   \n",
       "281  Female     Married           US Citizen              No  ...   \n",
       "282    Male   Separated           US Citizen              No  ...   \n",
       "283  Female     Married           US Citizen              No  ...   \n",
       "284  Female      Single           US Citizen              No  ...   \n",
       "285  Female     Married           US Citizen              No  ...   \n",
       "286    Male      Single           US Citizen              No  ...   \n",
       "287  Female     Married           US Citizen              No  ...   \n",
       "288  Female      Single           US Citizen              No  ...   \n",
       "289  Female      Single           US Citizen              No  ...   \n",
       "290    Male    Divorced           US Citizen              no  ...   \n",
       "291  Female      Single           US Citizen              No  ...   \n",
       "292  Female      Single           US Citizen              No  ...   \n",
       "293  Female      Single           US Citizen              No  ...   \n",
       "294  Female     Married           US Citizen              No  ...   \n",
       "295  Female   Separated           US Citizen              No  ...   \n",
       "296    Male      Single           US Citizen              No  ...   \n",
       "297  Female     Married           US Citizen              No  ...   \n",
       "298    Male      Single           US Citizen              No  ...   \n",
       "299    Male      Single          Non-Citizen              No  ...   \n",
       "300    Male      Single           US Citizen              No  ...   \n",
       "301     NaN         NaN                  NaN             NaN  ...   \n",
       "\n",
       "    Date of Hire Date of Termination                   Reason For Term  \\\n",
       "0     10/27/2008                 NaN              N/A - still employed   \n",
       "1       1/6/2014                 NaN              N/A - still employed   \n",
       "2      9/29/2014                 NaN              N/A - still employed   \n",
       "3      2/16/2015           4/15/2015              N/A - still employed   \n",
       "4       5/1/2015                 NaN              N/A - still employed   \n",
       "5      9/26/2011           9/25/2013                     career change   \n",
       "6       1/5/2016                 NaN              N/A - still employed   \n",
       "7      2/21/2011           8/15/2015                     career change   \n",
       "8      2/16/2015                 NaN              N/A - still employed   \n",
       "9       1/5/2009                 NaN              N/A - still employed   \n",
       "10      7/2/2012                 NaN              N/A - still employed   \n",
       "11     4/10/2010                 NaN              N/A - still employed   \n",
       "12      7/7/2014           9/12/2015                       performance   \n",
       "13     2/16/2015           3/15/2015                  no-call, no-show   \n",
       "14     2/16/2015           2/22/2015                  no-call, no-show   \n",
       "15     3/30/2015                 NaN              N/A - still employed   \n",
       "16      1/5/2015                 NaN              N/A - still employed   \n",
       "17    11/10/2014                 NaN              N/A - still employed   \n",
       "18     12/1/2014            5/1/2016                       performance   \n",
       "19    11/10/2014                 NaN              N/A - still employed   \n",
       "20     2/16/2015                 NaN              N/A - still employed   \n",
       "21     3/30/2015                 NaN              N/A - still employed   \n",
       "22      1/5/2015          10/31/2015                             hours   \n",
       "23      1/5/2015                 NaN              N/A - still employed   \n",
       "24     3/30/2015                 NaN              N/A - still employed   \n",
       "25     4/15/2011                 NaN              N/A - still employed   \n",
       "26     1/20/2013                 NaN              N/A - still employed   \n",
       "27      1/9/2012           11/4/2015                             hours   \n",
       "28     2/15/2012                 NaN              N/A - still employed   \n",
       "29      1/5/2014                 NaN              N/A - still employed   \n",
       "..           ...                 ...                               ...   \n",
       "272    5/12/2014                 NaN              N/A - still employed   \n",
       "273    8/19/2013                 NaN              N/A - still employed   \n",
       "274    4/30/2012                 NaN              N/A - still employed   \n",
       "275    5/14/2012                 NaN              N/A - still employed   \n",
       "276     7/6/2016                 NaN         N/A - Has not started yet   \n",
       "277    9/29/2014                 NaN              N/A - still employed   \n",
       "278     7/8/2013                 NaN              N/A - still employed   \n",
       "279    9/30/2013                 NaN              N/A - still employed   \n",
       "280     1/5/2015                 NaN              N/A - still employed   \n",
       "281     1/9/2012                 NaN              N/A - still employed   \n",
       "282     1/9/2006                 NaN              N/A - still employed   \n",
       "283    9/27/2010                 NaN              N/A - still employed   \n",
       "284    9/29/2014                 NaN              N/A - still employed   \n",
       "285     7/5/2011                 NaN              N/A - still employed   \n",
       "286     3/5/2012                 NaN              N/A - still employed   \n",
       "287     5/5/2014                 NaN              N/A - still employed   \n",
       "288     5/5/2014                 NaN              N/A - still employed   \n",
       "289    11/7/2011           4/24/2014  maternity leave - did not return   \n",
       "290    5/18/2014                 NaN              N/A - still employed   \n",
       "291   11/10/2014                 NaN              N/A - still employed   \n",
       "292   11/11/2013                 NaN              N/A - still employed   \n",
       "293     1/9/2012                 NaN              N/A - still employed   \n",
       "294     5/2/2011            6/5/2013                        attendance   \n",
       "295   11/11/2013                 NaN              N/A - still employed   \n",
       "296    11/7/2011            9/7/2015                  Another position   \n",
       "297    11/5/2012                 NaN              N/A - still employed   \n",
       "298     7/7/2014                 NaN              N/A - still employed   \n",
       "299    2/18/2013           4/15/2014                    medical issues   \n",
       "300    8/15/2011                 NaN              N/A - still employed   \n",
       "301          NaN                 NaN                               NaN   \n",
       "\n",
       "          Employment Status                 Department  \\\n",
       "0                    Active              Admin Offices   \n",
       "1                    Active              Admin Offices   \n",
       "2                    Active              Admin Offices   \n",
       "3                    Active              Admin Offices   \n",
       "4                    Active              Admin Offices   \n",
       "5    Voluntarily Terminated              Admin Offices   \n",
       "6                    Active              Admin Offices   \n",
       "7    Voluntarily Terminated              Admin Offices   \n",
       "8                    Active              Admin Offices   \n",
       "9                    Active              Admin Offices   \n",
       "10                   Active           Executive Office   \n",
       "11                   Active                      IT/IS   \n",
       "12     Terminated for Cause                      IT/IS   \n",
       "13     Terminated for Cause                      IT/IS   \n",
       "14     Terminated for Cause                      IT/IS   \n",
       "15                   Active                      IT/IS   \n",
       "16         Leave of Absence                      IT/IS   \n",
       "17                   Active                      IT/IS   \n",
       "18   Voluntarily Terminated                      IT/IS   \n",
       "19                   Active                      IT/IS   \n",
       "20                   Active                      IT/IS   \n",
       "21                   Active                      IT/IS   \n",
       "22   Voluntarily Terminated                      IT/IS   \n",
       "23                   Active                      IT/IS   \n",
       "24                   Active                      IT/IS   \n",
       "25                   Active                      IT/IS   \n",
       "26                   Active                      IT/IS   \n",
       "27   Voluntarily Terminated                      IT/IS   \n",
       "28                   Active                      IT/IS   \n",
       "29                   Active                      IT/IS   \n",
       "..                      ...                        ...   \n",
       "272                  Active                      Sales   \n",
       "273                  Active                      Sales   \n",
       "274                  Active                      Sales   \n",
       "275                  Active                      Sales   \n",
       "276            Future Start                      Sales   \n",
       "277                  Active                      Sales   \n",
       "278                  Active                      Sales   \n",
       "279                  Active                      Sales   \n",
       "280                  Active                      Sales   \n",
       "281                  Active                      Sales   \n",
       "282                  Active                      Sales   \n",
       "283                  Active                      Sales   \n",
       "284                  Active                      Sales   \n",
       "285                  Active                      Sales   \n",
       "286                  Active                      Sales   \n",
       "287                  Active                      Sales   \n",
       "288                  Active                      Sales   \n",
       "289  Voluntarily Terminated                      Sales   \n",
       "290                  Active                      Sales   \n",
       "291                  Active       Software Engineering   \n",
       "292                  Active       Software Engineering   \n",
       "293                  Active       Software Engineering   \n",
       "294    Terminated for Cause       Software Engineering   \n",
       "295                  Active       Software Engineering   \n",
       "296  Voluntarily Terminated       Software Engineering   \n",
       "297                  Active       Software Engineering   \n",
       "298                  Active       Software Engineering   \n",
       "299  Voluntarily Terminated       Software Engineering   \n",
       "300                  Active  Software Engineering        \n",
       "301                     NaN                        NaN   \n",
       "\n",
       "                         Position Pay Rate        Manager Name  \\\n",
       "0                    Accountant I    28.50  Brandon R. LeBlanc   \n",
       "1                    Accountant I    23.00  Brandon R. LeBlanc   \n",
       "2                    Accountant I    29.00  Brandon R. LeBlanc   \n",
       "3        Administrative Assistant    21.50  Brandon R. LeBlanc   \n",
       "4        Administrative Assistant    16.56  Brandon R. LeBlanc   \n",
       "5        Administrative Assistant    20.50  Brandon R. LeBlanc   \n",
       "6         Shared Services Manager    55.00          Janet King   \n",
       "7         Shared Services Manager    55.00          Janet King   \n",
       "8                  Sr. Accountant    34.95  Brandon R. LeBlanc   \n",
       "9                  Sr. Accountant    34.95  Board of Directors   \n",
       "10                President & CEO    80.00  Board of Directors   \n",
       "11                            CIO    65.00          Janet King   \n",
       "12         Database Administrator    43.00          Simon Roup   \n",
       "13         Database Administrator    48.50          Simon Roup   \n",
       "14         Database Administrator    40.10          Simon Roup   \n",
       "15         Database Administrator    34.00          Simon Roup   \n",
       "16         Database Administrator    40.00          Simon Roup   \n",
       "17         Database Administrator    35.50          Simon Roup   \n",
       "18         Database Administrator    41.00          Simon Roup   \n",
       "19         Database Administrator    42.75          Simon Roup   \n",
       "20         Database Administrator    39.55          Simon Roup   \n",
       "21         Database Administrator    42.20          Simon Roup   \n",
       "22         Database Administrator    45.00          Simon Roup   \n",
       "23         Database Administrator    30.20          Simon Roup   \n",
       "24         Database Administrator    31.40          Simon Roup   \n",
       "25                    IT Director    65.00     Jennifer Zamora   \n",
       "26                IT Manager - DB    62.00     Jennifer Zamora   \n",
       "27                IT Manager - DB    21.00     Jennifer Zamora   \n",
       "28             IT Manager - Infra    63.00     Jennifer Zamora   \n",
       "29           IT Manager - Support    64.00     Jennifer Zamora   \n",
       "..                            ...      ...                 ...   \n",
       "272            Area Sales Manager    56.00       Lynn Daneault   \n",
       "273            Area Sales Manager    55.00       Lynn Daneault   \n",
       "274            Area Sales Manager    55.00          John Smith   \n",
       "275            Area Sales Manager    56.00       Lynn Daneault   \n",
       "276            Area Sales Manager    55.00       Lynn Daneault   \n",
       "277            Area Sales Manager    55.00          John Smith   \n",
       "278            Area Sales Manager    55.00       Lynn Daneault   \n",
       "279            Area Sales Manager    57.00       Lynn Daneault   \n",
       "280            Area Sales Manager    55.00          John Smith   \n",
       "281            Area Sales Manager    55.00       Lynn Daneault   \n",
       "282            Area Sales Manager    55.00       Lynn Daneault   \n",
       "283            Area Sales Manager    54.00          John Smith   \n",
       "284            Area Sales Manager    55.00       Lynn Daneault   \n",
       "285            Area Sales Manager    55.00          John Smith   \n",
       "286            Area Sales Manager    56.00          John Smith   \n",
       "287             Director of Sales    60.00          Janet King   \n",
       "288                 Sales Manager    54.00      Debra Houlihan   \n",
       "289                 Sales Manager    60.25      Debra Houlihan   \n",
       "290                 Sales Manager    56.00      Debra Houlihan   \n",
       "291             Software Engineer    47.60     Alex Sweetwater   \n",
       "292             Software Engineer    56.00     Alex Sweetwater   \n",
       "293             Software Engineer    57.12     Alex Sweetwater   \n",
       "294             Software Engineer    48.50     Alex Sweetwater   \n",
       "295             Software Engineer    55.51     Alex Sweetwater   \n",
       "296             Software Engineer    52.25     Alex Sweetwater   \n",
       "297             Software Engineer    49.25     Alex Sweetwater   \n",
       "298             Software Engineer    48.00     Alex Sweetwater   \n",
       "299             Software Engineer    45.42     Alex Sweetwater   \n",
       "300  Software Engineering Manager    27.00     Jennifer Zamora   \n",
       "301                           NaN      NaN                 NaN   \n",
       "\n",
       "                            Employee Source         Performance Score  \n",
       "0                        Diversity Job Fair               Fully Meets  \n",
       "1                        Website Banner Ads               Fully Meets  \n",
       "2                           Internet Search               Fully Meets  \n",
       "3                    Pay Per Click - Google  N/A- too early to review  \n",
       "4                        Website Banner Ads  N/A- too early to review  \n",
       "5                        Diversity Job Fair               Fully Meets  \n",
       "6                               Monster.com               Fully Meets  \n",
       "7                        Diversity Job Fair               Fully Meets  \n",
       "8                        Diversity Job Fair              90-day meets  \n",
       "9                                     Other               Fully Meets  \n",
       "10                   Pay Per Click - Google               Fully Meets  \n",
       "11                        Employee Referral               Exceptional  \n",
       "12        Search Engine - Google Bing Yahoo               Fully Meets  \n",
       "13                                Glassdoor               Fully Meets  \n",
       "14                        Employee Referral  N/A- too early to review  \n",
       "15                                Glassdoor  N/A- too early to review  \n",
       "16                                Glassdoor              90-day meets  \n",
       "17                       Diversity Job Fair               Exceptional  \n",
       "18                        Employee Referral               Fully Meets  \n",
       "19                        Employee Referral               Exceptional  \n",
       "20                        Employee Referral               Fully Meets  \n",
       "21                   Pay Per Click - Google  N/A- too early to review  \n",
       "22                          Vendor Referral              90-day meets  \n",
       "23                        Employee Referral              90-day meets  \n",
       "24                        Employee Referral              90-day meets  \n",
       "25                     Professional Society               Exceptional  \n",
       "26                     Professional Society               Fully Meets  \n",
       "27                       Diversity Job Fair               Fully Meets  \n",
       "28                       Diversity Job Fair         Needs Improvement  \n",
       "29                     Professional Society                   Exceeds  \n",
       "..                                      ...                       ...  \n",
       "272                      Website Banner Ads                       PIP  \n",
       "273                  Pay Per Click - Google               Fully Meets  \n",
       "274                      Website Banner Ads               Fully Meets  \n",
       "275                       Employee Referral               Fully Meets  \n",
       "276                      Website Banner Ads  N/A- too early to review  \n",
       "277                         Internet Search         Needs Improvement  \n",
       "278                  Pay Per Click - Google               Fully Meets  \n",
       "279                  Pay Per Click - Google               Fully Meets  \n",
       "280                      Website Banner Ads              90-day meets  \n",
       "281                      Website Banner Ads               Fully Meets  \n",
       "282                               Billboard                   Exceeds  \n",
       "283                    Professional Society               Fully Meets  \n",
       "284                             Monster.com               Fully Meets  \n",
       "285                                   Other               Fully Meets  \n",
       "286                      Website Banner Ads               Fully Meets  \n",
       "287                                MBTA ads               Fully Meets  \n",
       "288                  Pay Per Click - Google               Fully Meets  \n",
       "289  Social Networks - Facebook Twitter etc               Fully Meets  \n",
       "290                      Diversity Job Fair         Needs Improvement  \n",
       "291                         Vendor Referral               Fully Meets  \n",
       "292                  Pay Per Click - Google              90-day meets  \n",
       "293                             Monster.com              90-day meets  \n",
       "294                               Billboard         Needs Improvement  \n",
       "295       Search Engine - Google Bing Yahoo               Fully Meets  \n",
       "296                      Diversity Job Fair                   Exceeds  \n",
       "297                  Pay Per Click - Google               Fully Meets  \n",
       "298                                MBTA ads               Exceptional  \n",
       "299                      Diversity Job Fair               Fully Meets  \n",
       "300       Search Engine - Google Bing Yahoo               Fully Meets  \n",
       "301                                     NaN                       NaN  \n",
       "\n",
       "[302 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_data = pd.read_csv('./custom_scripts/old_core_dataset.csv')\n",
    "hr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hr_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create Unique Values Dictionary</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq = gen_uniq_dict(hr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uniq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Load Entities</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': [['William LaRotonda',\n",
       "   'Tyrone Steans',\n",
       "   'Estelle Howard',\n",
       "   'Leigh Smith',\n",
       "   'Brandon LeBlanc',\n",
       "   'Sean Quinn',\n",
       "   'Bonalyn Boutwell',\n",
       "   'Amy Foster-Baker',\n",
       "   'Janet King',\n",
       "   'Jennifer Zamora',\n",
       "   'Renee Becker',\n",
       "   'Taisha Goble',\n",
       "   'Daniff Hernandez',\n",
       "   'Jayne Horton',\n",
       "   'Noelle Johnson',\n",
       "   'Thomas Murray',\n",
       "   'Randall Pearson',\n",
       "   'Thelma Petrowsky',\n",
       "   'Lori Roby',\n",
       "   'Jason Salter',\n",
       "   'Kramer Simard',\n",
       "   'Simon Roup',\n",
       "   'Ricardo Ruiz',\n",
       "   'Peter Monroe',\n",
       "   'Eric Dougall',\n",
       "   'Rick Clayton',\n",
       "   'Lisa Galia',\n",
       "   'Leonara Lindsay',\n",
       "   'Alejandro Bacong',\n",
       "   'Anthony Cisco',\n",
       "   'Linda Dolan',\n",
       "   'Maria Gonzalez',\n",
       "   'Carlos Merlos',\n",
       "   'Tanya Morway',\n",
       "   'Anita Shepard',\n",
       "   'Neville Tredinnick',\n",
       "   'Jumil Turpin',\n",
       "   'Karthikeyan Ait Sidi',\n",
       "   'Claudia Carr',\n",
       "   'Donald Favis',\n",
       "   'Bianca Roehrich',\n",
       "   'Ann Daniele',\n",
       "   'Jyoti Lajiri',\n",
       "   'Jeremiah Semizoglou',\n",
       "   'Joe South',\n",
       "   'Sarah Warfield',\n",
       "   'Elisa Bramante',\n",
       "   'Michael Albert',\n",
       "   'Charles Bozzi',\n",
       "   'Webster Butler',\n",
       "   'Elijiah Gray',\n",
       "   'Jonathan Hogland',\n",
       "   'Walter Immediato',\n",
       "   'Ketsia Liebig',\n",
       "   'Brannon Miller',\n",
       "   'Ebonee Peterson',\n",
       "   'Kelley Spirea',\n",
       "   'David Stanley',\n",
       "   'Kissy Sullivan',\n",
       "   'Courtney Wallace',\n",
       "   'Wilson Adinolfi',\n",
       "   'Trina Alagbe',\n",
       "   'Carol Anderson',\n",
       "   'Sam Athwal',\n",
       "   'Rachael Baczenski',\n",
       "   'Francesco Barone',\n",
       "   'Nader Barton',\n",
       "   'Lowan Biden',\n",
       "   'Helen Billis',\n",
       "   'Donna Brill',\n",
       "   'Josephine Bugali',\n",
       "   'Beatrice Chace',\n",
       "   'Lin Chan',\n",
       "   'Donovan Chang',\n",
       "   'Enola Chivukula',\n",
       "   'Caroline Cierpiszewski',\n",
       "   'Elijian Clukey',\n",
       "   'James Cockel',\n",
       "   'Spencer Cole',\n",
       "   'Jean Crimmings',\n",
       "   \"Jene'ya Darson\",\n",
       "   'Carl Desimone',\n",
       "   'Geoff Dickinson',\n",
       "   'Lily DiNocco',\n",
       "   'Denisa Dobrin',\n",
       "   'Marianne Eaton',\n",
       "   'Rex England',\n",
       "   'Miguel Estremera',\n",
       "   'April Evensen',\n",
       "   'Susan Ferguson',\n",
       "   'Nilson Fernandes',\n",
       "   'Violeta Ferreira',\n",
       "   'Libby Fidelia',\n",
       "   'Raul Garcia',\n",
       "   'Hamish Garneau',\n",
       "   'Barbara Gaul',\n",
       "   'Mildred Gentry',\n",
       "   'Melisa Gerke',\n",
       "   'Alex Gilles',\n",
       "   'Evelyn Girifalco',\n",
       "   'Shenice Gold',\n",
       "   'Roxana Goyal',\n",
       "   'Paula Gross',\n",
       "   'Joanne Handschiegl',\n",
       "   'Ludwick Harrell',\n",
       "   'Christie Harrington',\n",
       "   'Kara Harrison',\n",
       "   'Rose Ivey',\n",
       "   'Maryellen Jackson',\n",
       "   'Hannah Jacobi',\n",
       "   'Sneha Jhaveri',\n",
       "   'Judy Jung',\n",
       "   'Kathleen Kinsella',\n",
       "   'Alexandra Kirill',\n",
       "   'Bradley Knapp',\n",
       "   'John Kretschmer',\n",
       "   'Enrico Langton',\n",
       "   'Dallas Leach',\n",
       "   'Marilyn Linares',\n",
       "   'Allison Lydon',\n",
       "   'Lindsay Lynch',\n",
       "   'Samuel MacLennan',\n",
       "   'Lauren Mahoney',\n",
       "   'Debbie Mangal',\n",
       "   'Shana Maurice',\n",
       "   'Sandy Mckenna',\n",
       "   'Elizabeth Meads',\n",
       "   'Dawn Motlagh',\n",
       "   'Colombui Ndzi',\n",
       "   'Richard Newman',\n",
       "   'Shari Ngodup',\n",
       "   'Lei-Ming Nguyen',\n",
       "   \"Lynn O'hare\",\n",
       "   'Adeel Osturnka',\n",
       "   'Clinton Owad',\n",
       "   'Nina Panjwani',\n",
       "   'Emil Pelech',\n",
       "   'Shakira Perry',\n",
       "   'Hong Pham',\n",
       "   'Brad Pitt',\n",
       "   'Morissa Power',\n",
       "   'Louis Punjabhi',\n",
       "   'Janine Purinton',\n",
       "   'Quinn Rarrick',\n",
       "   'Haley Rivera',\n",
       "   'Alain Robinson',\n",
       "   'Ashley Rose',\n",
       "   'Bruno Rossetti',\n",
       "   'Melinda Saar-Beckles',\n",
       "   'Nore Sadki',\n",
       "   'Kamrin Sander',\n",
       "   'Nori Sewkumar',\n",
       "   'Seffi Shields',\n",
       "   'Taylor Sparks',\n",
       "   'Kristen Squatrito',\n",
       "   'Desiree Tavares',\n",
       "   'Sophia Theamstern',\n",
       "   'Theresa Tinto',\n",
       "   'Jeanette Tippett',\n",
       "   'Mei Trang',\n",
       "   'Abdellah Veera',\n",
       "   'Colleen Volk',\n",
       "   'Anna Von Massenbach',\n",
       "   'Scott Whittier',\n",
       "   'Barry Wilber',\n",
       "   'Jacquelyn Williams',\n",
       "   'Catherine Ybarra',\n",
       "   'Kimberly Beak',\n",
       "   'Dianna Blount',\n",
       "   'Betsy Bondwell',\n",
       "   'Joseph Buccheri',\n",
       "   'Joelle Burke',\n",
       "   'Benjamin Burkett',\n",
       "   'Phil Close',\n",
       "   'Daniel Davis',\n",
       "   'Carla Demita',\n",
       "   'Angela Erilus',\n",
       "   'Megan Faller',\n",
       "   'Nicole Fancett',\n",
       "   'Phylicia Gosciminski',\n",
       "   'Earnest Hankard',\n",
       "   'Adrienne Homberger',\n",
       "   'Julissa Hunts',\n",
       "   'Rosalie Hutter',\n",
       "   'Ming Huynh',\n",
       "   'Tayana Jeannite',\n",
       "   'Yen Johnston',\n",
       "   'Lindsey Langford',\n",
       "   'Mohammed Latif',\n",
       "   'Mathew Linden',\n",
       "   'Robyn Manchester',\n",
       "   'Karen Mancuso',\n",
       "   'Brigit McCarthy',\n",
       "   'Erasumus Monkfish',\n",
       "   'Luisa Monterro',\n",
       "   'Patrick Moran',\n",
       "   'Maliki Moumanil',\n",
       "   'Kristie Nowlan',\n",
       "   'Brooke Oliver',\n",
       "   'Ermine Pelletier',\n",
       "   'May Roberson',\n",
       "   'Adil Sahoo',\n",
       "   'Constance Sloan',\n",
       "   'Lenora Tejeda',\n",
       "   'Kenneth Thibaud',\n",
       "   'Cybil Trzeciak',\n",
       "   'Roger Walker',\n",
       "   'Jordan Winthrop',\n",
       "   'Hang Wolk',\n",
       "   'Edward Buck',\n",
       "   'Jessica Bunbury',\n",
       "   'Michelle Carter',\n",
       "   'Latia Costa',\n",
       "   'Jenna Dietrich',\n",
       "   'Alfred Digitale',\n",
       "   'Maruk Fraval',\n",
       "   'Gerry Friedman',\n",
       "   'Whitney Gill',\n",
       "   'Myriam Givens',\n",
       "   'Mike Guilianno',\n",
       "   'Jeremy Prater',\n",
       "   'Bartholemew Khemmich',\n",
       "   'Giovanni Leruth',\n",
       "   'Jac McKinzie',\n",
       "   'Howard Mullaney',\n",
       "   'Jasmine Onque',\n",
       "   'Travis Ozark',\n",
       "   'Xana Potts',\n",
       "   'Caitrin Strong',\n",
       "   'Sharlene Terry',\n",
       "   'Jackie Valentin',\n",
       "   'Noah Villanueva',\n",
       "   'Debra Houlihan',\n",
       "   'Donysha Kampew',\n",
       "   'Colby Andreola',\n",
       "   'Judith Carabbio',\n",
       "   'Keyla Del Bosque',\n",
       "   'Sandra Martin',\n",
       "   'Luke Patronick',\n",
       "   'Adell Saada',\n",
       "   'Andrew Szabo',\n",
       "   'Mia Brown',\n",
       "   'Ivan Rogers',\n",
       "   'Julia Soto',\n",
       "   'Nan Singh'],\n",
       "  [['william larotonda', 'William', 'william', 'LaRotonda', 'larotonda'],\n",
       "   ['tyrone steans', 'Tyrone', 'tyrone', 'Steans', 'steans'],\n",
       "   ['estelle howard', 'Estelle', 'estelle', 'Howard', 'howard'],\n",
       "   ['leigh smith', 'Leigh', 'leigh', 'Smith', 'smith'],\n",
       "   ['brandon leblanc', 'Brandon', 'brandon', 'LeBlanc', 'leblanc'],\n",
       "   ['sean quinn', 'Sean', 'sean', 'Quinn', 'quinn'],\n",
       "   ['bonalyn boutwell', 'Bonalyn', 'bonalyn', 'Boutwell', 'boutwell'],\n",
       "   ['amy foster-baker', 'Amy', 'amy', 'Foster-Baker', 'foster-baker'],\n",
       "   ['janet king', 'Janet', 'janet', 'King', 'king'],\n",
       "   ['jennifer zamora', 'Jennifer', 'jennifer', 'Zamora', 'zamora'],\n",
       "   ['renee becker', 'Renee', 'renee', 'Becker', 'becker'],\n",
       "   ['taisha goble', 'Taisha', 'taisha', 'Goble', 'goble'],\n",
       "   ['daniff hernandez', 'Daniff', 'daniff', 'Hernandez', 'hernandez'],\n",
       "   ['jayne horton', 'Jayne', 'jayne', 'Horton', 'horton'],\n",
       "   ['noelle johnson', 'Noelle', 'noelle', 'Johnson', 'johnson'],\n",
       "   ['thomas murray', 'Thomas', 'thomas', 'Murray', 'murray'],\n",
       "   ['randall pearson', 'Randall', 'randall', 'Pearson', 'pearson'],\n",
       "   ['thelma petrowsky', 'Thelma', 'thelma', 'Petrowsky', 'petrowsky'],\n",
       "   ['lori roby', 'Lori', 'lori', 'Roby', 'roby'],\n",
       "   ['jason salter', 'Jason', 'jason', 'Salter', 'salter'],\n",
       "   ['kramer simard', 'Kramer', 'kramer', 'Simard', 'simard'],\n",
       "   ['simon roup', 'Simon', 'simon', 'Roup', 'roup'],\n",
       "   ['ricardo ruiz', 'Ricardo', 'ricardo', 'Ruiz', 'ruiz'],\n",
       "   ['peter monroe', 'Peter', 'peter', 'Monroe', 'monroe'],\n",
       "   ['eric dougall', 'Eric', 'eric', 'Dougall', 'dougall'],\n",
       "   ['rick clayton', 'Rick', 'rick', 'Clayton', 'clayton'],\n",
       "   ['lisa galia', 'Lisa', 'lisa', 'Galia', 'galia'],\n",
       "   ['leonara lindsay', 'Leonara', 'leonara', 'Lindsay', 'lindsay'],\n",
       "   ['alejandro bacong', 'Alejandro', 'alejandro', 'Bacong', 'bacong'],\n",
       "   ['anthony cisco', 'Anthony', 'anthony', 'Cisco', 'cisco'],\n",
       "   ['linda dolan', 'Linda', 'linda', 'Dolan', 'dolan'],\n",
       "   ['maria gonzalez', 'Maria', 'maria', 'Gonzalez', 'gonzalez'],\n",
       "   ['carlos merlos', 'Carlos', 'carlos', 'Merlos', 'merlos'],\n",
       "   ['tanya morway', 'Tanya', 'tanya', 'Morway', 'morway'],\n",
       "   ['anita shepard', 'Anita', 'anita', 'Shepard', 'shepard'],\n",
       "   ['neville tredinnick', 'Neville', 'neville', 'Tredinnick', 'tredinnick'],\n",
       "   ['jumil turpin', 'Jumil', 'jumil', 'Turpin', 'turpin'],\n",
       "   ['karthikeyan ait sidi', 'Karthikeyan', 'karthikeyan', 'Ait', 'ait'],\n",
       "   ['claudia carr', 'Claudia', 'claudia', 'Carr', 'carr'],\n",
       "   ['donald favis', 'Donald', 'donald', 'Favis', 'favis'],\n",
       "   ['bianca roehrich', 'Bianca', 'bianca', 'Roehrich', 'roehrich'],\n",
       "   ['ann daniele', 'Ann', 'ann', 'Daniele', 'daniele'],\n",
       "   ['jyoti lajiri', 'Jyoti', 'jyoti', 'Lajiri', 'lajiri'],\n",
       "   ['jeremiah semizoglou', 'Jeremiah', 'jeremiah', 'Semizoglou', 'semizoglou'],\n",
       "   ['joe south', 'Joe', 'joe', 'South', 'south'],\n",
       "   ['sarah warfield', 'Sarah', 'sarah', 'Warfield', 'warfield'],\n",
       "   ['elisa bramante', 'Elisa', 'elisa', 'Bramante', 'bramante'],\n",
       "   ['michael albert', 'Michael', 'michael', 'Albert', 'albert'],\n",
       "   ['charles bozzi', 'Charles', 'charles', 'Bozzi', 'bozzi'],\n",
       "   ['webster butler', 'Webster', 'webster', 'Butler', 'butler'],\n",
       "   ['elijiah gray', 'Elijiah', 'elijiah', 'Gray', 'gray'],\n",
       "   ['jonathan hogland', 'Jonathan', 'jonathan', 'Hogland', 'hogland'],\n",
       "   ['walter immediato', 'Walter', 'walter', 'Immediato', 'immediato'],\n",
       "   ['ketsia liebig', 'Ketsia', 'ketsia', 'Liebig', 'liebig'],\n",
       "   ['brannon miller', 'Brannon', 'brannon', 'Miller', 'miller'],\n",
       "   ['ebonee peterson', 'Ebonee', 'ebonee', 'Peterson', 'peterson'],\n",
       "   ['kelley spirea', 'Kelley', 'kelley', 'Spirea', 'spirea'],\n",
       "   ['david stanley', 'David', 'david', 'Stanley', 'stanley'],\n",
       "   ['kissy sullivan', 'Kissy', 'kissy', 'Sullivan', 'sullivan'],\n",
       "   ['courtney wallace', 'Courtney', 'courtney', 'Wallace', 'wallace'],\n",
       "   ['wilson adinolfi', 'Wilson', 'wilson', 'Adinolfi', 'adinolfi'],\n",
       "   ['trina alagbe', 'Trina', 'trina', 'Alagbe', 'alagbe'],\n",
       "   ['carol anderson', 'Carol', 'carol', 'Anderson', 'anderson'],\n",
       "   ['sam athwal', 'Sam', 'sam', 'Athwal', 'athwal'],\n",
       "   ['rachael baczenski', 'Rachael', 'rachael', 'Baczenski', 'baczenski'],\n",
       "   ['francesco barone', 'Francesco', 'francesco', 'Barone', 'barone'],\n",
       "   ['nader barton', 'Nader', 'nader', 'Barton', 'barton'],\n",
       "   ['lowan biden', 'Lowan', 'lowan', 'Biden', 'biden'],\n",
       "   ['helen billis', 'Helen', 'helen', 'Billis', 'billis'],\n",
       "   ['donna brill', 'Donna', 'donna', 'Brill', 'brill'],\n",
       "   ['josephine bugali', 'Josephine', 'josephine', 'Bugali', 'bugali'],\n",
       "   ['beatrice chace', 'Beatrice', 'beatrice', 'Chace', 'chace'],\n",
       "   ['lin chan', 'Lin', 'lin', 'Chan', 'chan'],\n",
       "   ['donovan chang', 'Donovan', 'donovan', 'Chang', 'chang'],\n",
       "   ['enola chivukula', 'Enola', 'enola', 'Chivukula', 'chivukula'],\n",
       "   ['caroline cierpiszewski',\n",
       "    'Caroline',\n",
       "    'caroline',\n",
       "    'Cierpiszewski',\n",
       "    'cierpiszewski'],\n",
       "   ['elijian clukey', 'Elijian', 'elijian', 'Clukey', 'clukey'],\n",
       "   ['james cockel', 'James', 'james', 'Cockel', 'cockel'],\n",
       "   ['spencer cole', 'Spencer', 'spencer', 'Cole', 'cole'],\n",
       "   ['jean crimmings', 'Jean', 'jean', 'Crimmings', 'crimmings'],\n",
       "   [\"jene'ya darson\", \"Jene'ya\", \"jene'ya\", 'Darson', 'darson'],\n",
       "   ['carl desimone', 'Carl', 'carl', 'Desimone', 'desimone'],\n",
       "   ['geoff dickinson', 'Geoff', 'geoff', 'Dickinson', 'dickinson'],\n",
       "   ['lily dinocco', 'Lily', 'lily', 'DiNocco', 'dinocco'],\n",
       "   ['denisa dobrin', 'Denisa', 'denisa', 'Dobrin', 'dobrin'],\n",
       "   ['marianne eaton', 'Marianne', 'marianne', 'Eaton', 'eaton'],\n",
       "   ['rex england', 'Rex', 'rex', 'England', 'england'],\n",
       "   ['miguel estremera', 'Miguel', 'miguel', 'Estremera', 'estremera'],\n",
       "   ['april evensen', 'April', 'april', 'Evensen', 'evensen'],\n",
       "   ['susan ferguson', 'Susan', 'susan', 'Ferguson', 'ferguson'],\n",
       "   ['nilson fernandes', 'Nilson', 'nilson', 'Fernandes', 'fernandes'],\n",
       "   ['violeta ferreira', 'Violeta', 'violeta', 'Ferreira', 'ferreira'],\n",
       "   ['libby fidelia', 'Libby', 'libby', 'Fidelia', 'fidelia'],\n",
       "   ['raul garcia', 'Raul', 'raul', 'Garcia', 'garcia'],\n",
       "   ['hamish garneau', 'Hamish', 'hamish', 'Garneau', 'garneau'],\n",
       "   ['barbara gaul', 'Barbara', 'barbara', 'Gaul', 'gaul'],\n",
       "   ['mildred gentry', 'Mildred', 'mildred', 'Gentry', 'gentry'],\n",
       "   ['melisa gerke', 'Melisa', 'melisa', 'Gerke', 'gerke'],\n",
       "   ['alex gilles', 'Alex', 'alex', 'Gilles', 'gilles'],\n",
       "   ['evelyn girifalco', 'Evelyn', 'evelyn', 'Girifalco', 'girifalco'],\n",
       "   ['shenice gold', 'Shenice', 'shenice', 'Gold', 'gold'],\n",
       "   ['roxana goyal', 'Roxana', 'roxana', 'Goyal', 'goyal'],\n",
       "   ['paula gross', 'Paula', 'paula', 'Gross', 'gross'],\n",
       "   ['joanne handschiegl', 'Joanne', 'joanne', 'Handschiegl', 'handschiegl'],\n",
       "   ['ludwick harrell', 'Ludwick', 'ludwick', 'Harrell', 'harrell'],\n",
       "   ['christie harrington', 'Christie', 'christie', 'Harrington', 'harrington'],\n",
       "   ['kara harrison', 'Kara', 'kara', 'Harrison', 'harrison'],\n",
       "   ['rose ivey', 'Rose', 'rose', 'Ivey', 'ivey'],\n",
       "   ['maryellen jackson', 'Maryellen', 'maryellen', 'Jackson', 'jackson'],\n",
       "   ['hannah jacobi', 'Hannah', 'hannah', 'Jacobi', 'jacobi'],\n",
       "   ['sneha jhaveri', 'Sneha', 'sneha', 'Jhaveri', 'jhaveri'],\n",
       "   ['judy jung', 'Judy', 'judy', 'Jung', 'jung'],\n",
       "   ['kathleen kinsella', 'Kathleen', 'kathleen', 'Kinsella', 'kinsella'],\n",
       "   ['alexandra kirill', 'Alexandra', 'alexandra', 'Kirill', 'kirill'],\n",
       "   ['bradley knapp', 'Bradley', 'bradley', 'Knapp', 'knapp'],\n",
       "   ['john kretschmer', 'John', 'john', 'Kretschmer', 'kretschmer'],\n",
       "   ['enrico langton', 'Enrico', 'enrico', 'Langton', 'langton'],\n",
       "   ['dallas leach', 'Dallas', 'dallas', 'Leach', 'leach'],\n",
       "   ['marilyn linares', 'Marilyn', 'marilyn', 'Linares', 'linares'],\n",
       "   ['allison lydon', 'Allison', 'allison', 'Lydon', 'lydon'],\n",
       "   ['lindsay lynch', 'Lindsay', 'lindsay', 'Lynch', 'lynch'],\n",
       "   ['samuel maclennan', 'Samuel', 'samuel', 'MacLennan', 'maclennan'],\n",
       "   ['lauren mahoney', 'Lauren', 'lauren', 'Mahoney', 'mahoney'],\n",
       "   ['debbie mangal', 'Debbie', 'debbie', 'Mangal', 'mangal'],\n",
       "   ['shana maurice', 'Shana', 'shana', 'Maurice', 'maurice'],\n",
       "   ['sandy mckenna', 'Sandy', 'sandy', 'Mckenna', 'mckenna'],\n",
       "   ['elizabeth meads', 'Elizabeth', 'elizabeth', 'Meads', 'meads'],\n",
       "   ['dawn motlagh', 'Dawn', 'dawn', 'Motlagh', 'motlagh'],\n",
       "   ['colombui ndzi', 'Colombui', 'colombui', 'Ndzi', 'ndzi'],\n",
       "   ['richard newman', 'Richard', 'richard', 'Newman', 'newman'],\n",
       "   ['shari ngodup', 'Shari', 'shari', 'Ngodup', 'ngodup'],\n",
       "   ['lei-ming nguyen', 'Lei-Ming', 'lei-ming', 'Nguyen', 'nguyen'],\n",
       "   [\"lynn o'hare\", 'Lynn', 'lynn', \"O'hare\", \"o'hare\"],\n",
       "   ['adeel osturnka', 'Adeel', 'adeel', 'Osturnka', 'osturnka'],\n",
       "   ['clinton owad', 'Clinton', 'clinton', 'Owad', 'owad'],\n",
       "   ['nina panjwani', 'Nina', 'nina', 'Panjwani', 'panjwani'],\n",
       "   ['emil pelech', 'Emil', 'emil', 'Pelech', 'pelech'],\n",
       "   ['shakira perry', 'Shakira', 'shakira', 'Perry', 'perry'],\n",
       "   ['hong pham', 'Hong', 'hong', 'Pham', 'pham'],\n",
       "   ['brad pitt', 'Brad', 'brad', 'Pitt', 'pitt'],\n",
       "   ['morissa power', 'Morissa', 'morissa', 'Power', 'power'],\n",
       "   ['louis punjabhi', 'Louis', 'louis', 'Punjabhi', 'punjabhi'],\n",
       "   ['janine purinton', 'Janine', 'janine', 'Purinton', 'purinton'],\n",
       "   ['quinn rarrick', 'Quinn', 'quinn', 'Rarrick', 'rarrick'],\n",
       "   ['haley rivera', 'Haley', 'haley', 'Rivera', 'rivera'],\n",
       "   ['alain robinson', 'Alain', 'alain', 'Robinson', 'robinson'],\n",
       "   ['ashley rose', 'Ashley', 'ashley', 'Rose', 'rose'],\n",
       "   ['bruno rossetti', 'Bruno', 'bruno', 'Rossetti', 'rossetti'],\n",
       "   ['melinda saar-beckles',\n",
       "    'Melinda',\n",
       "    'melinda',\n",
       "    'Saar-Beckles',\n",
       "    'saar-beckles'],\n",
       "   ['nore sadki', 'Nore', 'nore', 'Sadki', 'sadki'],\n",
       "   ['kamrin sander', 'Kamrin', 'kamrin', 'Sander', 'sander'],\n",
       "   ['nori sewkumar', 'Nori', 'nori', 'Sewkumar', 'sewkumar'],\n",
       "   ['seffi shields', 'Seffi', 'seffi', 'Shields', 'shields'],\n",
       "   ['taylor sparks', 'Taylor', 'taylor', 'Sparks', 'sparks'],\n",
       "   ['kristen squatrito', 'Kristen', 'kristen', 'Squatrito', 'squatrito'],\n",
       "   ['desiree tavares', 'Desiree', 'desiree', 'Tavares', 'tavares'],\n",
       "   ['sophia theamstern', 'Sophia', 'sophia', 'Theamstern', 'theamstern'],\n",
       "   ['theresa tinto', 'Theresa', 'theresa', 'Tinto', 'tinto'],\n",
       "   ['jeanette tippett', 'Jeanette', 'jeanette', 'Tippett', 'tippett'],\n",
       "   ['mei trang', 'Mei', 'mei', 'Trang', 'trang'],\n",
       "   ['abdellah veera', 'Abdellah', 'abdellah', 'Veera', 'veera'],\n",
       "   ['colleen volk', 'Colleen', 'colleen', 'Volk', 'volk'],\n",
       "   ['anna von massenbach', 'Anna', 'anna', 'Von', 'von'],\n",
       "   ['scott whittier', 'Scott', 'scott', 'Whittier', 'whittier'],\n",
       "   ['barry wilber', 'Barry', 'barry', 'Wilber', 'wilber'],\n",
       "   ['jacquelyn williams', 'Jacquelyn', 'jacquelyn', 'Williams', 'williams'],\n",
       "   ['catherine ybarra', 'Catherine', 'catherine', 'Ybarra', 'ybarra'],\n",
       "   ['kimberly beak', 'Kimberly', 'kimberly', 'Beak', 'beak'],\n",
       "   ['dianna blount', 'Dianna', 'dianna', 'Blount', 'blount'],\n",
       "   ['betsy bondwell', 'Betsy', 'betsy', 'Bondwell', 'bondwell'],\n",
       "   ['joseph buccheri', 'Joseph', 'joseph', 'Buccheri', 'buccheri'],\n",
       "   ['joelle burke', 'Joelle', 'joelle', 'Burke', 'burke'],\n",
       "   ['benjamin burkett', 'Benjamin', 'benjamin', 'Burkett', 'burkett'],\n",
       "   ['phil close', 'Phil', 'phil', 'Close', 'close'],\n",
       "   ['daniel davis', 'Daniel', 'daniel', 'Davis', 'davis'],\n",
       "   ['carla demita', 'Carla', 'carla', 'Demita', 'demita'],\n",
       "   ['angela erilus', 'Angela', 'angela', 'Erilus', 'erilus'],\n",
       "   ['megan faller', 'Megan', 'megan', 'Faller', 'faller'],\n",
       "   ['nicole fancett', 'Nicole', 'nicole', 'Fancett', 'fancett'],\n",
       "   ['phylicia gosciminski',\n",
       "    'Phylicia',\n",
       "    'phylicia',\n",
       "    'Gosciminski',\n",
       "    'gosciminski'],\n",
       "   ['earnest hankard', 'Earnest', 'earnest', 'Hankard', 'hankard'],\n",
       "   ['adrienne homberger', 'Adrienne', 'adrienne', 'Homberger', 'homberger'],\n",
       "   ['julissa hunts', 'Julissa', 'julissa', 'Hunts', 'hunts'],\n",
       "   ['rosalie hutter', 'Rosalie', 'rosalie', 'Hutter', 'hutter'],\n",
       "   ['ming huynh', 'Ming', 'ming', 'Huynh', 'huynh'],\n",
       "   ['tayana jeannite', 'Tayana', 'tayana', 'Jeannite', 'jeannite'],\n",
       "   ['yen johnston', 'Yen', 'yen', 'Johnston', 'johnston'],\n",
       "   ['lindsey langford', 'Lindsey', 'lindsey', 'Langford', 'langford'],\n",
       "   ['mohammed latif', 'Mohammed', 'mohammed', 'Latif', 'latif'],\n",
       "   ['mathew linden', 'Mathew', 'mathew', 'Linden', 'linden'],\n",
       "   ['robyn manchester', 'Robyn', 'robyn', 'Manchester', 'manchester'],\n",
       "   ['karen mancuso', 'Karen', 'karen', 'Mancuso', 'mancuso'],\n",
       "   ['brigit mccarthy', 'Brigit', 'brigit', 'McCarthy', 'mccarthy'],\n",
       "   ['erasumus monkfish', 'Erasumus', 'erasumus', 'Monkfish', 'monkfish'],\n",
       "   ['luisa monterro', 'Luisa', 'luisa', 'Monterro', 'monterro'],\n",
       "   ['patrick moran', 'Patrick', 'patrick', 'Moran', 'moran'],\n",
       "   ['maliki moumanil', 'Maliki', 'maliki', 'Moumanil', 'moumanil'],\n",
       "   ['kristie nowlan', 'Kristie', 'kristie', 'Nowlan', 'nowlan'],\n",
       "   ['brooke oliver', 'Brooke', 'brooke', 'Oliver', 'oliver'],\n",
       "   ['ermine pelletier', 'Ermine', 'ermine', 'Pelletier', 'pelletier'],\n",
       "   ['may roberson', 'May', 'may', 'Roberson', 'roberson'],\n",
       "   ['adil sahoo', 'Adil', 'adil', 'Sahoo', 'sahoo'],\n",
       "   ['constance sloan', 'Constance', 'constance', 'Sloan', 'sloan'],\n",
       "   ['lenora tejeda', 'Lenora', 'lenora', 'Tejeda', 'tejeda'],\n",
       "   ['kenneth thibaud', 'Kenneth', 'kenneth', 'Thibaud', 'thibaud'],\n",
       "   ['cybil trzeciak', 'Cybil', 'cybil', 'Trzeciak', 'trzeciak'],\n",
       "   ['roger walker', 'Roger', 'roger', 'Walker', 'walker'],\n",
       "   ['jordan winthrop', 'Jordan', 'jordan', 'Winthrop', 'winthrop'],\n",
       "   ['hang wolk', 'Hang', 'hang', 'Wolk', 'wolk'],\n",
       "   ['edward buck', 'Edward', 'edward', 'Buck', 'buck'],\n",
       "   ['jessica bunbury', 'Jessica', 'jessica', 'Bunbury', 'bunbury'],\n",
       "   ['michelle carter', 'Michelle', 'michelle', 'Carter', 'carter'],\n",
       "   ['latia costa', 'Latia', 'latia', 'Costa', 'costa'],\n",
       "   ['jenna dietrich', 'Jenna', 'jenna', 'Dietrich', 'dietrich'],\n",
       "   ['alfred digitale', 'Alfred', 'alfred', 'Digitale', 'digitale'],\n",
       "   ['maruk fraval', 'Maruk', 'maruk', 'Fraval', 'fraval'],\n",
       "   ['gerry friedman', 'Gerry', 'gerry', 'Friedman', 'friedman'],\n",
       "   ['whitney gill', 'Whitney', 'whitney', 'Gill', 'gill'],\n",
       "   ['myriam givens', 'Myriam', 'myriam', 'Givens', 'givens'],\n",
       "   ['mike guilianno', 'Mike', 'mike', 'Guilianno', 'guilianno'],\n",
       "   ['jeremy prater', 'Jeremy', 'jeremy', 'Prater', 'prater'],\n",
       "   ['bartholemew khemmich',\n",
       "    'Bartholemew',\n",
       "    'bartholemew',\n",
       "    'Khemmich',\n",
       "    'khemmich'],\n",
       "   ['giovanni leruth', 'Giovanni', 'giovanni', 'Leruth', 'leruth'],\n",
       "   ['jac mckinzie', 'Jac', 'jac', 'McKinzie', 'mckinzie'],\n",
       "   ['howard mullaney', 'Howard', 'howard', 'Mullaney', 'mullaney'],\n",
       "   ['jasmine onque', 'Jasmine', 'jasmine', 'Onque', 'onque'],\n",
       "   ['travis ozark', 'Travis', 'travis', 'Ozark', 'ozark'],\n",
       "   ['xana potts', 'Xana', 'xana', 'Potts', 'potts'],\n",
       "   ['caitrin strong', 'Caitrin', 'caitrin', 'Strong', 'strong'],\n",
       "   ['sharlene terry', 'Sharlene', 'sharlene', 'Terry', 'terry'],\n",
       "   ['jackie valentin', 'Jackie', 'jackie', 'Valentin', 'valentin'],\n",
       "   ['noah villanueva', 'Noah', 'noah', 'Villanueva', 'villanueva'],\n",
       "   ['debra houlihan', 'Debra', 'debra', 'Houlihan', 'houlihan'],\n",
       "   ['donysha kampew', 'Donysha', 'donysha', 'Kampew', 'kampew'],\n",
       "   ['colby andreola', 'Colby', 'colby', 'Andreola', 'andreola'],\n",
       "   ['judith carabbio', 'Judith', 'judith', 'Carabbio', 'carabbio'],\n",
       "   ['keyla del bosque', 'Keyla', 'keyla', 'Del', 'del'],\n",
       "   ['sandra martin', 'Sandra', 'sandra', 'Martin', 'martin'],\n",
       "   ['luke patronick', 'Luke', 'luke', 'Patronick', 'patronick'],\n",
       "   ['adell saada', 'Adell', 'adell', 'Saada', 'saada'],\n",
       "   ['andrew szabo', 'Andrew', 'andrew', 'Szabo', 'szabo'],\n",
       "   ['mia brown', 'Mia', 'mia', 'Brown', 'brown'],\n",
       "   ['ivan rogers', 'Ivan', 'ivan', 'Rogers', 'rogers'],\n",
       "   ['julia soto', 'Julia', 'julia', 'Soto', 'soto'],\n",
       "   ['nan singh', 'Nan', 'nan', 'Singh', 'singh']],\n",
       "  []],\n",
       " 'state': [array(['MA', 'TX', 'CT', 'VA', 'VT', 'CA', 'WA', 'NH', 'NY', 'OH', 'IN',\n",
       "         'ID', 'TN', 'NV', 'CO', 'UT', 'AL', 'GA', 'FL', 'NC', 'KY', 'ND',\n",
       "         'MT', 'OR', 'AZ', 'ME', 'RI', 'PA'], dtype=object),\n",
       "  [['Massachussets'],\n",
       "   ['Texas'],\n",
       "   ['Connecticut'],\n",
       "   ['Virginia'],\n",
       "   ['Vermony'],\n",
       "   ['California'],\n",
       "   ['Washington'],\n",
       "   ['New Hampshire'],\n",
       "   ['New York'],\n",
       "   ['Ohio'],\n",
       "   ['Indiana'],\n",
       "   ['Idaho'],\n",
       "   ['Tennessee'],\n",
       "   ['Nevada'],\n",
       "   ['Colarado'],\n",
       "   ['Utah'],\n",
       "   ['Alabama'],\n",
       "   ['Georgia'],\n",
       "   ['Florida'],\n",
       "   ['North Carolina'],\n",
       "   ['Kentucky'],\n",
       "   ['North Dakota'],\n",
       "   ['Montana'],\n",
       "   ['Oregon'],\n",
       "   ['Arizona'],\n",
       "   ['Maine'],\n",
       "   ['Rhode Island'],\n",
       "   ['Pennsylvania']],\n",
       "  ['state',\n",
       "   'state of birth',\n",
       "   'state of residence',\n",
       "   'office location',\n",
       "   'location',\n",
       "   'out of state',\n",
       "   'live',\n",
       "   'lives',\n",
       "   'live in',\n",
       "   'based in',\n",
       "   'lives in',\n",
       "   'where',\n",
       "   'works in',\n",
       "   'works at',\n",
       "   'where is',\n",
       "   'cali']],\n",
       " 'age': [['32',\n",
       "   '33',\n",
       "   '31',\n",
       "   '29',\n",
       "   '30',\n",
       "   '38',\n",
       "   '63',\n",
       "   '46',\n",
       "   '36',\n",
       "   '47',\n",
       "   '37',\n",
       "   '44',\n",
       "   '54',\n",
       "   '49',\n",
       "   '28',\n",
       "   '48',\n",
       "   '42',\n",
       "   '53',\n",
       "   '66',\n",
       "   '34',\n",
       "   '52',\n",
       "   '39',\n",
       "   '45',\n",
       "   '41',\n",
       "   '40',\n",
       "   '62',\n",
       "   '43',\n",
       "   '59',\n",
       "   '27',\n",
       "   '67',\n",
       "   '50',\n",
       "   '35',\n",
       "   '26',\n",
       "   '25',\n",
       "   '65',\n",
       "   '51',\n",
       "   '58',\n",
       "   '56',\n",
       "   '64'],\n",
       "  [['old', 'years old', 'age of', 'ages of', 'age']],\n",
       "  ['age']],\n",
       " 'sex': [['male', 'female'],\n",
       "  [['men',\n",
       "    'males',\n",
       "    'guys',\n",
       "    'dudes',\n",
       "    'gents',\n",
       "    'gentlemen',\n",
       "    'boys',\n",
       "    'boy',\n",
       "    'male'],\n",
       "   ['women',\n",
       "    'females',\n",
       "    'ladies',\n",
       "    'lady',\n",
       "    'ladys',\n",
       "    'girls',\n",
       "    'gals',\n",
       "    'woman',\n",
       "    'girl',\n",
       "    'female']],\n",
       "  ['sex',\n",
       "   'gender',\n",
       "   'masculine',\n",
       "   'feminine',\n",
       "   'male person',\n",
       "   'm/f',\n",
       "   'male/female',\n",
       "   'M/F',\n",
       "   'Male/Female']],\n",
       " 'maritaldesc': [['married', 'divorced', 'single', 'separated', 'widowed'],\n",
       "  [['wed',\n",
       "    'legally married',\n",
       "    'espoused',\n",
       "    'joined in holy matrimony',\n",
       "    'hitched'],\n",
       "   nan,\n",
       "   ['unmarried', 'bachelor', 'bachelorette'],\n",
       "   nan,\n",
       "   nan],\n",
       "  ['husbandless',\n",
       "   'without a partner',\n",
       "   'unwedded',\n",
       "   'wifeless',\n",
       "   'no longer married',\n",
       "   'without a husband',\n",
       "   'without a wife',\n",
       "   'maritaldesc',\n",
       "   'marital status',\n",
       "   'spouse',\n",
       "   'husband',\n",
       "   'wife']],\n",
       " 'citizendesc': [['us citizen', 'non citizen'],\n",
       "  [['citizen',\n",
       "    'usa citizen',\n",
       "    'american citizen',\n",
       "    'citizen of the us',\n",
       "    'citizen of America',\n",
       "    'citizen of the usa',\n",
       "    'citizens'],\n",
       "   ['non citizen',\n",
       "    'not a citizen',\n",
       "    'non us citizen',\n",
       "    'not citizens',\n",
       "    'from abroad',\n",
       "    'immigrant',\n",
       "    'immigrants',\n",
       "    'eligble non citizen',\n",
       "    'non-citizen',\n",
       "    'non-citizens']],\n",
       "  ['h1 visa',\n",
       "   'foreigner',\n",
       "   'foreign',\n",
       "   'out of country',\n",
       "   'citizenship status',\n",
       "   'citizenship']],\n",
       " 'racedesc': [['black or african american',\n",
       "   'asian',\n",
       "   'two or more races',\n",
       "   'white',\n",
       "   'hispanic',\n",
       "   'american indian or alaska native'],\n",
       "  [['black', 'african american', 'african-american'],\n",
       "   ['from asia'],\n",
       "   ['multiracial',\n",
       "    'multi-racial',\n",
       "    'mixed',\n",
       "    'mixed race',\n",
       "    'biracial',\n",
       "    'interracial'],\n",
       "   ['caucasian'],\n",
       "   ['latino'],\n",
       "   ['native',\n",
       "    'natives',\n",
       "    'indians',\n",
       "    'indian',\n",
       "    'american indian',\n",
       "    'alaska native']],\n",
       "  ['ethnicity',\n",
       "   'race',\n",
       "   'racial background',\n",
       "   'ethnic group',\n",
       "   'ethnic type',\n",
       "   'racial indentity',\n",
       "   'community',\n",
       "   'minorities']],\n",
       " 'reason_for_termination': [['return to school',\n",
       "   'another position',\n",
       "   'unhappy',\n",
       "   'military',\n",
       "   'gross misconduct',\n",
       "   'hours',\n",
       "   'medical issues',\n",
       "   'relocation out of area',\n",
       "   'more money',\n",
       "   'career change',\n",
       "   'n/a - has not started yet',\n",
       "   'retiring',\n",
       "   'n/a - still employed',\n",
       "   'attendance',\n",
       "   'no-call no-show',\n",
       "   'maternity leave - did not return',\n",
       "   'performance'],\n",
       "  [['went back to school',\n",
       "    'had to go to school again',\n",
       "    'needed to go back to school',\n",
       "    'went back to college'],\n",
       "   ['took on another job',\n",
       "    'landed a new position',\n",
       "    'changed positions',\n",
       "    'got a new position',\n",
       "    'found a new position'],\n",
       "   [\"wasn't happy\",\n",
       "    \"didn't like his job\",\n",
       "    \"didn't like her job\",\n",
       "    'hated the job',\n",
       "    'disliked the job',\n",
       "    \"didn't enjoy the job\",\n",
       "    \"didn't like his work\",\n",
       "    \"didn't like her work\"],\n",
       "   ['joined the military',\n",
       "    'went to the military',\n",
       "    'left for the military',\n",
       "    'enlisted in the military',\n",
       "    'was drafted into the military'],\n",
       "   nan,\n",
       "   nan,\n",
       "   ['got sick', 'fell sick', 'medical problems', 'sick'],\n",
       "   ['was relocated',\n",
       "    'had to relocated',\n",
       "    'was assigned to a new location',\n",
       "    'was assigned to a different location'],\n",
       "   nan,\n",
       "   ['changed careers'],\n",
       "   nan,\n",
       "   ['retired', 'went into retirement'],\n",
       "   nan,\n",
       "   ['poor attendance', 'bad attendance'],\n",
       "   nan,\n",
       "   ['did not come back from maternity leave', 'had a kid and dissapeared'],\n",
       "   ['poor performance', 'performed below expectations']],\n",
       "  []],\n",
       " 'employment_status': [['terminated for cause',\n",
       "   'leave of absence',\n",
       "   'active',\n",
       "   'voluntarily terminated',\n",
       "   'future start'],\n",
       "  [['fired', 'let go', 'evicted', 'kicked out', 'removed', 'dismissed'],\n",
       "   ['on absence leave'],\n",
       "   ['currently employed',\n",
       "    'currently working',\n",
       "    'currently works',\n",
       "    'still works at',\n",
       "    'still working at',\n",
       "    'still work at',\n",
       "    'actively employed'],\n",
       "   ['quit', 'quitted', 'resigned', 'sent in a resignation'],\n",
       "   ['will start at a future time',\n",
       "    'will start later',\n",
       "    'will start some time in the future']],\n",
       "  ['renounce', 'employment status', 'current job status']],\n",
       " 'department': [['executive office',\n",
       "   'admin offices',\n",
       "   'production',\n",
       "   'it/is',\n",
       "   'software engineering',\n",
       "   'sales'],\n",
       "  [nan,\n",
       "   ['administration',\n",
       "    'office of admin',\n",
       "    'office of administration',\n",
       "    'admin office',\n",
       "    'administration office'],\n",
       "   nan,\n",
       "   ['IT',\n",
       "    'IS',\n",
       "    'Information Technology',\n",
       "    'Information Systems',\n",
       "    'Info Tech',\n",
       "    'Info Sys'],\n",
       "   ['programming', 'coding', 'software development'],\n",
       "   nan],\n",
       "  ['department',\n",
       "   'team',\n",
       "   'group',\n",
       "   'section',\n",
       "   'division',\n",
       "   'sector',\n",
       "   'office',\n",
       "   'office group',\n",
       "   'dpt',\n",
       "   'dept',\n",
       "   'dept.',\n",
       "   'branch',\n",
       "   'organization',\n",
       "   'organisation',\n",
       "   'org',\n",
       "   'company',\n",
       "   'corporation']],\n",
       " 'position': [['it manager - infra',\n",
       "   'cio',\n",
       "   'sales manager',\n",
       "   'president & ceo',\n",
       "   'administrative assistant',\n",
       "   'database administrator',\n",
       "   'area sales manager',\n",
       "   'it director',\n",
       "   'sr. accountant',\n",
       "   'it manager - support',\n",
       "   'production technician ii',\n",
       "   'network engineer',\n",
       "   'sr. network engineer',\n",
       "   'shared services manager',\n",
       "   'accountant i',\n",
       "   'it support',\n",
       "   'software engineering manager',\n",
       "   'production technician i',\n",
       "   'director of operations',\n",
       "   'director of sales',\n",
       "   'sr. dba',\n",
       "   'it manager - db',\n",
       "   'software engineer',\n",
       "   'production manager'],\n",
       "  [nan,\n",
       "   ['chief information officer'],\n",
       "   nan,\n",
       "   ['chief executive officer',\n",
       "    'ceo',\n",
       "    'prez',\n",
       "    'president',\n",
       "    'executive',\n",
       "    'highest rank',\n",
       "    'highest ranked',\n",
       "    'CEO',\n",
       "    'highest ranking'],\n",
       "   nan,\n",
       "   ['db admin', 'db administrator', 'database admin'],\n",
       "   nan,\n",
       "   ['director of it'],\n",
       "   ['senior accountant'],\n",
       "   nan,\n",
       "   ['production technician 2', 'production technician two'],\n",
       "   nan,\n",
       "   ['senior network engineer'],\n",
       "   nan,\n",
       "   ['accountant 1', 'accountant one'],\n",
       "   ['tech support'],\n",
       "   nan,\n",
       "   ['production technician 1', 'production technician one'],\n",
       "   ['operations director'],\n",
       "   ['sales director'],\n",
       "   ['senior database administrator',\n",
       "    'senior db admin',\n",
       "    'senior db administrator'],\n",
       "   nan,\n",
       "   ['software developer', 'programmer'],\n",
       "   nan],\n",
       "  ['title',\n",
       "   'job title',\n",
       "   'role',\n",
       "   'position',\n",
       "   'level in the organization',\n",
       "   'level',\n",
       "   'job',\n",
       "   'occupation']],\n",
       " 'manager': [['manager'],\n",
       "  [['manager name',\n",
       "    'manager',\n",
       "    'incharge',\n",
       "    'supervisor',\n",
       "    'mentor',\n",
       "    'leadership',\n",
       "    'boss',\n",
       "    'management',\n",
       "    'head',\n",
       "    'lead',\n",
       "    'chairman',\n",
       "    'working for',\n",
       "    'works for',\n",
       "    'work for',\n",
       "    'manage',\n",
       "    'managed by',\n",
       "    'managing',\n",
       "    'manages',\n",
       "    'reports to',\n",
       "    'report to',\n",
       "    'reporting to',\n",
       "    'reporting',\n",
       "    'working under',\n",
       "    'is under',\n",
       "    'leads',\n",
       "    'in charge of']],\n",
       "  []],\n",
       " 'employee_source': [['information session',\n",
       "   'company intranet - partner',\n",
       "   'social networks - facebook twitter etc',\n",
       "   'newspager/magazine',\n",
       "   'internet search',\n",
       "   'billboard',\n",
       "   'pay per click',\n",
       "   'on-line web application',\n",
       "   'glassdoor',\n",
       "   'professional society',\n",
       "   'monster.com',\n",
       "   'diversity job fair',\n",
       "   'careerbuilder',\n",
       "   'mbta ads',\n",
       "   'word of mouth',\n",
       "   'other',\n",
       "   'vendor referral',\n",
       "   'on-campus recruiting',\n",
       "   'website banner ads',\n",
       "   'employee referral'],\n",
       "  [['info session'],\n",
       "   nan,\n",
       "   ['social media',\n",
       "    'social media apps',\n",
       "    'facebook',\n",
       "    'instagram',\n",
       "    'twitter',\n",
       "    'snapchat',\n",
       "    'social network'],\n",
       "   ['newspaper', 'magazine'],\n",
       "   ['google',\n",
       "    'bing',\n",
       "    'yahoo',\n",
       "    \"search engine - google bing yahoo'\",\n",
       "    'search engine'],\n",
       "   ['poster'],\n",
       "   ['ppc', 'google ads', 'google ppc', 'ppc google'],\n",
       "   ['application potal', 'job portal'],\n",
       "   ['glass door'],\n",
       "   ['professional group'],\n",
       "   ['monster'],\n",
       "   nan,\n",
       "   nan,\n",
       "   ['advertisement', 'ads'],\n",
       "   ['verbal mention'],\n",
       "   nan,\n",
       "   ['referred by vendor', 'vendor referred'],\n",
       "   ['on-campus job fair', 'career fair'],\n",
       "   nan,\n",
       "   ['referred by employee']],\n",
       "  ['how did you learn about this position',\n",
       "   'how did you find out about this job',\n",
       "   'how did you find out about this position',\n",
       "   'how did you learn about this job. how did you hear about this',\n",
       "   'heard about us',\n",
       "   'hear about us',\n",
       "   'how you heard about us',\n",
       "   'how did you hear of us',\n",
       "   'hear of us']],\n",
       " 'performance_score': [['exceptional',\n",
       "   'fully meets',\n",
       "   'n/a- too early to review',\n",
       "   'pip',\n",
       "   'needs improvement',\n",
       "   'exceeds',\n",
       "   '90-day meets'],\n",
       "  [['extraordinary'],\n",
       "   ['up to the mark', 'meet expectations', 'meet', 'meets'],\n",
       "   nan,\n",
       "   nan,\n",
       "   ['performing badly',\n",
       "    'performing below expectations',\n",
       "    'not meeting standards',\n",
       "    'not meeting expectations',\n",
       "    'poor performance',\n",
       "    'performing poorly',\n",
       "    'poorly performing',\n",
       "    'does not meet',\n",
       "    'do not meet'],\n",
       "   ['beyond expectations',\n",
       "    'more than expected',\n",
       "    'better than expected',\n",
       "    'higher than excpected',\n",
       "    'exceed expectations'],\n",
       "   nan],\n",
       "  ['performance rating',\n",
       "   'performance score',\n",
       "   'performance evaluation',\n",
       "   'performance eval',\n",
       "   'evalation',\n",
       "   'eval',\n",
       "   'performance evaluation history',\n",
       "   'performance eval history',\n",
       "   'performance',\n",
       "   'performance history',\n",
       "   'how well']],\n",
       " 'money': [['pay rate'],\n",
       "  [['salary',\n",
       "    'income',\n",
       "    'pay',\n",
       "    'earn',\n",
       "    'earnings',\n",
       "    'make',\n",
       "    'dollars',\n",
       "    '$',\n",
       "    'paycheck',\n",
       "    'earns',\n",
       "    'earning',\n",
       "    'earners',\n",
       "    'earner',\n",
       "    'incomes',\n",
       "    'paycheck',\n",
       "    'compensation']],\n",
       "  ['earns', 'makes', 'amount']],\n",
       " 'comparator': [['more than', 'equals to', 'less than', 'between'],\n",
       "  [['greater than',\n",
       "    'higher than',\n",
       "    'longer',\n",
       "    'over',\n",
       "    'older than',\n",
       "    'above',\n",
       "    'bigger than',\n",
       "    'larger than'],\n",
       "   ['is exactly', 'is equal to', 'equates to', 'equal to'],\n",
       "   ['lower than', 'below', 'under', 'fewer than', 'younger than'],\n",
       "   ['between', 'in between']],\n",
       "  []],\n",
       " 'dob': [['dob'],\n",
       "  [['birthday',\n",
       "    'birthdate',\n",
       "    'birth date',\n",
       "    'date of birth',\n",
       "    'day of birth',\n",
       "    'born on',\n",
       "    'born on the',\n",
       "    'born in',\n",
       "    'born after',\n",
       "    'born before',\n",
       "    'DOB']],\n",
       "  []],\n",
       " 'time_interval': [['2000s',\n",
       "   '2010s',\n",
       "   '1920s',\n",
       "   '1930s',\n",
       "   '1940s',\n",
       "   '1950s',\n",
       "   '1960s',\n",
       "   '1970s',\n",
       "   '1980s',\n",
       "   '1990s'],\n",
       "  [[\"00's\", \"2000's\", 'two thousands'],\n",
       "   [\"10's\", 'two thousand tens', 'tens', \"2010's\"],\n",
       "   [\"20's\", 'nineteen twenties', 'twenties', \"1920's\"],\n",
       "   [\"30's\", 'nineteen thirties', 'thirties', \"1930's\"],\n",
       "   [\"40's\", 'nineteen forties', 'forties', \"1940's\"],\n",
       "   [\"50's\", 'nineteen fifties', 'fifties', \"1950's\"],\n",
       "   [\"60's\", 'nineteen sixties', 'sixties', \"1960's\"],\n",
       "   [\"70's\", 'nineteen seventies', 'seventies', \"1970's\"],\n",
       "   [\"80's\", 'nineteen eighties', 'eighties', \"1980's\"],\n",
       "   [\"90's\", 'nineteen nineties', 'nineties', \"1990's\"]],\n",
       "  []],\n",
       " 'time_recur': [['yearly', 'monthly', 'weekly', 'daily', 'hourly'],\n",
       "  [['by the year',\n",
       "    'every year',\n",
       "    'each year',\n",
       "    'annually',\n",
       "    'on a yearly basis',\n",
       "    'per year',\n",
       "    'annual',\n",
       "    'in a year',\n",
       "    'in the year'],\n",
       "   ['by the month',\n",
       "    'every month',\n",
       "    'each month',\n",
       "    'month to month',\n",
       "    'month-to-month',\n",
       "    'on a monthly basis',\n",
       "    'per month',\n",
       "    'in a month',\n",
       "    'in the month'],\n",
       "   ['by the week',\n",
       "    'every week',\n",
       "    'each week',\n",
       "    'week by week',\n",
       "    'on a weekly basis',\n",
       "    'per week',\n",
       "    'in a week',\n",
       "    'in the week'],\n",
       "   ['daily',\n",
       "    'every day',\n",
       "    'day by day',\n",
       "    'each day',\n",
       "    'on a daily basis',\n",
       "    'per day',\n",
       "    'in a day',\n",
       "    'in the day'],\n",
       "   ['every hour',\n",
       "    'each hour',\n",
       "    'on an hourly basis',\n",
       "    'on the hour',\n",
       "    'per hour',\n",
       "    'in an hour',\n",
       "    'in  a hour',\n",
       "    'hour',\n",
       "    'in the hour']],\n",
       "  []],\n",
       " 'function': [['percent', 'sum', 'average', 'count'],\n",
       "  [['fraction',\n",
       "    'portion',\n",
       "    'proportion',\n",
       "    'percentage',\n",
       "    '%',\n",
       "    'ratio',\n",
       "    'ratios',\n",
       "    'pct',\n",
       "    'distribution'],\n",
       "   ['total',\n",
       "    'cumulative',\n",
       "    'added up',\n",
       "    'summed up',\n",
       "    'totalled',\n",
       "    'summed',\n",
       "    'combined',\n",
       "    'aggregate'],\n",
       "   ['mean', 'typical', 'typically', 'median', 'avg', 'range'],\n",
       "   ['how many', 'number', 'number of', 'num of', 'headcount', 'count of']],\n",
       "  ['turn over rate']],\n",
       " 'extreme': [['highest', 'lowest'],\n",
       "  [['top', 'maximum', 'most', 'greatest', 'max', 'oldest', 'eldest', 'latest'],\n",
       "   ['least', 'minimum', 'bottom', 'lowest', 'min', 'youngest', 'earliest']],\n",
       "  []],\n",
       " 'employment_action': [['hired', 'fired'],\n",
       "  [['employed',\n",
       "    'recruited',\n",
       "    'start date',\n",
       "    'date of starting employment',\n",
       "    'hiring date',\n",
       "    'date of hire',\n",
       "    'join',\n",
       "    'joined',\n",
       "    'date of hiring',\n",
       "    'began her employment',\n",
       "    'began his employment',\n",
       "    'started working',\n",
       "    'join date',\n",
       "    'worked here',\n",
       "    'started',\n",
       "    'been with us',\n",
       "    'began working for',\n",
       "    'started her experience',\n",
       "    'started his experience',\n",
       "    'been working here',\n",
       "    'been with the company',\n",
       "    'been here',\n",
       "    'long has worked here',\n",
       "    'years of experience',\n",
       "    'of experience',\n",
       "    'employees that have been here',\n",
       "    'working here for'],\n",
       "   ['terminated',\n",
       "    'let go',\n",
       "    'end date',\n",
       "    'date of leaving job',\n",
       "    'date of ending employment',\n",
       "    'date of termination',\n",
       "    'firing date',\n",
       "    'end employment',\n",
       "    'end his employment',\n",
       "    'end her employment',\n",
       "    'out of the company',\n",
       "    'kicked out',\n",
       "    'booted from the company',\n",
       "    'booted from the corporation']],\n",
       "  []],\n",
       " 'date_compare': [['prev', 'post'],\n",
       "  [['before', 'pre', 'prior to'],\n",
       "   ['after',\n",
       "    'last',\n",
       "    'post',\n",
       "    'this year',\n",
       "    'this month',\n",
       "    'this week',\n",
       "    'atleast',\n",
       "    'since']],\n",
       "  []]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_df = load_ent('./custom_scripts/HR Manager Schema - Entities.csv')\n",
    "ent_dict = parse_clean_ent(ent_df, uniq)\n",
    "ent_dict['name'][1] = name_syn_update(ent_dict)\n",
    "uniq = uniq_dict_update(uniq, ent_dict)\n",
    "ent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_names = pd.read_csv('./custom_scripts/baby-names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ruie',\n",
       " 'Orlena',\n",
       " 'Wayland',\n",
       " 'Ishmael',\n",
       " 'Algot',\n",
       " 'Norberto',\n",
       " 'Tina',\n",
       " 'Minta',\n",
       " 'Kailyn',\n",
       " 'Norval',\n",
       " 'Deb',\n",
       " 'Fleeta',\n",
       " 'Christy',\n",
       " 'Worth',\n",
       " 'Jacqueline',\n",
       " 'Delia',\n",
       " 'Elder',\n",
       " 'Gayla',\n",
       " 'Celestine',\n",
       " 'Karen',\n",
       " 'Heriberto',\n",
       " 'Semaj',\n",
       " 'Dennie',\n",
       " 'Madden',\n",
       " 'Tyra',\n",
       " 'Joana',\n",
       " 'Jonathon',\n",
       " 'Verl',\n",
       " 'Cordie',\n",
       " 'Denine',\n",
       " 'Shani',\n",
       " 'Lyle',\n",
       " 'Shannon',\n",
       " 'Vic',\n",
       " 'Joesph',\n",
       " 'Zeb',\n",
       " 'Flo',\n",
       " 'Tai',\n",
       " 'Frona',\n",
       " 'Anderson',\n",
       " 'Rilla',\n",
       " 'Bud',\n",
       " 'Justus',\n",
       " 'Dionte',\n",
       " 'Wilton',\n",
       " 'Dossie',\n",
       " 'Jolie',\n",
       " 'Isiah',\n",
       " 'Brigid',\n",
       " 'Letitia',\n",
       " 'Serina',\n",
       " 'Ralph',\n",
       " 'Delores',\n",
       " 'Sabra',\n",
       " 'Jace',\n",
       " 'Elonzo',\n",
       " 'Chuck',\n",
       " 'Jalynn',\n",
       " 'Terese',\n",
       " 'Shawnna',\n",
       " 'Darrian',\n",
       " 'Londyn',\n",
       " 'Ilo',\n",
       " 'Emma',\n",
       " 'Fredy',\n",
       " 'Marrion',\n",
       " 'Rolla',\n",
       " 'Giselle',\n",
       " 'Loran',\n",
       " 'Aldona',\n",
       " 'Parlee',\n",
       " 'Georgiann',\n",
       " 'Durrell',\n",
       " 'Nila',\n",
       " 'Daniella',\n",
       " 'Hector',\n",
       " 'Richard',\n",
       " 'Estell',\n",
       " 'Otis',\n",
       " 'Leonie',\n",
       " 'Friend',\n",
       " 'Dannielle',\n",
       " 'Nola',\n",
       " 'Janna',\n",
       " 'Dolph',\n",
       " 'Brittanie',\n",
       " 'Jocelyn',\n",
       " 'Deven',\n",
       " 'Yael',\n",
       " 'Altie',\n",
       " 'Madelene',\n",
       " 'Vanesa',\n",
       " 'Thurston',\n",
       " 'Alzina',\n",
       " 'Nakia',\n",
       " 'Laurie',\n",
       " 'Leitha',\n",
       " 'Jeryl',\n",
       " 'Ethyle',\n",
       " 'Liston',\n",
       " 'Leone',\n",
       " 'Ferris',\n",
       " 'Frankie',\n",
       " 'Keri',\n",
       " 'Dasia',\n",
       " 'Williard',\n",
       " 'Earnestine',\n",
       " 'Steve',\n",
       " 'Scotty',\n",
       " 'Shanon',\n",
       " 'Harlan',\n",
       " 'Vita',\n",
       " 'Marshal',\n",
       " 'Rosina',\n",
       " 'Willam',\n",
       " 'Phylis',\n",
       " 'Marguerite',\n",
       " 'Darci',\n",
       " 'Webb',\n",
       " 'Lynnette',\n",
       " 'Jeffery',\n",
       " 'Green',\n",
       " 'Rico',\n",
       " 'Corwin',\n",
       " 'Deonte',\n",
       " 'Shanika',\n",
       " 'Amare',\n",
       " 'Penelope',\n",
       " 'Shena',\n",
       " 'Brigette',\n",
       " 'Joanna',\n",
       " 'Jayleen',\n",
       " 'Skylar',\n",
       " 'Harl',\n",
       " 'Seneca',\n",
       " 'Tyesha',\n",
       " 'Letty',\n",
       " 'Jossie',\n",
       " 'Wenzel',\n",
       " 'Alvah',\n",
       " 'Armando',\n",
       " 'Neta',\n",
       " 'Mattye',\n",
       " 'Grayling',\n",
       " 'Rhett',\n",
       " 'Louis',\n",
       " 'Tobe',\n",
       " 'Napoleon',\n",
       " 'Maximilian',\n",
       " 'Henry',\n",
       " 'Annabelle',\n",
       " 'Kenley',\n",
       " 'Diana',\n",
       " 'Lionel',\n",
       " 'Juluis',\n",
       " 'North',\n",
       " 'Deidra',\n",
       " 'Collins',\n",
       " 'Elmore',\n",
       " 'Rozanne',\n",
       " 'Raven',\n",
       " 'January',\n",
       " 'Gifford',\n",
       " 'Daisie',\n",
       " 'Shelvie',\n",
       " 'Sadye',\n",
       " 'Mazie',\n",
       " 'Gidget',\n",
       " 'Matthew',\n",
       " 'Hezekiah',\n",
       " 'Sierra',\n",
       " 'Alden',\n",
       " 'Danelle',\n",
       " 'Paul',\n",
       " 'Demi',\n",
       " 'Celie',\n",
       " 'Ximena',\n",
       " 'Anice',\n",
       " 'Kash',\n",
       " 'Chantel',\n",
       " 'Caitlin',\n",
       " 'Elfrieda',\n",
       " 'Christie',\n",
       " 'Genaro',\n",
       " 'Elissa',\n",
       " 'Joella',\n",
       " 'Ula',\n",
       " 'Parley',\n",
       " 'Rogers',\n",
       " 'Osborne',\n",
       " 'Stoney',\n",
       " 'Aydan',\n",
       " 'Lindsey',\n",
       " 'Gray',\n",
       " 'Lance',\n",
       " 'Kalene',\n",
       " 'Millard',\n",
       " 'Ellison',\n",
       " 'Danielle',\n",
       " 'Aida',\n",
       " 'Lim',\n",
       " 'Debbie',\n",
       " 'Ole',\n",
       " 'Cleva',\n",
       " 'Samara',\n",
       " 'Hilmer',\n",
       " 'Pamala',\n",
       " 'Lavonda',\n",
       " 'Tammy',\n",
       " 'Acy',\n",
       " 'Creola',\n",
       " 'Indiana',\n",
       " 'Howell',\n",
       " 'Kazuo',\n",
       " 'Jorge',\n",
       " 'Annis',\n",
       " 'Juliana',\n",
       " 'Roosevelt',\n",
       " 'Esperanza',\n",
       " 'Aggie',\n",
       " 'Milton',\n",
       " 'Ena',\n",
       " 'Jajuan',\n",
       " 'Geoff',\n",
       " 'Aniyah',\n",
       " 'Jeffrey',\n",
       " 'Jacob',\n",
       " 'Osborn',\n",
       " 'Reece',\n",
       " 'Gaven',\n",
       " 'Arnett',\n",
       " 'Cleo',\n",
       " 'Shyann',\n",
       " 'Brittany',\n",
       " 'Marisela',\n",
       " 'Geneva',\n",
       " 'Okey',\n",
       " 'Lashanda',\n",
       " 'Hence',\n",
       " 'Arla',\n",
       " 'Derrek',\n",
       " 'Earlene',\n",
       " 'Gustavo',\n",
       " 'Denese',\n",
       " 'Chauncy',\n",
       " 'Anthoney',\n",
       " 'Vidal',\n",
       " 'Palmer',\n",
       " 'Misty',\n",
       " 'Lolita',\n",
       " 'Tristin',\n",
       " 'Katlynn',\n",
       " 'Ethelbert',\n",
       " 'Darrion',\n",
       " 'Liana',\n",
       " 'Benjman',\n",
       " 'Vollie',\n",
       " 'Sanjuana',\n",
       " 'Jannette',\n",
       " 'Conner',\n",
       " 'Raphael',\n",
       " 'Dylan',\n",
       " 'Red',\n",
       " 'Judah',\n",
       " 'Jordyn',\n",
       " 'Titus',\n",
       " 'Lilianna',\n",
       " 'Ahmad',\n",
       " 'Taina',\n",
       " 'Kiya',\n",
       " 'Alisson',\n",
       " 'Alycia',\n",
       " 'Vance',\n",
       " 'Cedric',\n",
       " 'Tripp',\n",
       " 'Corbin',\n",
       " 'Hiroshi',\n",
       " 'Almond',\n",
       " 'Rudolfo',\n",
       " 'Jamya',\n",
       " 'Aurelio',\n",
       " 'Karlie',\n",
       " 'Selma',\n",
       " 'Isadore',\n",
       " 'Felix',\n",
       " 'Alek',\n",
       " 'Elayne',\n",
       " 'Felice',\n",
       " 'Adilene',\n",
       " 'Tyquan',\n",
       " 'Tiffanie',\n",
       " 'Millie',\n",
       " 'Alize',\n",
       " 'Jaslene',\n",
       " 'Hermine',\n",
       " 'Stephani',\n",
       " 'Butch',\n",
       " 'Kent',\n",
       " 'Harm',\n",
       " 'Tierra',\n",
       " 'Kathyrn',\n",
       " 'Spring',\n",
       " 'Yvette',\n",
       " 'Marcela',\n",
       " 'Allene',\n",
       " 'Berkley',\n",
       " 'Louisiana',\n",
       " 'Ama',\n",
       " 'Georgie',\n",
       " 'Daisy',\n",
       " 'Dorris',\n",
       " 'Mahala',\n",
       " 'Kylah',\n",
       " 'Javier',\n",
       " 'Michelina',\n",
       " 'Fitzgerald',\n",
       " 'Brien',\n",
       " 'Donavon',\n",
       " 'Florene',\n",
       " 'Lukas',\n",
       " 'Trevon',\n",
       " 'Tosha',\n",
       " 'Eileen',\n",
       " 'Mozelle',\n",
       " 'Merle',\n",
       " 'Abdul',\n",
       " 'Rosita',\n",
       " 'Darin',\n",
       " 'Namon',\n",
       " 'Annetta',\n",
       " 'Pansy',\n",
       " 'Kennard',\n",
       " 'Lindell',\n",
       " 'Mohammad',\n",
       " 'Theda',\n",
       " 'Horace',\n",
       " 'Tracey',\n",
       " 'Corene',\n",
       " 'Marius',\n",
       " 'Faye',\n",
       " 'Alec',\n",
       " 'Cicely',\n",
       " 'Cason',\n",
       " 'Dorthy',\n",
       " 'Malcolm',\n",
       " 'Alferd',\n",
       " 'Jackeline',\n",
       " 'Chestina',\n",
       " 'Xavier',\n",
       " 'Soren',\n",
       " 'Etta',\n",
       " 'Nigel',\n",
       " 'Lavenia',\n",
       " 'Laurel',\n",
       " 'Florine',\n",
       " 'Heather',\n",
       " 'Christa',\n",
       " 'Arbie',\n",
       " 'Demian',\n",
       " 'Archie',\n",
       " 'Damion',\n",
       " 'Brock',\n",
       " 'Elizabeth',\n",
       " 'Saniyah',\n",
       " 'Rory',\n",
       " 'Eulah',\n",
       " 'Rock',\n",
       " 'Kassidy',\n",
       " 'Diann',\n",
       " 'Yaakov',\n",
       " 'Faustino',\n",
       " 'Lillard',\n",
       " 'Chancy',\n",
       " 'Toccara',\n",
       " 'Authur',\n",
       " 'Leland',\n",
       " 'Christian',\n",
       " 'Adams',\n",
       " 'Torry',\n",
       " 'Bennie',\n",
       " 'Hedwig',\n",
       " 'Miranda',\n",
       " 'Agustus',\n",
       " 'Octavia',\n",
       " 'Chaka',\n",
       " 'Basil',\n",
       " 'Jon',\n",
       " 'Collin',\n",
       " 'Deirdre',\n",
       " 'Jammie',\n",
       " 'Foy',\n",
       " 'Arnoldo',\n",
       " 'Delton',\n",
       " 'Braeden',\n",
       " 'Keith',\n",
       " 'Mario',\n",
       " 'Nelia',\n",
       " 'Yessenia',\n",
       " 'Emelia',\n",
       " 'Orlin',\n",
       " 'Kevan',\n",
       " 'Fredie',\n",
       " 'Armin',\n",
       " 'Jadon',\n",
       " 'Raynard',\n",
       " 'Jameel',\n",
       " 'Bronson',\n",
       " 'Laurence',\n",
       " 'Ressie',\n",
       " 'Almeta',\n",
       " 'Scottie',\n",
       " 'Wayde',\n",
       " 'Davian',\n",
       " 'Jan',\n",
       " 'Jolene',\n",
       " 'Clora',\n",
       " 'Roswell',\n",
       " 'Martine',\n",
       " 'Meghan',\n",
       " 'Maud',\n",
       " 'Governor',\n",
       " 'Taurean',\n",
       " 'Wilford',\n",
       " 'Cleon',\n",
       " 'Rebecca',\n",
       " 'Renae',\n",
       " 'Hayleigh',\n",
       " 'Cherrelle',\n",
       " 'Finn',\n",
       " 'Ida',\n",
       " 'Allena',\n",
       " 'Taft',\n",
       " 'Sloane',\n",
       " 'Samir',\n",
       " 'Shad',\n",
       " 'Arvo',\n",
       " 'Darryl',\n",
       " 'Coy',\n",
       " 'Zack',\n",
       " 'Ruth',\n",
       " 'Hughes',\n",
       " 'Fonda',\n",
       " 'Jared',\n",
       " 'Gina',\n",
       " 'Johny',\n",
       " 'Leilani',\n",
       " 'Britni',\n",
       " 'Cressie',\n",
       " 'Kirby',\n",
       " 'Kendal',\n",
       " 'Rosie',\n",
       " 'Johnna',\n",
       " 'Humphrey',\n",
       " 'Kendell',\n",
       " 'Hazelle',\n",
       " 'Odelia',\n",
       " 'Annamarie',\n",
       " 'Mervin',\n",
       " 'Chaney',\n",
       " 'Kourtney',\n",
       " 'Kathern',\n",
       " 'Keanu',\n",
       " 'Eathel',\n",
       " 'Malissie',\n",
       " 'Barbra',\n",
       " 'Gust',\n",
       " 'Olivine',\n",
       " 'Zeta',\n",
       " 'Griffith',\n",
       " 'Mikel',\n",
       " 'Gasper',\n",
       " 'Aliyah',\n",
       " 'Price',\n",
       " 'Damien',\n",
       " 'Gaige',\n",
       " 'Shelba',\n",
       " 'Melton',\n",
       " 'Jovanny',\n",
       " 'Rueben',\n",
       " 'Donie',\n",
       " 'Evangeline',\n",
       " 'Mara',\n",
       " 'Nathaly',\n",
       " 'Crista',\n",
       " 'Christ',\n",
       " 'Alvaro',\n",
       " 'Nick',\n",
       " 'Hobson',\n",
       " 'Mac',\n",
       " 'Oliva',\n",
       " 'Charlotta',\n",
       " 'Roddy',\n",
       " 'Beula',\n",
       " 'Dedrick',\n",
       " 'Haywood',\n",
       " 'Prudie',\n",
       " 'Melisa',\n",
       " 'Arline',\n",
       " 'Lakisha',\n",
       " 'Lavelle',\n",
       " 'Clay',\n",
       " 'Merlene',\n",
       " 'Carleigh',\n",
       " 'Cristi',\n",
       " 'Litzy',\n",
       " 'Lelia',\n",
       " 'Lolla',\n",
       " 'Fronnie',\n",
       " 'Ashlea',\n",
       " 'Delano',\n",
       " 'Toya',\n",
       " 'Verona',\n",
       " 'Brandee',\n",
       " 'Graydon',\n",
       " 'Hershel',\n",
       " 'Edson',\n",
       " 'Constantine',\n",
       " 'Artie',\n",
       " 'Aden',\n",
       " 'Kandace',\n",
       " 'Cristine',\n",
       " 'Pratt',\n",
       " 'Anjali',\n",
       " 'Mabell',\n",
       " 'Verna',\n",
       " 'Iyana',\n",
       " 'Evan',\n",
       " 'Rosalind',\n",
       " 'Gloria',\n",
       " 'Mahalia',\n",
       " 'Thos',\n",
       " 'Belia',\n",
       " 'Niki',\n",
       " 'Curtis',\n",
       " 'Audrianna',\n",
       " 'Rianna',\n",
       " 'Lota',\n",
       " 'Maxwell',\n",
       " 'Shaniece',\n",
       " 'Trish',\n",
       " 'Ambers',\n",
       " 'Hedy',\n",
       " 'Bert',\n",
       " 'Agness',\n",
       " 'Jesenia',\n",
       " 'Brianna',\n",
       " 'Michell',\n",
       " 'Joanie',\n",
       " 'Ava',\n",
       " 'Sienna',\n",
       " 'Tim',\n",
       " 'Lilla',\n",
       " 'Margery',\n",
       " 'Chase',\n",
       " 'Alvin',\n",
       " 'Leonidas',\n",
       " 'Jarrett',\n",
       " 'Dollie',\n",
       " 'Kaye',\n",
       " 'Mae',\n",
       " 'Nicklaus',\n",
       " 'Winford',\n",
       " 'Dallin',\n",
       " 'Lovie',\n",
       " 'Clemie',\n",
       " 'Carli',\n",
       " 'Ninnie',\n",
       " 'Shenna',\n",
       " 'Clella',\n",
       " 'Garnet',\n",
       " 'Ardelia',\n",
       " 'Irvine',\n",
       " 'Brogan',\n",
       " 'Victory',\n",
       " 'Dulce',\n",
       " 'Barry',\n",
       " 'Maryam',\n",
       " 'Kami',\n",
       " 'Prince',\n",
       " 'Mildred',\n",
       " 'Raquel',\n",
       " 'Nanie',\n",
       " 'Miles',\n",
       " 'Anabella',\n",
       " 'Keon',\n",
       " 'Emanuel',\n",
       " 'Sabina',\n",
       " 'Maleah',\n",
       " 'Arlin',\n",
       " 'Kya',\n",
       " 'Claudette',\n",
       " 'Ronan',\n",
       " 'Sean',\n",
       " 'Coleman',\n",
       " 'Nancie',\n",
       " 'Ovila',\n",
       " 'Derek',\n",
       " 'Albertine',\n",
       " 'Lamont',\n",
       " 'Kellie',\n",
       " 'Matthias',\n",
       " 'Joselyn',\n",
       " 'Berton',\n",
       " 'Omar',\n",
       " 'Novella',\n",
       " 'Savannah',\n",
       " 'Bob',\n",
       " 'Lorena',\n",
       " 'Glinda',\n",
       " 'Danial',\n",
       " 'Leonardo',\n",
       " 'Paola',\n",
       " 'Brett',\n",
       " 'Latosha',\n",
       " 'Will',\n",
       " 'Larry',\n",
       " 'Otha',\n",
       " 'Aarav',\n",
       " 'Alline',\n",
       " 'Starling',\n",
       " 'Mozell',\n",
       " 'Zina',\n",
       " 'Marshall',\n",
       " 'Hymen',\n",
       " 'Letta',\n",
       " 'Macie',\n",
       " 'Adelyn',\n",
       " 'Reba',\n",
       " 'Omer',\n",
       " 'Young',\n",
       " 'Wynona',\n",
       " 'Josef',\n",
       " 'Ryker',\n",
       " 'Jeana',\n",
       " 'Anfernee',\n",
       " 'Rosamond',\n",
       " 'Kesha',\n",
       " 'Juliann',\n",
       " 'Eleonora',\n",
       " 'Nikki',\n",
       " 'Barron',\n",
       " 'Crystal',\n",
       " 'Hilton',\n",
       " 'Neola',\n",
       " 'Buell',\n",
       " 'Nasir',\n",
       " 'Rachel',\n",
       " 'Bethel',\n",
       " 'Nova',\n",
       " 'Rozella',\n",
       " 'Journey',\n",
       " 'Colten',\n",
       " 'Elroy',\n",
       " 'Nevaeh',\n",
       " 'Clydie',\n",
       " 'Madilynn',\n",
       " 'Verner',\n",
       " 'Babyboy',\n",
       " 'Dena',\n",
       " 'Colleen',\n",
       " 'Osvaldo',\n",
       " 'Kandy',\n",
       " 'Caleigh',\n",
       " 'Nickolas',\n",
       " 'Welton',\n",
       " 'Juan',\n",
       " 'Masao',\n",
       " 'Norman',\n",
       " 'Dellia',\n",
       " 'Webster',\n",
       " 'Ford',\n",
       " 'Althea',\n",
       " 'Deanna',\n",
       " 'Zona',\n",
       " 'Nile',\n",
       " 'Lex',\n",
       " 'Cass',\n",
       " 'Mariyah',\n",
       " 'Warner',\n",
       " 'Virgel',\n",
       " 'Consuela',\n",
       " 'Alaina',\n",
       " 'Cinnamon',\n",
       " 'Dianne',\n",
       " 'Raheem',\n",
       " 'Geraldo',\n",
       " 'Montana',\n",
       " 'Minoru',\n",
       " 'Sharla',\n",
       " 'Hanna',\n",
       " 'Rena',\n",
       " 'Porsha',\n",
       " 'Coraima',\n",
       " 'Wyatt',\n",
       " 'Meadow',\n",
       " 'Abram',\n",
       " 'Alabama',\n",
       " 'Anibal',\n",
       " 'Sergio',\n",
       " 'Alayna',\n",
       " 'Carson',\n",
       " 'Rayshawn',\n",
       " 'Davie',\n",
       " 'Almus',\n",
       " 'Brinda',\n",
       " 'Fernando',\n",
       " 'Sheryll',\n",
       " 'Joann',\n",
       " 'Maverick',\n",
       " 'Alby',\n",
       " 'Adin',\n",
       " 'Hayden',\n",
       " 'Jameson',\n",
       " 'Lexis',\n",
       " 'Keagan',\n",
       " 'Nikia',\n",
       " 'Dicy',\n",
       " 'Shirleyann',\n",
       " 'Benjiman',\n",
       " 'Derrell',\n",
       " 'Lita',\n",
       " 'Kegan',\n",
       " 'Sada',\n",
       " 'Verda',\n",
       " 'Patric',\n",
       " 'Aydin',\n",
       " 'Carley',\n",
       " 'Tenisha',\n",
       " 'Dante',\n",
       " 'Bjorn',\n",
       " 'Mona',\n",
       " 'Cristina',\n",
       " 'Davonte',\n",
       " 'Layla',\n",
       " 'Doc',\n",
       " 'Lenna',\n",
       " 'Orion',\n",
       " 'Leesa',\n",
       " 'Lafayette',\n",
       " 'Waylon',\n",
       " 'Winter',\n",
       " 'Rustin',\n",
       " 'Elzada',\n",
       " 'Rashawn',\n",
       " 'Hellen',\n",
       " 'Rosemarie',\n",
       " 'Kem',\n",
       " 'Maudie',\n",
       " 'Tanika',\n",
       " 'Leatha',\n",
       " 'Breonna',\n",
       " 'Clayton',\n",
       " 'Jaymes',\n",
       " 'Estela',\n",
       " 'Ismael',\n",
       " 'Marcia',\n",
       " 'Domenick',\n",
       " 'Hal',\n",
       " 'Vicente',\n",
       " 'Harlie',\n",
       " 'Ashleigh',\n",
       " 'Durward',\n",
       " 'Louella',\n",
       " 'Shaquita',\n",
       " 'Brantley',\n",
       " 'Karla',\n",
       " 'Uriah',\n",
       " 'Brennan',\n",
       " 'Venus',\n",
       " 'Elvia',\n",
       " 'Konnor',\n",
       " 'Shaquana',\n",
       " 'Maude',\n",
       " 'Kiley',\n",
       " 'Vernice',\n",
       " 'Benny',\n",
       " 'Nakisha',\n",
       " 'Kelli',\n",
       " 'Toby',\n",
       " 'Warren',\n",
       " 'Bama',\n",
       " 'Silvio',\n",
       " 'Collier',\n",
       " 'Nyasia',\n",
       " 'Dillard',\n",
       " 'Yesenia',\n",
       " 'Amey',\n",
       " 'Vernell',\n",
       " 'Rayne',\n",
       " 'Jeanne',\n",
       " 'Antionette',\n",
       " 'Aurthur',\n",
       " 'Anissa',\n",
       " 'Solon',\n",
       " 'Destinee',\n",
       " 'Mills',\n",
       " 'Yaritza',\n",
       " 'Machelle',\n",
       " 'Savon',\n",
       " 'Gaines',\n",
       " 'Zoe',\n",
       " 'Genevieve',\n",
       " 'Charlie',\n",
       " 'Connor',\n",
       " 'India',\n",
       " 'Angelica',\n",
       " 'Emilee',\n",
       " 'Pierre',\n",
       " 'Clarissa',\n",
       " 'Jefferson',\n",
       " 'Graves',\n",
       " 'Kaci',\n",
       " 'Clarke',\n",
       " 'Eartha',\n",
       " 'Kade',\n",
       " 'Lark',\n",
       " 'Abe',\n",
       " 'Mamie',\n",
       " 'Charly',\n",
       " 'Cyrus',\n",
       " 'Lue',\n",
       " 'Breanna',\n",
       " 'Lydia',\n",
       " 'Ova',\n",
       " 'Axel',\n",
       " 'Demarcus',\n",
       " 'Chanel',\n",
       " 'Bee',\n",
       " 'Mertie',\n",
       " 'Zechariah',\n",
       " 'Djuna',\n",
       " 'Almedia',\n",
       " 'Jodie',\n",
       " 'Savion',\n",
       " 'Kate',\n",
       " 'Unknown',\n",
       " 'Sherilyn',\n",
       " 'Izaiah',\n",
       " 'Charlsie',\n",
       " 'Estel',\n",
       " 'Shelli',\n",
       " 'Renada',\n",
       " 'Bettylou',\n",
       " 'Ayden',\n",
       " 'Donny',\n",
       " 'Launa',\n",
       " 'Boston',\n",
       " 'Jamison',\n",
       " 'Joseluis',\n",
       " 'Stanford',\n",
       " 'Tex',\n",
       " 'Darlene',\n",
       " 'Elodie',\n",
       " 'Whitley',\n",
       " 'Lonie',\n",
       " 'Julia',\n",
       " 'Gerardo',\n",
       " 'Hallie',\n",
       " 'Fannie',\n",
       " 'Raul',\n",
       " 'Maddison',\n",
       " 'Darcie',\n",
       " 'Ashby',\n",
       " 'Hung',\n",
       " 'Uriel',\n",
       " 'Julian',\n",
       " 'Darien',\n",
       " 'Anatole',\n",
       " 'Adan',\n",
       " 'Corinna',\n",
       " 'Tevin',\n",
       " 'Dariana',\n",
       " 'Rome',\n",
       " 'Gianna',\n",
       " 'Ezequiel',\n",
       " 'Thornton',\n",
       " 'Sheilah',\n",
       " 'Georgianna',\n",
       " 'Lucie',\n",
       " 'Carra',\n",
       " 'Betty',\n",
       " 'Quinn',\n",
       " 'Ima',\n",
       " 'Lanie',\n",
       " 'Alexandria',\n",
       " 'Malaya',\n",
       " 'Genesis',\n",
       " 'Angeles',\n",
       " 'Mal',\n",
       " 'Hayward',\n",
       " 'Jasiah',\n",
       " 'Alda',\n",
       " 'Carmine',\n",
       " 'Laurine',\n",
       " 'Tiney',\n",
       " 'Waldo',\n",
       " 'Bernice',\n",
       " 'Ronal',\n",
       " 'Rufus',\n",
       " 'Evie',\n",
       " 'Deric',\n",
       " 'Sabrina',\n",
       " 'Martha',\n",
       " 'Johnny',\n",
       " 'Cathi',\n",
       " 'Paityn',\n",
       " 'Merlin',\n",
       " 'Krish',\n",
       " 'Ryleigh',\n",
       " 'Mckenzie',\n",
       " 'Shakira',\n",
       " 'Latanya',\n",
       " 'Timmie',\n",
       " 'Krysten',\n",
       " 'Lorin',\n",
       " 'Roberta',\n",
       " 'Inez',\n",
       " 'Timothy',\n",
       " 'Dirk',\n",
       " 'Lilie',\n",
       " 'Yoshio',\n",
       " 'Sallie',\n",
       " 'Emmit',\n",
       " 'Chelsea',\n",
       " 'Garey',\n",
       " 'Lisette',\n",
       " 'Clementina',\n",
       " 'Dominque',\n",
       " 'Rod',\n",
       " 'Jakayla',\n",
       " 'Norton',\n",
       " 'Jake',\n",
       " 'Shirlie',\n",
       " 'Tarsha',\n",
       " 'Signa',\n",
       " 'Dorsey',\n",
       " 'Schuyler',\n",
       " 'Arba',\n",
       " 'Kerwin',\n",
       " 'Sincere',\n",
       " 'Odus',\n",
       " 'Cleta',\n",
       " 'Carlee',\n",
       " 'Sky',\n",
       " 'Ozell',\n",
       " 'Olen',\n",
       " 'Iola',\n",
       " 'Kwame',\n",
       " 'Raymon',\n",
       " 'Jemal',\n",
       " 'Trenton',\n",
       " 'Eldora',\n",
       " 'Eura',\n",
       " 'Noelia',\n",
       " 'Lavern',\n",
       " 'Alston',\n",
       " 'Hortensia',\n",
       " 'Camren',\n",
       " 'Virgia',\n",
       " 'Sanai',\n",
       " 'Karter',\n",
       " 'Deante',\n",
       " 'Gaylord',\n",
       " 'Darion',\n",
       " 'Jaylan',\n",
       " 'Jose',\n",
       " 'Baldwin',\n",
       " 'Dorene',\n",
       " 'Eben',\n",
       " 'Twila',\n",
       " 'Laila',\n",
       " 'Alexandr',\n",
       " 'Dion',\n",
       " 'Owens',\n",
       " 'Kimber',\n",
       " 'Bryn',\n",
       " 'Cena',\n",
       " 'Kermit',\n",
       " 'Carri',\n",
       " 'Ewart',\n",
       " 'Immanuel',\n",
       " 'Emmanuel',\n",
       " 'Coolidge',\n",
       " 'Bode',\n",
       " 'Audry',\n",
       " 'Irene',\n",
       " 'York',\n",
       " 'Rhona',\n",
       " 'Andres',\n",
       " 'Sinda',\n",
       " 'Gaither',\n",
       " 'Lise',\n",
       " 'Rita',\n",
       " 'Linus',\n",
       " 'Dewayne',\n",
       " 'Felicia',\n",
       " 'Naima',\n",
       " 'Dahlia',\n",
       " 'Paulette',\n",
       " 'Marcellus',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baby_names = list(set(baby_names['name']))\n",
    "baby_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['William LaRotonda',\n",
       " 'Tyrone Steans',\n",
       " 'Estelle Howard',\n",
       " 'Leigh Smith',\n",
       " 'Brandon LeBlanc',\n",
       " 'Sean Quinn',\n",
       " 'Bonalyn Boutwell',\n",
       " 'Amy Foster-Baker',\n",
       " 'Janet King',\n",
       " 'Jennifer Zamora',\n",
       " 'Renee Becker',\n",
       " 'Taisha Goble',\n",
       " 'Daniff Hernandez',\n",
       " 'Jayne Horton',\n",
       " 'Noelle Johnson',\n",
       " 'Thomas Murray',\n",
       " 'Randall Pearson',\n",
       " 'Thelma Petrowsky',\n",
       " 'Lori Roby',\n",
       " 'Jason Salter',\n",
       " 'Kramer Simard',\n",
       " 'Simon Roup',\n",
       " 'Ricardo Ruiz',\n",
       " 'Peter Monroe',\n",
       " 'Eric Dougall',\n",
       " 'Rick Clayton',\n",
       " 'Lisa Galia',\n",
       " 'Leonara Lindsay',\n",
       " 'Alejandro Bacong',\n",
       " 'Anthony Cisco',\n",
       " 'Linda Dolan',\n",
       " 'Maria Gonzalez',\n",
       " 'Carlos Merlos',\n",
       " 'Tanya Morway',\n",
       " 'Anita Shepard',\n",
       " 'Neville Tredinnick',\n",
       " 'Jumil Turpin',\n",
       " 'Karthikeyan Ait Sidi',\n",
       " 'Claudia Carr',\n",
       " 'Donald Favis',\n",
       " 'Bianca Roehrich',\n",
       " 'Ann Daniele',\n",
       " 'Jyoti Lajiri',\n",
       " 'Jeremiah Semizoglou',\n",
       " 'Joe South',\n",
       " 'Sarah Warfield',\n",
       " 'Elisa Bramante',\n",
       " 'Michael Albert',\n",
       " 'Charles Bozzi',\n",
       " 'Webster Butler',\n",
       " 'Elijiah Gray',\n",
       " 'Jonathan Hogland',\n",
       " 'Walter Immediato',\n",
       " 'Ketsia Liebig',\n",
       " 'Brannon Miller',\n",
       " 'Ebonee Peterson',\n",
       " 'Kelley Spirea',\n",
       " 'David Stanley',\n",
       " 'Kissy Sullivan',\n",
       " 'Courtney Wallace',\n",
       " 'Wilson Adinolfi',\n",
       " 'Trina Alagbe',\n",
       " 'Carol Anderson',\n",
       " 'Sam Athwal',\n",
       " 'Rachael Baczenski',\n",
       " 'Francesco Barone',\n",
       " 'Nader Barton',\n",
       " 'Lowan Biden',\n",
       " 'Helen Billis',\n",
       " 'Donna Brill',\n",
       " 'Josephine Bugali',\n",
       " 'Beatrice Chace',\n",
       " 'Lin Chan',\n",
       " 'Donovan Chang',\n",
       " 'Enola Chivukula',\n",
       " 'Caroline Cierpiszewski',\n",
       " 'Elijian Clukey',\n",
       " 'James Cockel',\n",
       " 'Spencer Cole',\n",
       " 'Jean Crimmings',\n",
       " \"Jene'ya Darson\",\n",
       " 'Carl Desimone',\n",
       " 'Geoff Dickinson',\n",
       " 'Lily DiNocco',\n",
       " 'Denisa Dobrin',\n",
       " 'Marianne Eaton',\n",
       " 'Rex England',\n",
       " 'Miguel Estremera',\n",
       " 'April Evensen',\n",
       " 'Susan Ferguson',\n",
       " 'Nilson Fernandes',\n",
       " 'Violeta Ferreira',\n",
       " 'Libby Fidelia',\n",
       " 'Raul Garcia',\n",
       " 'Hamish Garneau',\n",
       " 'Barbara Gaul',\n",
       " 'Mildred Gentry',\n",
       " 'Melisa Gerke',\n",
       " 'Alex Gilles',\n",
       " 'Evelyn Girifalco',\n",
       " 'Shenice Gold',\n",
       " 'Roxana Goyal',\n",
       " 'Paula Gross',\n",
       " 'Joanne Handschiegl',\n",
       " 'Ludwick Harrell',\n",
       " 'Christie Harrington',\n",
       " 'Kara Harrison',\n",
       " 'Rose Ivey',\n",
       " 'Maryellen Jackson',\n",
       " 'Hannah Jacobi',\n",
       " 'Sneha Jhaveri',\n",
       " 'Judy Jung',\n",
       " 'Kathleen Kinsella',\n",
       " 'Alexandra Kirill',\n",
       " 'Bradley Knapp',\n",
       " 'John Kretschmer',\n",
       " 'Enrico Langton',\n",
       " 'Dallas Leach',\n",
       " 'Marilyn Linares',\n",
       " 'Allison Lydon',\n",
       " 'Lindsay Lynch',\n",
       " 'Samuel MacLennan',\n",
       " 'Lauren Mahoney',\n",
       " 'Debbie Mangal',\n",
       " 'Shana Maurice',\n",
       " 'Sandy Mckenna',\n",
       " 'Elizabeth Meads',\n",
       " 'Dawn Motlagh',\n",
       " 'Colombui Ndzi',\n",
       " 'Richard Newman',\n",
       " 'Shari Ngodup',\n",
       " 'Lei-Ming Nguyen',\n",
       " \"Lynn O'hare\",\n",
       " 'Adeel Osturnka',\n",
       " 'Clinton Owad',\n",
       " 'Nina Panjwani',\n",
       " 'Emil Pelech',\n",
       " 'Shakira Perry',\n",
       " 'Hong Pham',\n",
       " 'Brad Pitt',\n",
       " 'Morissa Power',\n",
       " 'Louis Punjabhi',\n",
       " 'Janine Purinton',\n",
       " 'Quinn Rarrick',\n",
       " 'Haley Rivera',\n",
       " 'Alain Robinson',\n",
       " 'Ashley Rose',\n",
       " 'Bruno Rossetti',\n",
       " 'Melinda Saar-Beckles',\n",
       " 'Nore Sadki',\n",
       " 'Kamrin Sander',\n",
       " 'Nori Sewkumar',\n",
       " 'Seffi Shields',\n",
       " 'Taylor Sparks',\n",
       " 'Kristen Squatrito',\n",
       " 'Desiree Tavares',\n",
       " 'Sophia Theamstern',\n",
       " 'Theresa Tinto',\n",
       " 'Jeanette Tippett',\n",
       " 'Mei Trang',\n",
       " 'Abdellah Veera',\n",
       " 'Colleen Volk',\n",
       " 'Anna Von Massenbach',\n",
       " 'Scott Whittier',\n",
       " 'Barry Wilber',\n",
       " 'Jacquelyn Williams',\n",
       " 'Catherine Ybarra',\n",
       " 'Kimberly Beak',\n",
       " 'Dianna Blount',\n",
       " 'Betsy Bondwell',\n",
       " 'Joseph Buccheri',\n",
       " 'Joelle Burke',\n",
       " 'Benjamin Burkett',\n",
       " 'Phil Close',\n",
       " 'Daniel Davis',\n",
       " 'Carla Demita',\n",
       " 'Angela Erilus',\n",
       " 'Megan Faller',\n",
       " 'Nicole Fancett',\n",
       " 'Phylicia Gosciminski',\n",
       " 'Earnest Hankard',\n",
       " 'Adrienne Homberger',\n",
       " 'Julissa Hunts',\n",
       " 'Rosalie Hutter',\n",
       " 'Ming Huynh',\n",
       " 'Tayana Jeannite',\n",
       " 'Yen Johnston',\n",
       " 'Lindsey Langford',\n",
       " 'Mohammed Latif',\n",
       " 'Mathew Linden',\n",
       " 'Robyn Manchester',\n",
       " 'Karen Mancuso',\n",
       " 'Brigit McCarthy',\n",
       " 'Erasumus Monkfish',\n",
       " 'Luisa Monterro',\n",
       " 'Patrick Moran',\n",
       " 'Maliki Moumanil',\n",
       " 'Kristie Nowlan',\n",
       " 'Brooke Oliver',\n",
       " 'Ermine Pelletier',\n",
       " 'May Roberson',\n",
       " 'Adil Sahoo',\n",
       " 'Constance Sloan',\n",
       " 'Lenora Tejeda',\n",
       " 'Kenneth Thibaud',\n",
       " 'Cybil Trzeciak',\n",
       " 'Roger Walker',\n",
       " 'Jordan Winthrop',\n",
       " 'Hang Wolk',\n",
       " 'Edward Buck',\n",
       " 'Jessica Bunbury',\n",
       " 'Michelle Carter',\n",
       " 'Latia Costa',\n",
       " 'Jenna Dietrich',\n",
       " 'Alfred Digitale',\n",
       " 'Maruk Fraval',\n",
       " 'Gerry Friedman',\n",
       " 'Whitney Gill',\n",
       " 'Myriam Givens',\n",
       " 'Mike Guilianno',\n",
       " 'Jeremy Prater',\n",
       " 'Bartholemew Khemmich',\n",
       " 'Giovanni Leruth',\n",
       " 'Jac McKinzie',\n",
       " 'Howard Mullaney',\n",
       " 'Jasmine Onque',\n",
       " 'Travis Ozark',\n",
       " 'Xana Potts',\n",
       " 'Caitrin Strong',\n",
       " 'Sharlene Terry',\n",
       " 'Jackie Valentin',\n",
       " 'Noah Villanueva',\n",
       " 'Debra Houlihan',\n",
       " 'Donysha Kampew',\n",
       " 'Colby Andreola',\n",
       " 'Judith Carabbio',\n",
       " 'Keyla Del Bosque',\n",
       " 'Sandra Martin',\n",
       " 'Luke Patronick',\n",
       " 'Adell Saada',\n",
       " 'Andrew Szabo',\n",
       " 'Mia Brown',\n",
       " 'Ivan Rogers',\n",
       " 'Julia Soto',\n",
       " 'Nan Singh',\n",
       " '']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ec375edbb1b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muniq_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muniq_first\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0muniq_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "uniq_first = []\n",
    "names = list(uniq['name'])\n",
    "for name in names: uniq_first.append(name.split()[0].lower())\n",
    "uniq_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': [['William LaRotonda',\n",
       "   'Tyrone Steans',\n",
       "   'Estelle Howard',\n",
       "   'Leigh Smith',\n",
       "   'Brandon LeBlanc',\n",
       "   'Sean Quinn',\n",
       "   'Bonalyn Boutwell',\n",
       "   'Amy Foster-Baker',\n",
       "   'Janet King',\n",
       "   'Jennifer Zamora',\n",
       "   'Renee Becker',\n",
       "   'Taisha Goble',\n",
       "   'Daniff Hernandez',\n",
       "   'Jayne Horton',\n",
       "   'Noelle Johnson',\n",
       "   'Thomas Murray',\n",
       "   'Randall Pearson',\n",
       "   'Thelma Petrowsky',\n",
       "   'Lori Roby',\n",
       "   'Jason Salter',\n",
       "   'Kramer Simard',\n",
       "   'Simon Roup',\n",
       "   'Ricardo Ruiz',\n",
       "   'Peter Monroe',\n",
       "   'Eric Dougall',\n",
       "   'Rick Clayton',\n",
       "   'Lisa Galia',\n",
       "   'Leonara Lindsay',\n",
       "   'Alejandro Bacong',\n",
       "   'Anthony Cisco',\n",
       "   'Linda Dolan',\n",
       "   'Maria Gonzalez',\n",
       "   'Carlos Merlos',\n",
       "   'Tanya Morway',\n",
       "   'Anita Shepard',\n",
       "   'Neville Tredinnick',\n",
       "   'Jumil Turpin',\n",
       "   'Karthikeyan Ait Sidi',\n",
       "   'Claudia Carr',\n",
       "   'Donald Favis',\n",
       "   'Bianca Roehrich',\n",
       "   'Ann Daniele',\n",
       "   'Jyoti Lajiri',\n",
       "   'Jeremiah Semizoglou',\n",
       "   'Joe South',\n",
       "   'Sarah Warfield',\n",
       "   'Elisa Bramante',\n",
       "   'Michael Albert',\n",
       "   'Charles Bozzi',\n",
       "   'Webster Butler',\n",
       "   'Elijiah Gray',\n",
       "   'Jonathan Hogland',\n",
       "   'Walter Immediato',\n",
       "   'Ketsia Liebig',\n",
       "   'Brannon Miller',\n",
       "   'Ebonee Peterson',\n",
       "   'Kelley Spirea',\n",
       "   'David Stanley',\n",
       "   'Kissy Sullivan',\n",
       "   'Courtney Wallace',\n",
       "   'Wilson Adinolfi',\n",
       "   'Trina Alagbe',\n",
       "   'Carol Anderson',\n",
       "   'Sam Athwal',\n",
       "   'Rachael Baczenski',\n",
       "   'Francesco Barone',\n",
       "   'Nader Barton',\n",
       "   'Lowan Biden',\n",
       "   'Helen Billis',\n",
       "   'Donna Brill',\n",
       "   'Josephine Bugali',\n",
       "   'Beatrice Chace',\n",
       "   'Lin Chan',\n",
       "   'Donovan Chang',\n",
       "   'Enola Chivukula',\n",
       "   'Caroline Cierpiszewski',\n",
       "   'Elijian Clukey',\n",
       "   'James Cockel',\n",
       "   'Spencer Cole',\n",
       "   'Jean Crimmings',\n",
       "   \"Jene'ya Darson\",\n",
       "   'Carl Desimone',\n",
       "   'Geoff Dickinson',\n",
       "   'Lily DiNocco',\n",
       "   'Denisa Dobrin',\n",
       "   'Marianne Eaton',\n",
       "   'Rex England',\n",
       "   'Miguel Estremera',\n",
       "   'April Evensen',\n",
       "   'Susan Ferguson',\n",
       "   'Nilson Fernandes',\n",
       "   'Violeta Ferreira',\n",
       "   'Libby Fidelia',\n",
       "   'Raul Garcia',\n",
       "   'Hamish Garneau',\n",
       "   'Barbara Gaul',\n",
       "   'Mildred Gentry',\n",
       "   'Melisa Gerke',\n",
       "   'Alex Gilles',\n",
       "   'Evelyn Girifalco',\n",
       "   'Shenice Gold',\n",
       "   'Roxana Goyal',\n",
       "   'Paula Gross',\n",
       "   'Joanne Handschiegl',\n",
       "   'Ludwick Harrell',\n",
       "   'Christie Harrington',\n",
       "   'Kara Harrison',\n",
       "   'Rose Ivey',\n",
       "   'Maryellen Jackson',\n",
       "   'Hannah Jacobi',\n",
       "   'Sneha Jhaveri',\n",
       "   'Judy Jung',\n",
       "   'Kathleen Kinsella',\n",
       "   'Alexandra Kirill',\n",
       "   'Bradley Knapp',\n",
       "   'John Kretschmer',\n",
       "   'Enrico Langton',\n",
       "   'Dallas Leach',\n",
       "   'Marilyn Linares',\n",
       "   'Allison Lydon',\n",
       "   'Lindsay Lynch',\n",
       "   'Samuel MacLennan',\n",
       "   'Lauren Mahoney',\n",
       "   'Debbie Mangal',\n",
       "   'Shana Maurice',\n",
       "   'Sandy Mckenna',\n",
       "   'Elizabeth Meads',\n",
       "   'Dawn Motlagh',\n",
       "   'Colombui Ndzi',\n",
       "   'Richard Newman',\n",
       "   'Shari Ngodup',\n",
       "   'Lei-Ming Nguyen',\n",
       "   \"Lynn O'hare\",\n",
       "   'Adeel Osturnka',\n",
       "   'Clinton Owad',\n",
       "   'Nina Panjwani',\n",
       "   'Emil Pelech',\n",
       "   'Shakira Perry',\n",
       "   'Hong Pham',\n",
       "   'Brad Pitt',\n",
       "   'Morissa Power',\n",
       "   'Louis Punjabhi',\n",
       "   'Janine Purinton',\n",
       "   'Quinn Rarrick',\n",
       "   'Haley Rivera',\n",
       "   'Alain Robinson',\n",
       "   'Ashley Rose',\n",
       "   'Bruno Rossetti',\n",
       "   'Melinda Saar-Beckles',\n",
       "   'Nore Sadki',\n",
       "   'Kamrin Sander',\n",
       "   'Nori Sewkumar',\n",
       "   'Seffi Shields',\n",
       "   'Taylor Sparks',\n",
       "   'Kristen Squatrito',\n",
       "   'Desiree Tavares',\n",
       "   'Sophia Theamstern',\n",
       "   'Theresa Tinto',\n",
       "   'Jeanette Tippett',\n",
       "   'Mei Trang',\n",
       "   'Abdellah Veera',\n",
       "   'Colleen Volk',\n",
       "   'Anna Von Massenbach',\n",
       "   'Scott Whittier',\n",
       "   'Barry Wilber',\n",
       "   'Jacquelyn Williams',\n",
       "   'Catherine Ybarra',\n",
       "   'Kimberly Beak',\n",
       "   'Dianna Blount',\n",
       "   'Betsy Bondwell',\n",
       "   'Joseph Buccheri',\n",
       "   'Joelle Burke',\n",
       "   'Benjamin Burkett',\n",
       "   'Phil Close',\n",
       "   'Daniel Davis',\n",
       "   'Carla Demita',\n",
       "   'Angela Erilus',\n",
       "   'Megan Faller',\n",
       "   'Nicole Fancett',\n",
       "   'Phylicia Gosciminski',\n",
       "   'Earnest Hankard',\n",
       "   'Adrienne Homberger',\n",
       "   'Julissa Hunts',\n",
       "   'Rosalie Hutter',\n",
       "   'Ming Huynh',\n",
       "   'Tayana Jeannite',\n",
       "   'Yen Johnston',\n",
       "   'Lindsey Langford',\n",
       "   'Mohammed Latif',\n",
       "   'Mathew Linden',\n",
       "   'Robyn Manchester',\n",
       "   'Karen Mancuso',\n",
       "   'Brigit McCarthy',\n",
       "   'Erasumus Monkfish',\n",
       "   'Luisa Monterro',\n",
       "   'Patrick Moran',\n",
       "   'Maliki Moumanil',\n",
       "   'Kristie Nowlan',\n",
       "   'Brooke Oliver',\n",
       "   'Ermine Pelletier',\n",
       "   'May Roberson',\n",
       "   'Adil Sahoo',\n",
       "   'Constance Sloan',\n",
       "   'Lenora Tejeda',\n",
       "   'Kenneth Thibaud',\n",
       "   'Cybil Trzeciak',\n",
       "   'Roger Walker',\n",
       "   'Jordan Winthrop',\n",
       "   'Hang Wolk',\n",
       "   'Edward Buck',\n",
       "   'Jessica Bunbury',\n",
       "   'Michelle Carter',\n",
       "   'Latia Costa',\n",
       "   'Jenna Dietrich',\n",
       "   'Alfred Digitale',\n",
       "   'Maruk Fraval',\n",
       "   'Gerry Friedman',\n",
       "   'Whitney Gill',\n",
       "   'Myriam Givens',\n",
       "   'Mike Guilianno',\n",
       "   'Jeremy Prater',\n",
       "   'Bartholemew Khemmich',\n",
       "   'Giovanni Leruth',\n",
       "   'Jac McKinzie',\n",
       "   'Howard Mullaney',\n",
       "   'Jasmine Onque',\n",
       "   'Travis Ozark',\n",
       "   'Xana Potts',\n",
       "   'Caitrin Strong',\n",
       "   'Sharlene Terry',\n",
       "   'Jackie Valentin',\n",
       "   'Noah Villanueva',\n",
       "   'Debra Houlihan',\n",
       "   'Donysha Kampew',\n",
       "   'Colby Andreola',\n",
       "   'Judith Carabbio',\n",
       "   'Keyla Del Bosque',\n",
       "   'Sandra Martin',\n",
       "   'Luke Patronick',\n",
       "   'Adell Saada',\n",
       "   'Andrew Szabo',\n",
       "   'Mia Brown',\n",
       "   'Ivan Rogers',\n",
       "   'Julia Soto',\n",
       "   'Nan Singh',\n",
       "   ''],\n",
       "  [['william larotonda', 'William', 'william', 'LaRotonda', 'larotonda'],\n",
       "   ['tyrone steans', 'Tyrone', 'tyrone', 'Steans', 'steans'],\n",
       "   ['estelle howard', 'Estelle', 'estelle', 'Howard', 'howard'],\n",
       "   ['leigh smith', 'Leigh', 'leigh', 'Smith', 'smith'],\n",
       "   ['brandon leblanc', 'Brandon', 'brandon', 'LeBlanc', 'leblanc'],\n",
       "   ['sean quinn', 'Sean', 'sean', 'Quinn', 'quinn'],\n",
       "   ['bonalyn boutwell', 'Bonalyn', 'bonalyn', 'Boutwell', 'boutwell'],\n",
       "   ['amy foster-baker', 'Amy', 'amy', 'Foster-Baker', 'foster-baker'],\n",
       "   ['janet king', 'Janet', 'janet', 'King', 'king'],\n",
       "   ['jennifer zamora', 'Jennifer', 'jennifer', 'Zamora', 'zamora'],\n",
       "   ['renee becker', 'Renee', 'renee', 'Becker', 'becker'],\n",
       "   ['taisha goble', 'Taisha', 'taisha', 'Goble', 'goble'],\n",
       "   ['daniff hernandez', 'Daniff', 'daniff', 'Hernandez', 'hernandez'],\n",
       "   ['jayne horton', 'Jayne', 'jayne', 'Horton', 'horton'],\n",
       "   ['noelle johnson', 'Noelle', 'noelle', 'Johnson', 'johnson'],\n",
       "   ['thomas murray', 'Thomas', 'thomas', 'Murray', 'murray'],\n",
       "   ['randall pearson', 'Randall', 'randall', 'Pearson', 'pearson'],\n",
       "   ['thelma petrowsky', 'Thelma', 'thelma', 'Petrowsky', 'petrowsky'],\n",
       "   ['lori roby', 'Lori', 'lori', 'Roby', 'roby'],\n",
       "   ['jason salter', 'Jason', 'jason', 'Salter', 'salter'],\n",
       "   ['kramer simard', 'Kramer', 'kramer', 'Simard', 'simard'],\n",
       "   ['simon roup', 'Simon', 'simon', 'Roup', 'roup'],\n",
       "   ['ricardo ruiz', 'Ricardo', 'ricardo', 'Ruiz', 'ruiz'],\n",
       "   ['peter monroe', 'Peter', 'peter', 'Monroe', 'monroe'],\n",
       "   ['eric dougall', 'Eric', 'eric', 'Dougall', 'dougall'],\n",
       "   ['rick clayton', 'Rick', 'rick', 'Clayton', 'clayton'],\n",
       "   ['lisa galia', 'Lisa', 'lisa', 'Galia', 'galia'],\n",
       "   ['leonara lindsay', 'Leonara', 'leonara', 'Lindsay', 'lindsay'],\n",
       "   ['alejandro bacong', 'Alejandro', 'alejandro', 'Bacong', 'bacong'],\n",
       "   ['anthony cisco', 'Anthony', 'anthony', 'Cisco', 'cisco'],\n",
       "   ['linda dolan', 'Linda', 'linda', 'Dolan', 'dolan'],\n",
       "   ['maria gonzalez', 'Maria', 'maria', 'Gonzalez', 'gonzalez'],\n",
       "   ['carlos merlos', 'Carlos', 'carlos', 'Merlos', 'merlos'],\n",
       "   ['tanya morway', 'Tanya', 'tanya', 'Morway', 'morway'],\n",
       "   ['anita shepard', 'Anita', 'anita', 'Shepard', 'shepard'],\n",
       "   ['neville tredinnick', 'Neville', 'neville', 'Tredinnick', 'tredinnick'],\n",
       "   ['jumil turpin', 'Jumil', 'jumil', 'Turpin', 'turpin'],\n",
       "   ['karthikeyan ait sidi', 'Karthikeyan', 'karthikeyan', 'Ait', 'ait'],\n",
       "   ['claudia carr', 'Claudia', 'claudia', 'Carr', 'carr'],\n",
       "   ['donald favis', 'Donald', 'donald', 'Favis', 'favis'],\n",
       "   ['bianca roehrich', 'Bianca', 'bianca', 'Roehrich', 'roehrich'],\n",
       "   ['ann daniele', 'Ann', 'ann', 'Daniele', 'daniele'],\n",
       "   ['jyoti lajiri', 'Jyoti', 'jyoti', 'Lajiri', 'lajiri'],\n",
       "   ['jeremiah semizoglou', 'Jeremiah', 'jeremiah', 'Semizoglou', 'semizoglou'],\n",
       "   ['joe south', 'Joe', 'joe', 'South', 'south'],\n",
       "   ['sarah warfield', 'Sarah', 'sarah', 'Warfield', 'warfield'],\n",
       "   ['elisa bramante', 'Elisa', 'elisa', 'Bramante', 'bramante'],\n",
       "   ['michael albert', 'Michael', 'michael', 'Albert', 'albert'],\n",
       "   ['charles bozzi', 'Charles', 'charles', 'Bozzi', 'bozzi'],\n",
       "   ['webster butler', 'Webster', 'webster', 'Butler', 'butler'],\n",
       "   ['elijiah gray', 'Elijiah', 'elijiah', 'Gray', 'gray'],\n",
       "   ['jonathan hogland', 'Jonathan', 'jonathan', 'Hogland', 'hogland'],\n",
       "   ['walter immediato', 'Walter', 'walter', 'Immediato', 'immediato'],\n",
       "   ['ketsia liebig', 'Ketsia', 'ketsia', 'Liebig', 'liebig'],\n",
       "   ['brannon miller', 'Brannon', 'brannon', 'Miller', 'miller'],\n",
       "   ['ebonee peterson', 'Ebonee', 'ebonee', 'Peterson', 'peterson'],\n",
       "   ['kelley spirea', 'Kelley', 'kelley', 'Spirea', 'spirea'],\n",
       "   ['david stanley', 'David', 'david', 'Stanley', 'stanley'],\n",
       "   ['kissy sullivan', 'Kissy', 'kissy', 'Sullivan', 'sullivan'],\n",
       "   ['courtney wallace', 'Courtney', 'courtney', 'Wallace', 'wallace'],\n",
       "   ['wilson adinolfi', 'Wilson', 'wilson', 'Adinolfi', 'adinolfi'],\n",
       "   ['trina alagbe', 'Trina', 'trina', 'Alagbe', 'alagbe'],\n",
       "   ['carol anderson', 'Carol', 'carol', 'Anderson', 'anderson'],\n",
       "   ['sam athwal', 'Sam', 'sam', 'Athwal', 'athwal'],\n",
       "   ['rachael baczenski', 'Rachael', 'rachael', 'Baczenski', 'baczenski'],\n",
       "   ['francesco barone', 'Francesco', 'francesco', 'Barone', 'barone'],\n",
       "   ['nader barton', 'Nader', 'nader', 'Barton', 'barton'],\n",
       "   ['lowan biden', 'Lowan', 'lowan', 'Biden', 'biden'],\n",
       "   ['helen billis', 'Helen', 'helen', 'Billis', 'billis'],\n",
       "   ['donna brill', 'Donna', 'donna', 'Brill', 'brill'],\n",
       "   ['josephine bugali', 'Josephine', 'josephine', 'Bugali', 'bugali'],\n",
       "   ['beatrice chace', 'Beatrice', 'beatrice', 'Chace', 'chace'],\n",
       "   ['lin chan', 'Lin', 'lin', 'Chan', 'chan'],\n",
       "   ['donovan chang', 'Donovan', 'donovan', 'Chang', 'chang'],\n",
       "   ['enola chivukula', 'Enola', 'enola', 'Chivukula', 'chivukula'],\n",
       "   ['caroline cierpiszewski',\n",
       "    'Caroline',\n",
       "    'caroline',\n",
       "    'Cierpiszewski',\n",
       "    'cierpiszewski'],\n",
       "   ['elijian clukey', 'Elijian', 'elijian', 'Clukey', 'clukey'],\n",
       "   ['james cockel', 'James', 'james', 'Cockel', 'cockel'],\n",
       "   ['spencer cole', 'Spencer', 'spencer', 'Cole', 'cole'],\n",
       "   ['jean crimmings', 'Jean', 'jean', 'Crimmings', 'crimmings'],\n",
       "   [\"jene'ya darson\", \"Jene'ya\", \"jene'ya\", 'Darson', 'darson'],\n",
       "   ['carl desimone', 'Carl', 'carl', 'Desimone', 'desimone'],\n",
       "   ['geoff dickinson', 'Geoff', 'geoff', 'Dickinson', 'dickinson'],\n",
       "   ['lily dinocco', 'Lily', 'lily', 'DiNocco', 'dinocco'],\n",
       "   ['denisa dobrin', 'Denisa', 'denisa', 'Dobrin', 'dobrin'],\n",
       "   ['marianne eaton', 'Marianne', 'marianne', 'Eaton', 'eaton'],\n",
       "   ['rex england', 'Rex', 'rex', 'England', 'england'],\n",
       "   ['miguel estremera', 'Miguel', 'miguel', 'Estremera', 'estremera'],\n",
       "   ['april evensen', 'April', 'april', 'Evensen', 'evensen'],\n",
       "   ['susan ferguson', 'Susan', 'susan', 'Ferguson', 'ferguson'],\n",
       "   ['nilson fernandes', 'Nilson', 'nilson', 'Fernandes', 'fernandes'],\n",
       "   ['violeta ferreira', 'Violeta', 'violeta', 'Ferreira', 'ferreira'],\n",
       "   ['libby fidelia', 'Libby', 'libby', 'Fidelia', 'fidelia'],\n",
       "   ['raul garcia', 'Raul', 'raul', 'Garcia', 'garcia'],\n",
       "   ['hamish garneau', 'Hamish', 'hamish', 'Garneau', 'garneau'],\n",
       "   ['barbara gaul', 'Barbara', 'barbara', 'Gaul', 'gaul'],\n",
       "   ['mildred gentry', 'Mildred', 'mildred', 'Gentry', 'gentry'],\n",
       "   ['melisa gerke', 'Melisa', 'melisa', 'Gerke', 'gerke'],\n",
       "   ['alex gilles', 'Alex', 'alex', 'Gilles', 'gilles'],\n",
       "   ['evelyn girifalco', 'Evelyn', 'evelyn', 'Girifalco', 'girifalco'],\n",
       "   ['shenice gold', 'Shenice', 'shenice', 'Gold', 'gold'],\n",
       "   ['roxana goyal', 'Roxana', 'roxana', 'Goyal', 'goyal'],\n",
       "   ['paula gross', 'Paula', 'paula', 'Gross', 'gross'],\n",
       "   ['joanne handschiegl', 'Joanne', 'joanne', 'Handschiegl', 'handschiegl'],\n",
       "   ['ludwick harrell', 'Ludwick', 'ludwick', 'Harrell', 'harrell'],\n",
       "   ['christie harrington', 'Christie', 'christie', 'Harrington', 'harrington'],\n",
       "   ['kara harrison', 'Kara', 'kara', 'Harrison', 'harrison'],\n",
       "   ['rose ivey', 'Rose', 'rose', 'Ivey', 'ivey'],\n",
       "   ['maryellen jackson', 'Maryellen', 'maryellen', 'Jackson', 'jackson'],\n",
       "   ['hannah jacobi', 'Hannah', 'hannah', 'Jacobi', 'jacobi'],\n",
       "   ['sneha jhaveri', 'Sneha', 'sneha', 'Jhaveri', 'jhaveri'],\n",
       "   ['judy jung', 'Judy', 'judy', 'Jung', 'jung'],\n",
       "   ['kathleen kinsella', 'Kathleen', 'kathleen', 'Kinsella', 'kinsella'],\n",
       "   ['alexandra kirill', 'Alexandra', 'alexandra', 'Kirill', 'kirill'],\n",
       "   ['bradley knapp', 'Bradley', 'bradley', 'Knapp', 'knapp'],\n",
       "   ['john kretschmer', 'John', 'john', 'Kretschmer', 'kretschmer'],\n",
       "   ['enrico langton', 'Enrico', 'enrico', 'Langton', 'langton'],\n",
       "   ['dallas leach', 'Dallas', 'dallas', 'Leach', 'leach'],\n",
       "   ['marilyn linares', 'Marilyn', 'marilyn', 'Linares', 'linares'],\n",
       "   ['allison lydon', 'Allison', 'allison', 'Lydon', 'lydon'],\n",
       "   ['lindsay lynch', 'Lindsay', 'lindsay', 'Lynch', 'lynch'],\n",
       "   ['samuel maclennan', 'Samuel', 'samuel', 'MacLennan', 'maclennan'],\n",
       "   ['lauren mahoney', 'Lauren', 'lauren', 'Mahoney', 'mahoney'],\n",
       "   ['debbie mangal', 'Debbie', 'debbie', 'Mangal', 'mangal'],\n",
       "   ['shana maurice', 'Shana', 'shana', 'Maurice', 'maurice'],\n",
       "   ['sandy mckenna', 'Sandy', 'sandy', 'Mckenna', 'mckenna'],\n",
       "   ['elizabeth meads', 'Elizabeth', 'elizabeth', 'Meads', 'meads'],\n",
       "   ['dawn motlagh', 'Dawn', 'dawn', 'Motlagh', 'motlagh'],\n",
       "   ['colombui ndzi', 'Colombui', 'colombui', 'Ndzi', 'ndzi'],\n",
       "   ['richard newman', 'Richard', 'richard', 'Newman', 'newman'],\n",
       "   ['shari ngodup', 'Shari', 'shari', 'Ngodup', 'ngodup'],\n",
       "   ['lei-ming nguyen', 'Lei-Ming', 'lei-ming', 'Nguyen', 'nguyen'],\n",
       "   [\"lynn o'hare\", 'Lynn', 'lynn', \"O'hare\", \"o'hare\"],\n",
       "   ['adeel osturnka', 'Adeel', 'adeel', 'Osturnka', 'osturnka'],\n",
       "   ['clinton owad', 'Clinton', 'clinton', 'Owad', 'owad'],\n",
       "   ['nina panjwani', 'Nina', 'nina', 'Panjwani', 'panjwani'],\n",
       "   ['emil pelech', 'Emil', 'emil', 'Pelech', 'pelech'],\n",
       "   ['shakira perry', 'Shakira', 'shakira', 'Perry', 'perry'],\n",
       "   ['hong pham', 'Hong', 'hong', 'Pham', 'pham'],\n",
       "   ['brad pitt', 'Brad', 'brad', 'Pitt', 'pitt'],\n",
       "   ['morissa power', 'Morissa', 'morissa', 'Power', 'power'],\n",
       "   ['louis punjabhi', 'Louis', 'louis', 'Punjabhi', 'punjabhi'],\n",
       "   ['janine purinton', 'Janine', 'janine', 'Purinton', 'purinton'],\n",
       "   ['quinn rarrick', 'Quinn', 'quinn', 'Rarrick', 'rarrick'],\n",
       "   ['haley rivera', 'Haley', 'haley', 'Rivera', 'rivera'],\n",
       "   ['alain robinson', 'Alain', 'alain', 'Robinson', 'robinson'],\n",
       "   ['ashley rose', 'Ashley', 'ashley', 'Rose', 'rose'],\n",
       "   ['bruno rossetti', 'Bruno', 'bruno', 'Rossetti', 'rossetti'],\n",
       "   ['melinda saar-beckles',\n",
       "    'Melinda',\n",
       "    'melinda',\n",
       "    'Saar-Beckles',\n",
       "    'saar-beckles'],\n",
       "   ['nore sadki', 'Nore', 'nore', 'Sadki', 'sadki'],\n",
       "   ['kamrin sander', 'Kamrin', 'kamrin', 'Sander', 'sander'],\n",
       "   ['nori sewkumar', 'Nori', 'nori', 'Sewkumar', 'sewkumar'],\n",
       "   ['seffi shields', 'Seffi', 'seffi', 'Shields', 'shields'],\n",
       "   ['taylor sparks', 'Taylor', 'taylor', 'Sparks', 'sparks'],\n",
       "   ['kristen squatrito', 'Kristen', 'kristen', 'Squatrito', 'squatrito'],\n",
       "   ['desiree tavares', 'Desiree', 'desiree', 'Tavares', 'tavares'],\n",
       "   ['sophia theamstern', 'Sophia', 'sophia', 'Theamstern', 'theamstern'],\n",
       "   ['theresa tinto', 'Theresa', 'theresa', 'Tinto', 'tinto'],\n",
       "   ['jeanette tippett', 'Jeanette', 'jeanette', 'Tippett', 'tippett'],\n",
       "   ['mei trang', 'Mei', 'mei', 'Trang', 'trang'],\n",
       "   ['abdellah veera', 'Abdellah', 'abdellah', 'Veera', 'veera'],\n",
       "   ['colleen volk', 'Colleen', 'colleen', 'Volk', 'volk'],\n",
       "   ['anna von massenbach', 'Anna', 'anna', 'Von', 'von'],\n",
       "   ['scott whittier', 'Scott', 'scott', 'Whittier', 'whittier'],\n",
       "   ['barry wilber', 'Barry', 'barry', 'Wilber', 'wilber'],\n",
       "   ['jacquelyn williams', 'Jacquelyn', 'jacquelyn', 'Williams', 'williams'],\n",
       "   ['catherine ybarra', 'Catherine', 'catherine', 'Ybarra', 'ybarra'],\n",
       "   ['kimberly beak', 'Kimberly', 'kimberly', 'Beak', 'beak'],\n",
       "   ['dianna blount', 'Dianna', 'dianna', 'Blount', 'blount'],\n",
       "   ['betsy bondwell', 'Betsy', 'betsy', 'Bondwell', 'bondwell'],\n",
       "   ['joseph buccheri', 'Joseph', 'joseph', 'Buccheri', 'buccheri'],\n",
       "   ['joelle burke', 'Joelle', 'joelle', 'Burke', 'burke'],\n",
       "   ['benjamin burkett', 'Benjamin', 'benjamin', 'Burkett', 'burkett'],\n",
       "   ['phil close', 'Phil', 'phil', 'Close', 'close'],\n",
       "   ['daniel davis', 'Daniel', 'daniel', 'Davis', 'davis'],\n",
       "   ['carla demita', 'Carla', 'carla', 'Demita', 'demita'],\n",
       "   ['angela erilus', 'Angela', 'angela', 'Erilus', 'erilus'],\n",
       "   ['megan faller', 'Megan', 'megan', 'Faller', 'faller'],\n",
       "   ['nicole fancett', 'Nicole', 'nicole', 'Fancett', 'fancett'],\n",
       "   ['phylicia gosciminski',\n",
       "    'Phylicia',\n",
       "    'phylicia',\n",
       "    'Gosciminski',\n",
       "    'gosciminski'],\n",
       "   ['earnest hankard', 'Earnest', 'earnest', 'Hankard', 'hankard'],\n",
       "   ['adrienne homberger', 'Adrienne', 'adrienne', 'Homberger', 'homberger'],\n",
       "   ['julissa hunts', 'Julissa', 'julissa', 'Hunts', 'hunts'],\n",
       "   ['rosalie hutter', 'Rosalie', 'rosalie', 'Hutter', 'hutter'],\n",
       "   ['ming huynh', 'Ming', 'ming', 'Huynh', 'huynh'],\n",
       "   ['tayana jeannite', 'Tayana', 'tayana', 'Jeannite', 'jeannite'],\n",
       "   ['yen johnston', 'Yen', 'yen', 'Johnston', 'johnston'],\n",
       "   ['lindsey langford', 'Lindsey', 'lindsey', 'Langford', 'langford'],\n",
       "   ['mohammed latif', 'Mohammed', 'mohammed', 'Latif', 'latif'],\n",
       "   ['mathew linden', 'Mathew', 'mathew', 'Linden', 'linden'],\n",
       "   ['robyn manchester', 'Robyn', 'robyn', 'Manchester', 'manchester'],\n",
       "   ['karen mancuso', 'Karen', 'karen', 'Mancuso', 'mancuso'],\n",
       "   ['brigit mccarthy', 'Brigit', 'brigit', 'McCarthy', 'mccarthy'],\n",
       "   ['erasumus monkfish', 'Erasumus', 'erasumus', 'Monkfish', 'monkfish'],\n",
       "   ['luisa monterro', 'Luisa', 'luisa', 'Monterro', 'monterro'],\n",
       "   ['patrick moran', 'Patrick', 'patrick', 'Moran', 'moran'],\n",
       "   ['maliki moumanil', 'Maliki', 'maliki', 'Moumanil', 'moumanil'],\n",
       "   ['kristie nowlan', 'Kristie', 'kristie', 'Nowlan', 'nowlan'],\n",
       "   ['brooke oliver', 'Brooke', 'brooke', 'Oliver', 'oliver'],\n",
       "   ['ermine pelletier', 'Ermine', 'ermine', 'Pelletier', 'pelletier'],\n",
       "   ['may roberson', 'May', 'may', 'Roberson', 'roberson'],\n",
       "   ['adil sahoo', 'Adil', 'adil', 'Sahoo', 'sahoo'],\n",
       "   ['constance sloan', 'Constance', 'constance', 'Sloan', 'sloan'],\n",
       "   ['lenora tejeda', 'Lenora', 'lenora', 'Tejeda', 'tejeda'],\n",
       "   ['kenneth thibaud', 'Kenneth', 'kenneth', 'Thibaud', 'thibaud'],\n",
       "   ['cybil trzeciak', 'Cybil', 'cybil', 'Trzeciak', 'trzeciak'],\n",
       "   ['roger walker', 'Roger', 'roger', 'Walker', 'walker'],\n",
       "   ['jordan winthrop', 'Jordan', 'jordan', 'Winthrop', 'winthrop'],\n",
       "   ['hang wolk', 'Hang', 'hang', 'Wolk', 'wolk'],\n",
       "   ['edward buck', 'Edward', 'edward', 'Buck', 'buck'],\n",
       "   ['jessica bunbury', 'Jessica', 'jessica', 'Bunbury', 'bunbury'],\n",
       "   ['michelle carter', 'Michelle', 'michelle', 'Carter', 'carter'],\n",
       "   ['latia costa', 'Latia', 'latia', 'Costa', 'costa'],\n",
       "   ['jenna dietrich', 'Jenna', 'jenna', 'Dietrich', 'dietrich'],\n",
       "   ['alfred digitale', 'Alfred', 'alfred', 'Digitale', 'digitale'],\n",
       "   ['maruk fraval', 'Maruk', 'maruk', 'Fraval', 'fraval'],\n",
       "   ['gerry friedman', 'Gerry', 'gerry', 'Friedman', 'friedman'],\n",
       "   ['whitney gill', 'Whitney', 'whitney', 'Gill', 'gill'],\n",
       "   ['myriam givens', 'Myriam', 'myriam', 'Givens', 'givens'],\n",
       "   ['mike guilianno', 'Mike', 'mike', 'Guilianno', 'guilianno'],\n",
       "   ['jeremy prater', 'Jeremy', 'jeremy', 'Prater', 'prater'],\n",
       "   ['bartholemew khemmich',\n",
       "    'Bartholemew',\n",
       "    'bartholemew',\n",
       "    'Khemmich',\n",
       "    'khemmich'],\n",
       "   ['giovanni leruth', 'Giovanni', 'giovanni', 'Leruth', 'leruth'],\n",
       "   ['jac mckinzie', 'Jac', 'jac', 'McKinzie', 'mckinzie'],\n",
       "   ['howard mullaney', 'Howard', 'howard', 'Mullaney', 'mullaney'],\n",
       "   ['jasmine onque', 'Jasmine', 'jasmine', 'Onque', 'onque'],\n",
       "   ['travis ozark', 'Travis', 'travis', 'Ozark', 'ozark'],\n",
       "   ['xana potts', 'Xana', 'xana', 'Potts', 'potts'],\n",
       "   ['caitrin strong', 'Caitrin', 'caitrin', 'Strong', 'strong'],\n",
       "   ['sharlene terry', 'Sharlene', 'sharlene', 'Terry', 'terry'],\n",
       "   ['jackie valentin', 'Jackie', 'jackie', 'Valentin', 'valentin'],\n",
       "   ['noah villanueva', 'Noah', 'noah', 'Villanueva', 'villanueva'],\n",
       "   ['debra houlihan', 'Debra', 'debra', 'Houlihan', 'houlihan'],\n",
       "   ['donysha kampew', 'Donysha', 'donysha', 'Kampew', 'kampew'],\n",
       "   ['colby andreola', 'Colby', 'colby', 'Andreola', 'andreola'],\n",
       "   ['judith carabbio', 'Judith', 'judith', 'Carabbio', 'carabbio'],\n",
       "   ['keyla del bosque', 'Keyla', 'keyla', 'Del', 'del'],\n",
       "   ['sandra martin', 'Sandra', 'sandra', 'Martin', 'martin'],\n",
       "   ['luke patronick', 'Luke', 'luke', 'Patronick', 'patronick'],\n",
       "   ['adell saada', 'Adell', 'adell', 'Saada', 'saada'],\n",
       "   ['andrew szabo', 'Andrew', 'andrew', 'Szabo', 'szabo'],\n",
       "   ['mia brown', 'Mia', 'mia', 'Brown', 'brown'],\n",
       "   ['ivan rogers', 'Ivan', 'ivan', 'Rogers', 'rogers'],\n",
       "   ['julia soto', 'Julia', 'julia', 'Soto', 'soto'],\n",
       "   ['nan singh', 'Nan', 'nan', 'Singh', 'singh']],\n",
       "  []],\n",
       " 'state': [array(['MA', 'TX', 'CT', 'VA', 'VT', 'CA', 'WA', 'NH', 'NY', 'OH', 'IN',\n",
       "         'ID', 'TN', 'NV', 'CO', 'UT', 'AL', 'GA', 'FL', 'NC', 'KY', 'ND',\n",
       "         'MT', 'OR', 'AZ', 'ME', 'RI', 'PA'], dtype=object),\n",
       "  [['Massachussets'],\n",
       "   ['Texas'],\n",
       "   ['Connecticut'],\n",
       "   ['Virginia'],\n",
       "   ['Vermony'],\n",
       "   ['California'],\n",
       "   ['Washington'],\n",
       "   ['New Hampshire'],\n",
       "   ['New York'],\n",
       "   ['Ohio'],\n",
       "   ['Indiana'],\n",
       "   ['Idaho'],\n",
       "   ['Tennessee'],\n",
       "   ['Nevada'],\n",
       "   ['Colarado'],\n",
       "   ['Utah'],\n",
       "   ['Alabama'],\n",
       "   ['Georgia'],\n",
       "   ['Florida'],\n",
       "   ['North Carolina'],\n",
       "   ['Kentucky'],\n",
       "   ['North Dakota'],\n",
       "   ['Montana'],\n",
       "   ['Oregon'],\n",
       "   ['Arizona'],\n",
       "   ['Maine'],\n",
       "   ['Rhode Island'],\n",
       "   ['Pennsylvania']],\n",
       "  ['state',\n",
       "   'state of birth',\n",
       "   'state of residence',\n",
       "   'office location',\n",
       "   'location',\n",
       "   'out of state',\n",
       "   'live',\n",
       "   'lives',\n",
       "   'live in',\n",
       "   'based in',\n",
       "   'lives in',\n",
       "   'where',\n",
       "   'works in',\n",
       "   'works at',\n",
       "   'where is',\n",
       "   'cali']],\n",
       " 'age': [['32',\n",
       "   '33',\n",
       "   '31',\n",
       "   '29',\n",
       "   '30',\n",
       "   '38',\n",
       "   '63',\n",
       "   '46',\n",
       "   '36',\n",
       "   '47',\n",
       "   '37',\n",
       "   '44',\n",
       "   '54',\n",
       "   '49',\n",
       "   '28',\n",
       "   '48',\n",
       "   '42',\n",
       "   '53',\n",
       "   '66',\n",
       "   '34',\n",
       "   '52',\n",
       "   '39',\n",
       "   '45',\n",
       "   '41',\n",
       "   '40',\n",
       "   '62',\n",
       "   '43',\n",
       "   '59',\n",
       "   '27',\n",
       "   '67',\n",
       "   '50',\n",
       "   '35',\n",
       "   '26',\n",
       "   '25',\n",
       "   '65',\n",
       "   '51',\n",
       "   '58',\n",
       "   '56',\n",
       "   '64'],\n",
       "  [['old', 'years old', 'age of', 'ages of', 'age']],\n",
       "  ['age']],\n",
       " 'sex': [['male', 'female'],\n",
       "  [['men',\n",
       "    'males',\n",
       "    'guys',\n",
       "    'dudes',\n",
       "    'gents',\n",
       "    'gentlemen',\n",
       "    'boys',\n",
       "    'boy',\n",
       "    'male'],\n",
       "   ['women',\n",
       "    'females',\n",
       "    'ladies',\n",
       "    'lady',\n",
       "    'ladys',\n",
       "    'girls',\n",
       "    'gals',\n",
       "    'woman',\n",
       "    'girl',\n",
       "    'female']],\n",
       "  ['sex',\n",
       "   'gender',\n",
       "   'masculine',\n",
       "   'feminine',\n",
       "   'male person',\n",
       "   'm/f',\n",
       "   'male/female',\n",
       "   'M/F',\n",
       "   'Male/Female']],\n",
       " 'maritaldesc': [['married', 'divorced', 'single', 'separated', 'widowed'],\n",
       "  [['wed',\n",
       "    'legally married',\n",
       "    'espoused',\n",
       "    'joined in holy matrimony',\n",
       "    'hitched'],\n",
       "   nan,\n",
       "   ['unmarried', 'bachelor', 'bachelorette'],\n",
       "   nan,\n",
       "   nan],\n",
       "  ['husbandless',\n",
       "   'without a partner',\n",
       "   'unwedded',\n",
       "   'wifeless',\n",
       "   'no longer married',\n",
       "   'without a husband',\n",
       "   'without a wife',\n",
       "   'maritaldesc',\n",
       "   'marital status',\n",
       "   'spouse',\n",
       "   'husband',\n",
       "   'wife']],\n",
       " 'citizendesc': [['us citizen', 'non citizen'],\n",
       "  [['citizen',\n",
       "    'usa citizen',\n",
       "    'american citizen',\n",
       "    'citizen of the us',\n",
       "    'citizen of America',\n",
       "    'citizen of the usa',\n",
       "    'citizens'],\n",
       "   ['non citizen',\n",
       "    'not a citizen',\n",
       "    'non us citizen',\n",
       "    'not citizens',\n",
       "    'from abroad',\n",
       "    'immigrant',\n",
       "    'immigrants',\n",
       "    'eligble non citizen',\n",
       "    'non-citizen',\n",
       "    'non-citizens']],\n",
       "  ['h1 visa',\n",
       "   'foreigner',\n",
       "   'foreign',\n",
       "   'out of country',\n",
       "   'citizenship status',\n",
       "   'citizenship']],\n",
       " 'racedesc': [['black or african american',\n",
       "   'asian',\n",
       "   'two or more races',\n",
       "   'white',\n",
       "   'hispanic',\n",
       "   'american indian or alaska native'],\n",
       "  [['black', 'african american', 'african-american'],\n",
       "   ['from asia'],\n",
       "   ['multiracial',\n",
       "    'multi-racial',\n",
       "    'mixed',\n",
       "    'mixed race',\n",
       "    'biracial',\n",
       "    'interracial'],\n",
       "   ['caucasian'],\n",
       "   ['latino'],\n",
       "   ['native',\n",
       "    'natives',\n",
       "    'indians',\n",
       "    'indian',\n",
       "    'american indian',\n",
       "    'alaska native']],\n",
       "  ['ethnicity',\n",
       "   'race',\n",
       "   'racial background',\n",
       "   'ethnic group',\n",
       "   'ethnic type',\n",
       "   'racial indentity',\n",
       "   'community',\n",
       "   'minorities']],\n",
       " 'reason_for_termination': [['return to school',\n",
       "   'another position',\n",
       "   'unhappy',\n",
       "   'military',\n",
       "   'gross misconduct',\n",
       "   'hours',\n",
       "   'medical issues',\n",
       "   'relocation out of area',\n",
       "   'more money',\n",
       "   'career change',\n",
       "   'n/a - has not started yet',\n",
       "   'retiring',\n",
       "   'n/a - still employed',\n",
       "   'attendance',\n",
       "   'no-call no-show',\n",
       "   'maternity leave - did not return',\n",
       "   'performance'],\n",
       "  [['went back to school',\n",
       "    'had to go to school again',\n",
       "    'needed to go back to school',\n",
       "    'went back to college'],\n",
       "   ['took on another job',\n",
       "    'landed a new position',\n",
       "    'changed positions',\n",
       "    'got a new position',\n",
       "    'found a new position'],\n",
       "   [\"wasn't happy\",\n",
       "    \"didn't like his job\",\n",
       "    \"didn't like her job\",\n",
       "    'hated the job',\n",
       "    'disliked the job',\n",
       "    \"didn't enjoy the job\",\n",
       "    \"didn't like his work\",\n",
       "    \"didn't like her work\"],\n",
       "   ['joined the military',\n",
       "    'went to the military',\n",
       "    'left for the military',\n",
       "    'enlisted in the military',\n",
       "    'was drafted into the military'],\n",
       "   nan,\n",
       "   nan,\n",
       "   ['got sick', 'fell sick', 'medical problems', 'sick'],\n",
       "   ['was relocated',\n",
       "    'had to relocated',\n",
       "    'was assigned to a new location',\n",
       "    'was assigned to a different location'],\n",
       "   nan,\n",
       "   ['changed careers'],\n",
       "   nan,\n",
       "   ['retired', 'went into retirement'],\n",
       "   nan,\n",
       "   ['poor attendance', 'bad attendance'],\n",
       "   nan,\n",
       "   ['did not come back from maternity leave', 'had a kid and dissapeared'],\n",
       "   ['poor performance', 'performed below expectations']],\n",
       "  []],\n",
       " 'employment_status': [['terminated for cause',\n",
       "   'leave of absence',\n",
       "   'active',\n",
       "   'voluntarily terminated',\n",
       "   'future start'],\n",
       "  [['fired', 'let go', 'evicted', 'kicked out', 'removed', 'dismissed'],\n",
       "   ['on absence leave'],\n",
       "   ['currently employed',\n",
       "    'currently working',\n",
       "    'currently works',\n",
       "    'still works at',\n",
       "    'still working at',\n",
       "    'still work at',\n",
       "    'actively employed'],\n",
       "   ['quit', 'quitted', 'resigned', 'sent in a resignation'],\n",
       "   ['will start at a future time',\n",
       "    'will start later',\n",
       "    'will start some time in the future']],\n",
       "  ['renounce', 'employment status', 'current job status']],\n",
       " 'department': [['executive office',\n",
       "   'admin offices',\n",
       "   'production',\n",
       "   'it/is',\n",
       "   'software engineering',\n",
       "   'sales'],\n",
       "  [nan,\n",
       "   ['administration',\n",
       "    'office of admin',\n",
       "    'office of administration',\n",
       "    'admin office',\n",
       "    'administration office'],\n",
       "   nan,\n",
       "   ['IT',\n",
       "    'IS',\n",
       "    'Information Technology',\n",
       "    'Information Systems',\n",
       "    'Info Tech',\n",
       "    'Info Sys'],\n",
       "   ['programming', 'coding', 'software development'],\n",
       "   nan],\n",
       "  ['department',\n",
       "   'team',\n",
       "   'group',\n",
       "   'section',\n",
       "   'division',\n",
       "   'sector',\n",
       "   'office',\n",
       "   'office group',\n",
       "   'dpt',\n",
       "   'dept',\n",
       "   'dept.',\n",
       "   'branch',\n",
       "   'organization',\n",
       "   'organisation',\n",
       "   'org',\n",
       "   'company',\n",
       "   'corporation']],\n",
       " 'position': [['it manager - infra',\n",
       "   'cio',\n",
       "   'sales manager',\n",
       "   'president & ceo',\n",
       "   'administrative assistant',\n",
       "   'database administrator',\n",
       "   'area sales manager',\n",
       "   'it director',\n",
       "   'sr. accountant',\n",
       "   'it manager - support',\n",
       "   'production technician ii',\n",
       "   'network engineer',\n",
       "   'sr. network engineer',\n",
       "   'shared services manager',\n",
       "   'accountant i',\n",
       "   'it support',\n",
       "   'software engineering manager',\n",
       "   'production technician i',\n",
       "   'director of operations',\n",
       "   'director of sales',\n",
       "   'sr. dba',\n",
       "   'it manager - db',\n",
       "   'software engineer',\n",
       "   'production manager'],\n",
       "  [nan,\n",
       "   ['chief information officer'],\n",
       "   nan,\n",
       "   ['chief executive officer',\n",
       "    'ceo',\n",
       "    'prez',\n",
       "    'president',\n",
       "    'executive',\n",
       "    'highest rank',\n",
       "    'highest ranked',\n",
       "    'CEO',\n",
       "    'highest ranking'],\n",
       "   nan,\n",
       "   ['db admin', 'db administrator', 'database admin'],\n",
       "   nan,\n",
       "   ['director of it'],\n",
       "   ['senior accountant'],\n",
       "   nan,\n",
       "   ['production technician 2', 'production technician two'],\n",
       "   nan,\n",
       "   ['senior network engineer'],\n",
       "   nan,\n",
       "   ['accountant 1', 'accountant one'],\n",
       "   ['tech support'],\n",
       "   nan,\n",
       "   ['production technician 1', 'production technician one'],\n",
       "   ['operations director'],\n",
       "   ['sales director'],\n",
       "   ['senior database administrator',\n",
       "    'senior db admin',\n",
       "    'senior db administrator'],\n",
       "   nan,\n",
       "   ['software developer', 'programmer'],\n",
       "   nan],\n",
       "  ['title',\n",
       "   'job title',\n",
       "   'role',\n",
       "   'position',\n",
       "   'level in the organization',\n",
       "   'level',\n",
       "   'job',\n",
       "   'occupation']],\n",
       " 'manager': [['manager'],\n",
       "  [['manager name',\n",
       "    'manager',\n",
       "    'incharge',\n",
       "    'supervisor',\n",
       "    'mentor',\n",
       "    'leadership',\n",
       "    'boss',\n",
       "    'management',\n",
       "    'head',\n",
       "    'lead',\n",
       "    'chairman',\n",
       "    'working for',\n",
       "    'works for',\n",
       "    'work for',\n",
       "    'manage',\n",
       "    'managed by',\n",
       "    'managing',\n",
       "    'manages',\n",
       "    'reports to',\n",
       "    'report to',\n",
       "    'reporting to',\n",
       "    'reporting',\n",
       "    'working under',\n",
       "    'is under',\n",
       "    'leads',\n",
       "    'in charge of']],\n",
       "  []],\n",
       " 'employee_source': [['information session',\n",
       "   'company intranet - partner',\n",
       "   'social networks - facebook twitter etc',\n",
       "   'newspager/magazine',\n",
       "   'internet search',\n",
       "   'billboard',\n",
       "   'pay per click',\n",
       "   'on-line web application',\n",
       "   'glassdoor',\n",
       "   'professional society',\n",
       "   'monster.com',\n",
       "   'diversity job fair',\n",
       "   'careerbuilder',\n",
       "   'mbta ads',\n",
       "   'word of mouth',\n",
       "   'other',\n",
       "   'vendor referral',\n",
       "   'on-campus recruiting',\n",
       "   'website banner ads',\n",
       "   'employee referral'],\n",
       "  [['info session'],\n",
       "   nan,\n",
       "   ['social media',\n",
       "    'social media apps',\n",
       "    'facebook',\n",
       "    'instagram',\n",
       "    'twitter',\n",
       "    'snapchat',\n",
       "    'social network'],\n",
       "   ['newspaper', 'magazine'],\n",
       "   ['google',\n",
       "    'bing',\n",
       "    'yahoo',\n",
       "    \"search engine - google bing yahoo'\",\n",
       "    'search engine'],\n",
       "   ['poster'],\n",
       "   ['ppc', 'google ads', 'google ppc', 'ppc google'],\n",
       "   ['application potal', 'job portal'],\n",
       "   ['glass door'],\n",
       "   ['professional group'],\n",
       "   ['monster'],\n",
       "   nan,\n",
       "   nan,\n",
       "   ['advertisement', 'ads'],\n",
       "   ['verbal mention'],\n",
       "   nan,\n",
       "   ['referred by vendor', 'vendor referred'],\n",
       "   ['on-campus job fair', 'career fair'],\n",
       "   nan,\n",
       "   ['referred by employee']],\n",
       "  ['how did you learn about this position',\n",
       "   'how did you find out about this job',\n",
       "   'how did you find out about this position',\n",
       "   'how did you learn about this job. how did you hear about this',\n",
       "   'heard about us',\n",
       "   'hear about us',\n",
       "   'how you heard about us',\n",
       "   'how did you hear of us',\n",
       "   'hear of us']],\n",
       " 'performance_score': [['exceptional',\n",
       "   'fully meets',\n",
       "   'n/a- too early to review',\n",
       "   'pip',\n",
       "   'needs improvement',\n",
       "   'exceeds',\n",
       "   '90-day meets'],\n",
       "  [['extraordinary'],\n",
       "   ['up to the mark', 'meet expectations', 'meet', 'meets'],\n",
       "   nan,\n",
       "   nan,\n",
       "   ['performing badly',\n",
       "    'performing below expectations',\n",
       "    'not meeting standards',\n",
       "    'not meeting expectations',\n",
       "    'poor performance',\n",
       "    'performing poorly',\n",
       "    'poorly performing',\n",
       "    'does not meet',\n",
       "    'do not meet'],\n",
       "   ['beyond expectations',\n",
       "    'more than expected',\n",
       "    'better than expected',\n",
       "    'higher than excpected',\n",
       "    'exceed expectations'],\n",
       "   nan],\n",
       "  ['performance rating',\n",
       "   'performance score',\n",
       "   'performance evaluation',\n",
       "   'performance eval',\n",
       "   'evalation',\n",
       "   'eval',\n",
       "   'performance evaluation history',\n",
       "   'performance eval history',\n",
       "   'performance',\n",
       "   'performance history',\n",
       "   'how well']],\n",
       " 'money': [['pay rate'],\n",
       "  [['salary',\n",
       "    'income',\n",
       "    'pay',\n",
       "    'earn',\n",
       "    'earnings',\n",
       "    'make',\n",
       "    'dollars',\n",
       "    '$',\n",
       "    'paycheck',\n",
       "    'earns',\n",
       "    'earning',\n",
       "    'earners',\n",
       "    'earner',\n",
       "    'incomes',\n",
       "    'paycheck',\n",
       "    'compensation']],\n",
       "  ['earns', 'makes', 'amount']],\n",
       " 'comparator': [['more than', 'equals to', 'less than', 'between'],\n",
       "  [['greater than',\n",
       "    'higher than',\n",
       "    'longer',\n",
       "    'over',\n",
       "    'older than',\n",
       "    'above',\n",
       "    'bigger than',\n",
       "    'larger than'],\n",
       "   ['is exactly', 'is equal to', 'equates to', 'equal to'],\n",
       "   ['lower than', 'below', 'under', 'fewer than', 'younger than'],\n",
       "   ['between', 'in between']],\n",
       "  []],\n",
       " 'dob': [['dob'],\n",
       "  [['birthday',\n",
       "    'birthdate',\n",
       "    'birth date',\n",
       "    'date of birth',\n",
       "    'day of birth',\n",
       "    'born on',\n",
       "    'born on the',\n",
       "    'born in',\n",
       "    'born after',\n",
       "    'born before',\n",
       "    'DOB']],\n",
       "  []],\n",
       " 'time_interval': [['2000s',\n",
       "   '2010s',\n",
       "   '1920s',\n",
       "   '1930s',\n",
       "   '1940s',\n",
       "   '1950s',\n",
       "   '1960s',\n",
       "   '1970s',\n",
       "   '1980s',\n",
       "   '1990s'],\n",
       "  [[\"00's\", \"2000's\", 'two thousands'],\n",
       "   [\"10's\", 'two thousand tens', 'tens', \"2010's\"],\n",
       "   [\"20's\", 'nineteen twenties', 'twenties', \"1920's\"],\n",
       "   [\"30's\", 'nineteen thirties', 'thirties', \"1930's\"],\n",
       "   [\"40's\", 'nineteen forties', 'forties', \"1940's\"],\n",
       "   [\"50's\", 'nineteen fifties', 'fifties', \"1950's\"],\n",
       "   [\"60's\", 'nineteen sixties', 'sixties', \"1960's\"],\n",
       "   [\"70's\", 'nineteen seventies', 'seventies', \"1970's\"],\n",
       "   [\"80's\", 'nineteen eighties', 'eighties', \"1980's\"],\n",
       "   [\"90's\", 'nineteen nineties', 'nineties', \"1990's\"]],\n",
       "  []],\n",
       " 'time_recur': [['yearly', 'monthly', 'weekly', 'daily', 'hourly'],\n",
       "  [['by the year',\n",
       "    'every year',\n",
       "    'each year',\n",
       "    'annually',\n",
       "    'on a yearly basis',\n",
       "    'per year',\n",
       "    'annual',\n",
       "    'in a year',\n",
       "    'in the year'],\n",
       "   ['by the month',\n",
       "    'every month',\n",
       "    'each month',\n",
       "    'month to month',\n",
       "    'month-to-month',\n",
       "    'on a monthly basis',\n",
       "    'per month',\n",
       "    'in a month',\n",
       "    'in the month'],\n",
       "   ['by the week',\n",
       "    'every week',\n",
       "    'each week',\n",
       "    'week by week',\n",
       "    'on a weekly basis',\n",
       "    'per week',\n",
       "    'in a week',\n",
       "    'in the week'],\n",
       "   ['daily',\n",
       "    'every day',\n",
       "    'day by day',\n",
       "    'each day',\n",
       "    'on a daily basis',\n",
       "    'per day',\n",
       "    'in a day',\n",
       "    'in the day'],\n",
       "   ['every hour',\n",
       "    'each hour',\n",
       "    'on an hourly basis',\n",
       "    'on the hour',\n",
       "    'per hour',\n",
       "    'in an hour',\n",
       "    'in  a hour',\n",
       "    'hour',\n",
       "    'in the hour']],\n",
       "  []],\n",
       " 'function': [['percent', 'sum', 'average', 'count'],\n",
       "  [['fraction',\n",
       "    'portion',\n",
       "    'proportion',\n",
       "    'percentage',\n",
       "    '%',\n",
       "    'ratio',\n",
       "    'ratios',\n",
       "    'pct',\n",
       "    'distribution'],\n",
       "   ['total',\n",
       "    'cumulative',\n",
       "    'added up',\n",
       "    'summed up',\n",
       "    'totalled',\n",
       "    'summed',\n",
       "    'combined',\n",
       "    'aggregate'],\n",
       "   ['mean', 'typical', 'typically', 'median', 'avg', 'range'],\n",
       "   ['how many', 'number', 'number of', 'num of', 'headcount', 'count of']],\n",
       "  ['turn over rate']],\n",
       " 'extreme': [['highest', 'lowest'],\n",
       "  [['top', 'maximum', 'most', 'greatest', 'max', 'oldest', 'eldest', 'latest'],\n",
       "   ['least', 'minimum', 'bottom', 'lowest', 'min', 'youngest', 'earliest']],\n",
       "  []],\n",
       " 'employment_action': [['hired', 'fired'],\n",
       "  [['employed',\n",
       "    'recruited',\n",
       "    'start date',\n",
       "    'date of starting employment',\n",
       "    'hiring date',\n",
       "    'date of hire',\n",
       "    'join',\n",
       "    'joined',\n",
       "    'date of hiring',\n",
       "    'began her employment',\n",
       "    'began his employment',\n",
       "    'started working',\n",
       "    'join date',\n",
       "    'worked here',\n",
       "    'started',\n",
       "    'been with us',\n",
       "    'began working for',\n",
       "    'started her experience',\n",
       "    'started his experience',\n",
       "    'been working here',\n",
       "    'been with the company',\n",
       "    'been here',\n",
       "    'long has worked here',\n",
       "    'years of experience',\n",
       "    'of experience',\n",
       "    'employees that have been here',\n",
       "    'working here for'],\n",
       "   ['terminated',\n",
       "    'let go',\n",
       "    'end date',\n",
       "    'date of leaving job',\n",
       "    'date of ending employment',\n",
       "    'date of termination',\n",
       "    'firing date',\n",
       "    'end employment',\n",
       "    'end his employment',\n",
       "    'end her employment',\n",
       "    'out of the company',\n",
       "    'kicked out',\n",
       "    'booted from the company',\n",
       "    'booted from the corporation']],\n",
       "  []],\n",
       " 'date_compare': [['prev', 'post'],\n",
       "  [['before', 'pre', 'prior to'],\n",
       "   ['after',\n",
       "    'last',\n",
       "    'post',\n",
       "    'this year',\n",
       "    'this month',\n",
       "    'this week',\n",
       "    'atleast',\n",
       "    'since']],\n",
       "  []]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_dict['name'][0].append('')\n",
    "ent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': [['William LaRotonda',\n",
       "   'Tyrone Steans',\n",
       "   'Estelle Howard',\n",
       "   'Leigh Smith',\n",
       "   'Brandon LeBlanc',\n",
       "   'Sean Quinn',\n",
       "   'Bonalyn Boutwell',\n",
       "   'Amy Foster-Baker',\n",
       "   'Janet King',\n",
       "   'Jennifer Zamora',\n",
       "   'Renee Becker',\n",
       "   'Taisha Goble',\n",
       "   'Daniff Hernandez',\n",
       "   'Jayne Horton',\n",
       "   'Noelle Johnson',\n",
       "   'Thomas Murray',\n",
       "   'Randall Pearson',\n",
       "   'Thelma Petrowsky',\n",
       "   'Lori Roby',\n",
       "   'Jason Salter',\n",
       "   'Kramer Simard',\n",
       "   'Simon Roup',\n",
       "   'Ricardo Ruiz',\n",
       "   'Peter Monroe',\n",
       "   'Eric Dougall',\n",
       "   'Rick Clayton',\n",
       "   'Lisa Galia',\n",
       "   'Leonara Lindsay',\n",
       "   'Alejandro Bacong',\n",
       "   'Anthony Cisco',\n",
       "   'Linda Dolan',\n",
       "   'Maria Gonzalez',\n",
       "   'Carlos Merlos',\n",
       "   'Tanya Morway',\n",
       "   'Anita Shepard',\n",
       "   'Neville Tredinnick',\n",
       "   'Jumil Turpin',\n",
       "   'Karthikeyan Ait Sidi',\n",
       "   'Claudia Carr',\n",
       "   'Donald Favis',\n",
       "   'Bianca Roehrich',\n",
       "   'Ann Daniele',\n",
       "   'Jyoti Lajiri',\n",
       "   'Jeremiah Semizoglou',\n",
       "   'Joe South',\n",
       "   'Sarah Warfield',\n",
       "   'Elisa Bramante',\n",
       "   'Michael Albert',\n",
       "   'Charles Bozzi',\n",
       "   'Webster Butler',\n",
       "   'Elijiah Gray',\n",
       "   'Jonathan Hogland',\n",
       "   'Walter Immediato',\n",
       "   'Ketsia Liebig',\n",
       "   'Brannon Miller',\n",
       "   'Ebonee Peterson',\n",
       "   'Kelley Spirea',\n",
       "   'David Stanley',\n",
       "   'Kissy Sullivan',\n",
       "   'Courtney Wallace',\n",
       "   'Wilson Adinolfi',\n",
       "   'Trina Alagbe',\n",
       "   'Carol Anderson',\n",
       "   'Sam Athwal',\n",
       "   'Rachael Baczenski',\n",
       "   'Francesco Barone',\n",
       "   'Nader Barton',\n",
       "   'Lowan Biden',\n",
       "   'Helen Billis',\n",
       "   'Donna Brill',\n",
       "   'Josephine Bugali',\n",
       "   'Beatrice Chace',\n",
       "   'Lin Chan',\n",
       "   'Donovan Chang',\n",
       "   'Enola Chivukula',\n",
       "   'Caroline Cierpiszewski',\n",
       "   'Elijian Clukey',\n",
       "   'James Cockel',\n",
       "   'Spencer Cole',\n",
       "   'Jean Crimmings',\n",
       "   \"Jene'ya Darson\",\n",
       "   'Carl Desimone',\n",
       "   'Geoff Dickinson',\n",
       "   'Lily DiNocco',\n",
       "   'Denisa Dobrin',\n",
       "   'Marianne Eaton',\n",
       "   'Rex England',\n",
       "   'Miguel Estremera',\n",
       "   'April Evensen',\n",
       "   'Susan Ferguson',\n",
       "   'Nilson Fernandes',\n",
       "   'Violeta Ferreira',\n",
       "   'Libby Fidelia',\n",
       "   'Raul Garcia',\n",
       "   'Hamish Garneau',\n",
       "   'Barbara Gaul',\n",
       "   'Mildred Gentry',\n",
       "   'Melisa Gerke',\n",
       "   'Alex Gilles',\n",
       "   'Evelyn Girifalco',\n",
       "   'Shenice Gold',\n",
       "   'Roxana Goyal',\n",
       "   'Paula Gross',\n",
       "   'Joanne Handschiegl',\n",
       "   'Ludwick Harrell',\n",
       "   'Christie Harrington',\n",
       "   'Kara Harrison',\n",
       "   'Rose Ivey',\n",
       "   'Maryellen Jackson',\n",
       "   'Hannah Jacobi',\n",
       "   'Sneha Jhaveri',\n",
       "   'Judy Jung',\n",
       "   'Kathleen Kinsella',\n",
       "   'Alexandra Kirill',\n",
       "   'Bradley Knapp',\n",
       "   'John Kretschmer',\n",
       "   'Enrico Langton',\n",
       "   'Dallas Leach',\n",
       "   'Marilyn Linares',\n",
       "   'Allison Lydon',\n",
       "   'Lindsay Lynch',\n",
       "   'Samuel MacLennan',\n",
       "   'Lauren Mahoney',\n",
       "   'Debbie Mangal',\n",
       "   'Shana Maurice',\n",
       "   'Sandy Mckenna',\n",
       "   'Elizabeth Meads',\n",
       "   'Dawn Motlagh',\n",
       "   'Colombui Ndzi',\n",
       "   'Richard Newman',\n",
       "   'Shari Ngodup',\n",
       "   'Lei-Ming Nguyen',\n",
       "   \"Lynn O'hare\",\n",
       "   'Adeel Osturnka',\n",
       "   'Clinton Owad',\n",
       "   'Nina Panjwani',\n",
       "   'Emil Pelech',\n",
       "   'Shakira Perry',\n",
       "   'Hong Pham',\n",
       "   'Brad Pitt',\n",
       "   'Morissa Power',\n",
       "   'Louis Punjabhi',\n",
       "   'Janine Purinton',\n",
       "   'Quinn Rarrick',\n",
       "   'Haley Rivera',\n",
       "   'Alain Robinson',\n",
       "   'Ashley Rose',\n",
       "   'Bruno Rossetti',\n",
       "   'Melinda Saar-Beckles',\n",
       "   'Nore Sadki',\n",
       "   'Kamrin Sander',\n",
       "   'Nori Sewkumar',\n",
       "   'Seffi Shields',\n",
       "   'Taylor Sparks',\n",
       "   'Kristen Squatrito',\n",
       "   'Desiree Tavares',\n",
       "   'Sophia Theamstern',\n",
       "   'Theresa Tinto',\n",
       "   'Jeanette Tippett',\n",
       "   'Mei Trang',\n",
       "   'Abdellah Veera',\n",
       "   'Colleen Volk',\n",
       "   'Anna Von Massenbach',\n",
       "   'Scott Whittier',\n",
       "   'Barry Wilber',\n",
       "   'Jacquelyn Williams',\n",
       "   'Catherine Ybarra',\n",
       "   'Kimberly Beak',\n",
       "   'Dianna Blount',\n",
       "   'Betsy Bondwell',\n",
       "   'Joseph Buccheri',\n",
       "   'Joelle Burke',\n",
       "   'Benjamin Burkett',\n",
       "   'Phil Close',\n",
       "   'Daniel Davis',\n",
       "   'Carla Demita',\n",
       "   'Angela Erilus',\n",
       "   'Megan Faller',\n",
       "   'Nicole Fancett',\n",
       "   'Phylicia Gosciminski',\n",
       "   'Earnest Hankard',\n",
       "   'Adrienne Homberger',\n",
       "   'Julissa Hunts',\n",
       "   'Rosalie Hutter',\n",
       "   'Ming Huynh',\n",
       "   'Tayana Jeannite',\n",
       "   'Yen Johnston',\n",
       "   'Lindsey Langford',\n",
       "   'Mohammed Latif',\n",
       "   'Mathew Linden',\n",
       "   'Robyn Manchester',\n",
       "   'Karen Mancuso',\n",
       "   'Brigit McCarthy',\n",
       "   'Erasumus Monkfish',\n",
       "   'Luisa Monterro',\n",
       "   'Patrick Moran',\n",
       "   'Maliki Moumanil',\n",
       "   'Kristie Nowlan',\n",
       "   'Brooke Oliver',\n",
       "   'Ermine Pelletier',\n",
       "   'May Roberson',\n",
       "   'Adil Sahoo',\n",
       "   'Constance Sloan',\n",
       "   'Lenora Tejeda',\n",
       "   'Kenneth Thibaud',\n",
       "   'Cybil Trzeciak',\n",
       "   'Roger Walker',\n",
       "   'Jordan Winthrop',\n",
       "   'Hang Wolk',\n",
       "   'Edward Buck',\n",
       "   'Jessica Bunbury',\n",
       "   'Michelle Carter',\n",
       "   'Latia Costa',\n",
       "   'Jenna Dietrich',\n",
       "   'Alfred Digitale',\n",
       "   'Maruk Fraval',\n",
       "   'Gerry Friedman',\n",
       "   'Whitney Gill',\n",
       "   'Myriam Givens',\n",
       "   'Mike Guilianno',\n",
       "   'Jeremy Prater',\n",
       "   'Bartholemew Khemmich',\n",
       "   'Giovanni Leruth',\n",
       "   'Jac McKinzie',\n",
       "   'Howard Mullaney',\n",
       "   'Jasmine Onque',\n",
       "   'Travis Ozark',\n",
       "   'Xana Potts',\n",
       "   'Caitrin Strong',\n",
       "   'Sharlene Terry',\n",
       "   'Jackie Valentin',\n",
       "   'Noah Villanueva',\n",
       "   'Debra Houlihan',\n",
       "   'Donysha Kampew',\n",
       "   'Colby Andreola',\n",
       "   'Judith Carabbio',\n",
       "   'Keyla Del Bosque',\n",
       "   'Sandra Martin',\n",
       "   'Luke Patronick',\n",
       "   'Adell Saada',\n",
       "   'Andrew Szabo',\n",
       "   'Mia Brown',\n",
       "   'Ivan Rogers',\n",
       "   'Julia Soto',\n",
       "   'Nan Singh',\n",
       "   ''],\n",
       "  [['william larotonda', 'William', 'william', 'LaRotonda', 'larotonda'],\n",
       "   ['tyrone steans', 'Tyrone', 'tyrone', 'Steans', 'steans'],\n",
       "   ['estelle howard', 'Estelle', 'estelle', 'Howard', 'howard'],\n",
       "   ['leigh smith', 'Leigh', 'leigh', 'Smith', 'smith'],\n",
       "   ['brandon leblanc', 'Brandon', 'brandon', 'LeBlanc', 'leblanc'],\n",
       "   ['sean quinn', 'Sean', 'sean', 'Quinn', 'quinn'],\n",
       "   ['bonalyn boutwell', 'Bonalyn', 'bonalyn', 'Boutwell', 'boutwell'],\n",
       "   ['amy foster-baker', 'Amy', 'amy', 'Foster-Baker', 'foster-baker'],\n",
       "   ['janet king', 'Janet', 'janet', 'King', 'king'],\n",
       "   ['jennifer zamora', 'Jennifer', 'jennifer', 'Zamora', 'zamora'],\n",
       "   ['renee becker', 'Renee', 'renee', 'Becker', 'becker'],\n",
       "   ['taisha goble', 'Taisha', 'taisha', 'Goble', 'goble'],\n",
       "   ['daniff hernandez', 'Daniff', 'daniff', 'Hernandez', 'hernandez'],\n",
       "   ['jayne horton', 'Jayne', 'jayne', 'Horton', 'horton'],\n",
       "   ['noelle johnson', 'Noelle', 'noelle', 'Johnson', 'johnson'],\n",
       "   ['thomas murray', 'Thomas', 'thomas', 'Murray', 'murray'],\n",
       "   ['randall pearson', 'Randall', 'randall', 'Pearson', 'pearson'],\n",
       "   ['thelma petrowsky', 'Thelma', 'thelma', 'Petrowsky', 'petrowsky'],\n",
       "   ['lori roby', 'Lori', 'lori', 'Roby', 'roby'],\n",
       "   ['jason salter', 'Jason', 'jason', 'Salter', 'salter'],\n",
       "   ['kramer simard', 'Kramer', 'kramer', 'Simard', 'simard'],\n",
       "   ['simon roup', 'Simon', 'simon', 'Roup', 'roup'],\n",
       "   ['ricardo ruiz', 'Ricardo', 'ricardo', 'Ruiz', 'ruiz'],\n",
       "   ['peter monroe', 'Peter', 'peter', 'Monroe', 'monroe'],\n",
       "   ['eric dougall', 'Eric', 'eric', 'Dougall', 'dougall'],\n",
       "   ['rick clayton', 'Rick', 'rick', 'Clayton', 'clayton'],\n",
       "   ['lisa galia', 'Lisa', 'lisa', 'Galia', 'galia'],\n",
       "   ['leonara lindsay', 'Leonara', 'leonara', 'Lindsay', 'lindsay'],\n",
       "   ['alejandro bacong', 'Alejandro', 'alejandro', 'Bacong', 'bacong'],\n",
       "   ['anthony cisco', 'Anthony', 'anthony', 'Cisco', 'cisco'],\n",
       "   ['linda dolan', 'Linda', 'linda', 'Dolan', 'dolan'],\n",
       "   ['maria gonzalez', 'Maria', 'maria', 'Gonzalez', 'gonzalez'],\n",
       "   ['carlos merlos', 'Carlos', 'carlos', 'Merlos', 'merlos'],\n",
       "   ['tanya morway', 'Tanya', 'tanya', 'Morway', 'morway'],\n",
       "   ['anita shepard', 'Anita', 'anita', 'Shepard', 'shepard'],\n",
       "   ['neville tredinnick', 'Neville', 'neville', 'Tredinnick', 'tredinnick'],\n",
       "   ['jumil turpin', 'Jumil', 'jumil', 'Turpin', 'turpin'],\n",
       "   ['karthikeyan ait sidi', 'Karthikeyan', 'karthikeyan', 'Ait', 'ait'],\n",
       "   ['claudia carr', 'Claudia', 'claudia', 'Carr', 'carr'],\n",
       "   ['donald favis', 'Donald', 'donald', 'Favis', 'favis'],\n",
       "   ['bianca roehrich', 'Bianca', 'bianca', 'Roehrich', 'roehrich'],\n",
       "   ['ann daniele', 'Ann', 'ann', 'Daniele', 'daniele'],\n",
       "   ['jyoti lajiri', 'Jyoti', 'jyoti', 'Lajiri', 'lajiri'],\n",
       "   ['jeremiah semizoglou', 'Jeremiah', 'jeremiah', 'Semizoglou', 'semizoglou'],\n",
       "   ['joe south', 'Joe', 'joe', 'South', 'south'],\n",
       "   ['sarah warfield', 'Sarah', 'sarah', 'Warfield', 'warfield'],\n",
       "   ['elisa bramante', 'Elisa', 'elisa', 'Bramante', 'bramante'],\n",
       "   ['michael albert', 'Michael', 'michael', 'Albert', 'albert'],\n",
       "   ['charles bozzi', 'Charles', 'charles', 'Bozzi', 'bozzi'],\n",
       "   ['webster butler', 'Webster', 'webster', 'Butler', 'butler'],\n",
       "   ['elijiah gray', 'Elijiah', 'elijiah', 'Gray', 'gray'],\n",
       "   ['jonathan hogland', 'Jonathan', 'jonathan', 'Hogland', 'hogland'],\n",
       "   ['walter immediato', 'Walter', 'walter', 'Immediato', 'immediato'],\n",
       "   ['ketsia liebig', 'Ketsia', 'ketsia', 'Liebig', 'liebig'],\n",
       "   ['brannon miller', 'Brannon', 'brannon', 'Miller', 'miller'],\n",
       "   ['ebonee peterson', 'Ebonee', 'ebonee', 'Peterson', 'peterson'],\n",
       "   ['kelley spirea', 'Kelley', 'kelley', 'Spirea', 'spirea'],\n",
       "   ['david stanley', 'David', 'david', 'Stanley', 'stanley'],\n",
       "   ['kissy sullivan', 'Kissy', 'kissy', 'Sullivan', 'sullivan'],\n",
       "   ['courtney wallace', 'Courtney', 'courtney', 'Wallace', 'wallace'],\n",
       "   ['wilson adinolfi', 'Wilson', 'wilson', 'Adinolfi', 'adinolfi'],\n",
       "   ['trina alagbe', 'Trina', 'trina', 'Alagbe', 'alagbe'],\n",
       "   ['carol anderson', 'Carol', 'carol', 'Anderson', 'anderson'],\n",
       "   ['sam athwal', 'Sam', 'sam', 'Athwal', 'athwal'],\n",
       "   ['rachael baczenski', 'Rachael', 'rachael', 'Baczenski', 'baczenski'],\n",
       "   ['francesco barone', 'Francesco', 'francesco', 'Barone', 'barone'],\n",
       "   ['nader barton', 'Nader', 'nader', 'Barton', 'barton'],\n",
       "   ['lowan biden', 'Lowan', 'lowan', 'Biden', 'biden'],\n",
       "   ['helen billis', 'Helen', 'helen', 'Billis', 'billis'],\n",
       "   ['donna brill', 'Donna', 'donna', 'Brill', 'brill'],\n",
       "   ['josephine bugali', 'Josephine', 'josephine', 'Bugali', 'bugali'],\n",
       "   ['beatrice chace', 'Beatrice', 'beatrice', 'Chace', 'chace'],\n",
       "   ['lin chan', 'Lin', 'lin', 'Chan', 'chan'],\n",
       "   ['donovan chang', 'Donovan', 'donovan', 'Chang', 'chang'],\n",
       "   ['enola chivukula', 'Enola', 'enola', 'Chivukula', 'chivukula'],\n",
       "   ['caroline cierpiszewski',\n",
       "    'Caroline',\n",
       "    'caroline',\n",
       "    'Cierpiszewski',\n",
       "    'cierpiszewski'],\n",
       "   ['elijian clukey', 'Elijian', 'elijian', 'Clukey', 'clukey'],\n",
       "   ['james cockel', 'James', 'james', 'Cockel', 'cockel'],\n",
       "   ['spencer cole', 'Spencer', 'spencer', 'Cole', 'cole'],\n",
       "   ['jean crimmings', 'Jean', 'jean', 'Crimmings', 'crimmings'],\n",
       "   [\"jene'ya darson\", \"Jene'ya\", \"jene'ya\", 'Darson', 'darson'],\n",
       "   ['carl desimone', 'Carl', 'carl', 'Desimone', 'desimone'],\n",
       "   ['geoff dickinson', 'Geoff', 'geoff', 'Dickinson', 'dickinson'],\n",
       "   ['lily dinocco', 'Lily', 'lily', 'DiNocco', 'dinocco'],\n",
       "   ['denisa dobrin', 'Denisa', 'denisa', 'Dobrin', 'dobrin'],\n",
       "   ['marianne eaton', 'Marianne', 'marianne', 'Eaton', 'eaton'],\n",
       "   ['rex england', 'Rex', 'rex', 'England', 'england'],\n",
       "   ['miguel estremera', 'Miguel', 'miguel', 'Estremera', 'estremera'],\n",
       "   ['april evensen', 'April', 'april', 'Evensen', 'evensen'],\n",
       "   ['susan ferguson', 'Susan', 'susan', 'Ferguson', 'ferguson'],\n",
       "   ['nilson fernandes', 'Nilson', 'nilson', 'Fernandes', 'fernandes'],\n",
       "   ['violeta ferreira', 'Violeta', 'violeta', 'Ferreira', 'ferreira'],\n",
       "   ['libby fidelia', 'Libby', 'libby', 'Fidelia', 'fidelia'],\n",
       "   ['raul garcia', 'Raul', 'raul', 'Garcia', 'garcia'],\n",
       "   ['hamish garneau', 'Hamish', 'hamish', 'Garneau', 'garneau'],\n",
       "   ['barbara gaul', 'Barbara', 'barbara', 'Gaul', 'gaul'],\n",
       "   ['mildred gentry', 'Mildred', 'mildred', 'Gentry', 'gentry'],\n",
       "   ['melisa gerke', 'Melisa', 'melisa', 'Gerke', 'gerke'],\n",
       "   ['alex gilles', 'Alex', 'alex', 'Gilles', 'gilles'],\n",
       "   ['evelyn girifalco', 'Evelyn', 'evelyn', 'Girifalco', 'girifalco'],\n",
       "   ['shenice gold', 'Shenice', 'shenice', 'Gold', 'gold'],\n",
       "   ['roxana goyal', 'Roxana', 'roxana', 'Goyal', 'goyal'],\n",
       "   ['paula gross', 'Paula', 'paula', 'Gross', 'gross'],\n",
       "   ['joanne handschiegl', 'Joanne', 'joanne', 'Handschiegl', 'handschiegl'],\n",
       "   ['ludwick harrell', 'Ludwick', 'ludwick', 'Harrell', 'harrell'],\n",
       "   ['christie harrington', 'Christie', 'christie', 'Harrington', 'harrington'],\n",
       "   ['kara harrison', 'Kara', 'kara', 'Harrison', 'harrison'],\n",
       "   ['rose ivey', 'Rose', 'rose', 'Ivey', 'ivey'],\n",
       "   ['maryellen jackson', 'Maryellen', 'maryellen', 'Jackson', 'jackson'],\n",
       "   ['hannah jacobi', 'Hannah', 'hannah', 'Jacobi', 'jacobi'],\n",
       "   ['sneha jhaveri', 'Sneha', 'sneha', 'Jhaveri', 'jhaveri'],\n",
       "   ['judy jung', 'Judy', 'judy', 'Jung', 'jung'],\n",
       "   ['kathleen kinsella', 'Kathleen', 'kathleen', 'Kinsella', 'kinsella'],\n",
       "   ['alexandra kirill', 'Alexandra', 'alexandra', 'Kirill', 'kirill'],\n",
       "   ['bradley knapp', 'Bradley', 'bradley', 'Knapp', 'knapp'],\n",
       "   ['john kretschmer', 'John', 'john', 'Kretschmer', 'kretschmer'],\n",
       "   ['enrico langton', 'Enrico', 'enrico', 'Langton', 'langton'],\n",
       "   ['dallas leach', 'Dallas', 'dallas', 'Leach', 'leach'],\n",
       "   ['marilyn linares', 'Marilyn', 'marilyn', 'Linares', 'linares'],\n",
       "   ['allison lydon', 'Allison', 'allison', 'Lydon', 'lydon'],\n",
       "   ['lindsay lynch', 'Lindsay', 'lindsay', 'Lynch', 'lynch'],\n",
       "   ['samuel maclennan', 'Samuel', 'samuel', 'MacLennan', 'maclennan'],\n",
       "   ['lauren mahoney', 'Lauren', 'lauren', 'Mahoney', 'mahoney'],\n",
       "   ['debbie mangal', 'Debbie', 'debbie', 'Mangal', 'mangal'],\n",
       "   ['shana maurice', 'Shana', 'shana', 'Maurice', 'maurice'],\n",
       "   ['sandy mckenna', 'Sandy', 'sandy', 'Mckenna', 'mckenna'],\n",
       "   ['elizabeth meads', 'Elizabeth', 'elizabeth', 'Meads', 'meads'],\n",
       "   ['dawn motlagh', 'Dawn', 'dawn', 'Motlagh', 'motlagh'],\n",
       "   ['colombui ndzi', 'Colombui', 'colombui', 'Ndzi', 'ndzi'],\n",
       "   ['richard newman', 'Richard', 'richard', 'Newman', 'newman'],\n",
       "   ['shari ngodup', 'Shari', 'shari', 'Ngodup', 'ngodup'],\n",
       "   ['lei-ming nguyen', 'Lei-Ming', 'lei-ming', 'Nguyen', 'nguyen'],\n",
       "   [\"lynn o'hare\", 'Lynn', 'lynn', \"O'hare\", \"o'hare\"],\n",
       "   ['adeel osturnka', 'Adeel', 'adeel', 'Osturnka', 'osturnka'],\n",
       "   ['clinton owad', 'Clinton', 'clinton', 'Owad', 'owad'],\n",
       "   ['nina panjwani', 'Nina', 'nina', 'Panjwani', 'panjwani'],\n",
       "   ['emil pelech', 'Emil', 'emil', 'Pelech', 'pelech'],\n",
       "   ['shakira perry', 'Shakira', 'shakira', 'Perry', 'perry'],\n",
       "   ['hong pham', 'Hong', 'hong', 'Pham', 'pham'],\n",
       "   ['brad pitt', 'Brad', 'brad', 'Pitt', 'pitt'],\n",
       "   ['morissa power', 'Morissa', 'morissa', 'Power', 'power'],\n",
       "   ['louis punjabhi', 'Louis', 'louis', 'Punjabhi', 'punjabhi'],\n",
       "   ['janine purinton', 'Janine', 'janine', 'Purinton', 'purinton'],\n",
       "   ['quinn rarrick', 'Quinn', 'quinn', 'Rarrick', 'rarrick'],\n",
       "   ['haley rivera', 'Haley', 'haley', 'Rivera', 'rivera'],\n",
       "   ['alain robinson', 'Alain', 'alain', 'Robinson', 'robinson'],\n",
       "   ['ashley rose', 'Ashley', 'ashley', 'Rose', 'rose'],\n",
       "   ['bruno rossetti', 'Bruno', 'bruno', 'Rossetti', 'rossetti'],\n",
       "   ['melinda saar-beckles',\n",
       "    'Melinda',\n",
       "    'melinda',\n",
       "    'Saar-Beckles',\n",
       "    'saar-beckles'],\n",
       "   ['nore sadki', 'Nore', 'nore', 'Sadki', 'sadki'],\n",
       "   ['kamrin sander', 'Kamrin', 'kamrin', 'Sander', 'sander'],\n",
       "   ['nori sewkumar', 'Nori', 'nori', 'Sewkumar', 'sewkumar'],\n",
       "   ['seffi shields', 'Seffi', 'seffi', 'Shields', 'shields'],\n",
       "   ['taylor sparks', 'Taylor', 'taylor', 'Sparks', 'sparks'],\n",
       "   ['kristen squatrito', 'Kristen', 'kristen', 'Squatrito', 'squatrito'],\n",
       "   ['desiree tavares', 'Desiree', 'desiree', 'Tavares', 'tavares'],\n",
       "   ['sophia theamstern', 'Sophia', 'sophia', 'Theamstern', 'theamstern'],\n",
       "   ['theresa tinto', 'Theresa', 'theresa', 'Tinto', 'tinto'],\n",
       "   ['jeanette tippett', 'Jeanette', 'jeanette', 'Tippett', 'tippett'],\n",
       "   ['mei trang', 'Mei', 'mei', 'Trang', 'trang'],\n",
       "   ['abdellah veera', 'Abdellah', 'abdellah', 'Veera', 'veera'],\n",
       "   ['colleen volk', 'Colleen', 'colleen', 'Volk', 'volk'],\n",
       "   ['anna von massenbach', 'Anna', 'anna', 'Von', 'von'],\n",
       "   ['scott whittier', 'Scott', 'scott', 'Whittier', 'whittier'],\n",
       "   ['barry wilber', 'Barry', 'barry', 'Wilber', 'wilber'],\n",
       "   ['jacquelyn williams', 'Jacquelyn', 'jacquelyn', 'Williams', 'williams'],\n",
       "   ['catherine ybarra', 'Catherine', 'catherine', 'Ybarra', 'ybarra'],\n",
       "   ['kimberly beak', 'Kimberly', 'kimberly', 'Beak', 'beak'],\n",
       "   ['dianna blount', 'Dianna', 'dianna', 'Blount', 'blount'],\n",
       "   ['betsy bondwell', 'Betsy', 'betsy', 'Bondwell', 'bondwell'],\n",
       "   ['joseph buccheri', 'Joseph', 'joseph', 'Buccheri', 'buccheri'],\n",
       "   ['joelle burke', 'Joelle', 'joelle', 'Burke', 'burke'],\n",
       "   ['benjamin burkett', 'Benjamin', 'benjamin', 'Burkett', 'burkett'],\n",
       "   ['phil close', 'Phil', 'phil', 'Close', 'close'],\n",
       "   ['daniel davis', 'Daniel', 'daniel', 'Davis', 'davis'],\n",
       "   ['carla demita', 'Carla', 'carla', 'Demita', 'demita'],\n",
       "   ['angela erilus', 'Angela', 'angela', 'Erilus', 'erilus'],\n",
       "   ['megan faller', 'Megan', 'megan', 'Faller', 'faller'],\n",
       "   ['nicole fancett', 'Nicole', 'nicole', 'Fancett', 'fancett'],\n",
       "   ['phylicia gosciminski',\n",
       "    'Phylicia',\n",
       "    'phylicia',\n",
       "    'Gosciminski',\n",
       "    'gosciminski'],\n",
       "   ['earnest hankard', 'Earnest', 'earnest', 'Hankard', 'hankard'],\n",
       "   ['adrienne homberger', 'Adrienne', 'adrienne', 'Homberger', 'homberger'],\n",
       "   ['julissa hunts', 'Julissa', 'julissa', 'Hunts', 'hunts'],\n",
       "   ['rosalie hutter', 'Rosalie', 'rosalie', 'Hutter', 'hutter'],\n",
       "   ['ming huynh', 'Ming', 'ming', 'Huynh', 'huynh'],\n",
       "   ['tayana jeannite', 'Tayana', 'tayana', 'Jeannite', 'jeannite'],\n",
       "   ['yen johnston', 'Yen', 'yen', 'Johnston', 'johnston'],\n",
       "   ['lindsey langford', 'Lindsey', 'lindsey', 'Langford', 'langford'],\n",
       "   ['mohammed latif', 'Mohammed', 'mohammed', 'Latif', 'latif'],\n",
       "   ['mathew linden', 'Mathew', 'mathew', 'Linden', 'linden'],\n",
       "   ['robyn manchester', 'Robyn', 'robyn', 'Manchester', 'manchester'],\n",
       "   ['karen mancuso', 'Karen', 'karen', 'Mancuso', 'mancuso'],\n",
       "   ['brigit mccarthy', 'Brigit', 'brigit', 'McCarthy', 'mccarthy'],\n",
       "   ['erasumus monkfish', 'Erasumus', 'erasumus', 'Monkfish', 'monkfish'],\n",
       "   ['luisa monterro', 'Luisa', 'luisa', 'Monterro', 'monterro'],\n",
       "   ['patrick moran', 'Patrick', 'patrick', 'Moran', 'moran'],\n",
       "   ['maliki moumanil', 'Maliki', 'maliki', 'Moumanil', 'moumanil'],\n",
       "   ['kristie nowlan', 'Kristie', 'kristie', 'Nowlan', 'nowlan'],\n",
       "   ['brooke oliver', 'Brooke', 'brooke', 'Oliver', 'oliver'],\n",
       "   ['ermine pelletier', 'Ermine', 'ermine', 'Pelletier', 'pelletier'],\n",
       "   ['may roberson', 'May', 'may', 'Roberson', 'roberson'],\n",
       "   ['adil sahoo', 'Adil', 'adil', 'Sahoo', 'sahoo'],\n",
       "   ['constance sloan', 'Constance', 'constance', 'Sloan', 'sloan'],\n",
       "   ['lenora tejeda', 'Lenora', 'lenora', 'Tejeda', 'tejeda'],\n",
       "   ['kenneth thibaud', 'Kenneth', 'kenneth', 'Thibaud', 'thibaud'],\n",
       "   ['cybil trzeciak', 'Cybil', 'cybil', 'Trzeciak', 'trzeciak'],\n",
       "   ['roger walker', 'Roger', 'roger', 'Walker', 'walker'],\n",
       "   ['jordan winthrop', 'Jordan', 'jordan', 'Winthrop', 'winthrop'],\n",
       "   ['hang wolk', 'Hang', 'hang', 'Wolk', 'wolk'],\n",
       "   ['edward buck', 'Edward', 'edward', 'Buck', 'buck'],\n",
       "   ['jessica bunbury', 'Jessica', 'jessica', 'Bunbury', 'bunbury'],\n",
       "   ['michelle carter', 'Michelle', 'michelle', 'Carter', 'carter'],\n",
       "   ['latia costa', 'Latia', 'latia', 'Costa', 'costa'],\n",
       "   ['jenna dietrich', 'Jenna', 'jenna', 'Dietrich', 'dietrich'],\n",
       "   ['alfred digitale', 'Alfred', 'alfred', 'Digitale', 'digitale'],\n",
       "   ['maruk fraval', 'Maruk', 'maruk', 'Fraval', 'fraval'],\n",
       "   ['gerry friedman', 'Gerry', 'gerry', 'Friedman', 'friedman'],\n",
       "   ['whitney gill', 'Whitney', 'whitney', 'Gill', 'gill'],\n",
       "   ['myriam givens', 'Myriam', 'myriam', 'Givens', 'givens'],\n",
       "   ['mike guilianno', 'Mike', 'mike', 'Guilianno', 'guilianno'],\n",
       "   ['jeremy prater', 'Jeremy', 'jeremy', 'Prater', 'prater'],\n",
       "   ['bartholemew khemmich',\n",
       "    'Bartholemew',\n",
       "    'bartholemew',\n",
       "    'Khemmich',\n",
       "    'khemmich'],\n",
       "   ['giovanni leruth', 'Giovanni', 'giovanni', 'Leruth', 'leruth'],\n",
       "   ['jac mckinzie', 'Jac', 'jac', 'McKinzie', 'mckinzie'],\n",
       "   ['howard mullaney', 'Howard', 'howard', 'Mullaney', 'mullaney'],\n",
       "   ['jasmine onque', 'Jasmine', 'jasmine', 'Onque', 'onque'],\n",
       "   ['travis ozark', 'Travis', 'travis', 'Ozark', 'ozark'],\n",
       "   ['xana potts', 'Xana', 'xana', 'Potts', 'potts'],\n",
       "   ['caitrin strong', 'Caitrin', 'caitrin', 'Strong', 'strong'],\n",
       "   ['sharlene terry', 'Sharlene', 'sharlene', 'Terry', 'terry'],\n",
       "   ['jackie valentin', 'Jackie', 'jackie', 'Valentin', 'valentin'],\n",
       "   ['noah villanueva', 'Noah', 'noah', 'Villanueva', 'villanueva'],\n",
       "   ['debra houlihan', 'Debra', 'debra', 'Houlihan', 'houlihan'],\n",
       "   ['donysha kampew', 'Donysha', 'donysha', 'Kampew', 'kampew'],\n",
       "   ['colby andreola', 'Colby', 'colby', 'Andreola', 'andreola'],\n",
       "   ['judith carabbio', 'Judith', 'judith', 'Carabbio', 'carabbio'],\n",
       "   ['keyla del bosque', 'Keyla', 'keyla', 'Del', 'del'],\n",
       "   ['sandra martin', 'Sandra', 'sandra', 'Martin', 'martin'],\n",
       "   ['luke patronick', 'Luke', 'luke', 'Patronick', 'patronick'],\n",
       "   ['adell saada', 'Adell', 'adell', 'Saada', 'saada'],\n",
       "   ['andrew szabo', 'Andrew', 'andrew', 'Szabo', 'szabo'],\n",
       "   ['mia brown', 'Mia', 'mia', 'Brown', 'brown'],\n",
       "   ['ivan rogers', 'Ivan', 'ivan', 'Rogers', 'rogers'],\n",
       "   ['julia soto', 'Julia', 'julia', 'Soto', 'soto'],\n",
       "   ['nan singh', 'Nan', 'nan', 'Singh', 'singh'],\n",
       "   ['Ruie',\n",
       "    'Orlena',\n",
       "    'Wayland',\n",
       "    'Ishmael',\n",
       "    'Algot',\n",
       "    'Norberto',\n",
       "    'Tina',\n",
       "    'Minta',\n",
       "    'Kailyn',\n",
       "    'Norval',\n",
       "    'Deb',\n",
       "    'Fleeta',\n",
       "    'Christy',\n",
       "    'Worth',\n",
       "    'Jacqueline',\n",
       "    'Delia',\n",
       "    'Elder',\n",
       "    'Gayla',\n",
       "    'Celestine',\n",
       "    'Karen',\n",
       "    'Heriberto',\n",
       "    'Semaj',\n",
       "    'Dennie',\n",
       "    'Madden',\n",
       "    'Tyra',\n",
       "    'Joana',\n",
       "    'Jonathon',\n",
       "    'Verl',\n",
       "    'Cordie',\n",
       "    'Denine',\n",
       "    'Shani',\n",
       "    'Lyle',\n",
       "    'Shannon',\n",
       "    'Vic',\n",
       "    'Joesph',\n",
       "    'Zeb',\n",
       "    'Flo',\n",
       "    'Tai',\n",
       "    'Frona',\n",
       "    'Anderson',\n",
       "    'Rilla',\n",
       "    'Bud',\n",
       "    'Justus',\n",
       "    'Dionte',\n",
       "    'Wilton',\n",
       "    'Dossie',\n",
       "    'Jolie',\n",
       "    'Isiah',\n",
       "    'Brigid',\n",
       "    'Letitia',\n",
       "    'Serina',\n",
       "    'Ralph',\n",
       "    'Delores',\n",
       "    'Sabra',\n",
       "    'Jace',\n",
       "    'Elonzo',\n",
       "    'Chuck',\n",
       "    'Jalynn',\n",
       "    'Terese',\n",
       "    'Shawnna',\n",
       "    'Darrian',\n",
       "    'Londyn',\n",
       "    'Ilo',\n",
       "    'Emma',\n",
       "    'Fredy',\n",
       "    'Marrion',\n",
       "    'Rolla',\n",
       "    'Giselle',\n",
       "    'Loran',\n",
       "    'Aldona',\n",
       "    'Parlee',\n",
       "    'Georgiann',\n",
       "    'Durrell',\n",
       "    'Nila',\n",
       "    'Daniella',\n",
       "    'Hector',\n",
       "    'Richard',\n",
       "    'Estell',\n",
       "    'Otis',\n",
       "    'Leonie',\n",
       "    'Friend',\n",
       "    'Dannielle',\n",
       "    'Nola',\n",
       "    'Janna',\n",
       "    'Dolph',\n",
       "    'Brittanie',\n",
       "    'Jocelyn',\n",
       "    'Deven',\n",
       "    'Yael',\n",
       "    'Altie',\n",
       "    'Madelene',\n",
       "    'Vanesa',\n",
       "    'Thurston',\n",
       "    'Alzina',\n",
       "    'Nakia',\n",
       "    'Laurie',\n",
       "    'Leitha',\n",
       "    'Jeryl',\n",
       "    'Ethyle',\n",
       "    'Liston',\n",
       "    'Leone',\n",
       "    'Ferris',\n",
       "    'Frankie',\n",
       "    'Keri',\n",
       "    'Dasia',\n",
       "    'Williard',\n",
       "    'Earnestine',\n",
       "    'Steve',\n",
       "    'Scotty',\n",
       "    'Shanon',\n",
       "    'Harlan',\n",
       "    'Vita',\n",
       "    'Marshal',\n",
       "    'Rosina',\n",
       "    'Willam',\n",
       "    'Phylis',\n",
       "    'Marguerite',\n",
       "    'Darci',\n",
       "    'Webb',\n",
       "    'Lynnette',\n",
       "    'Jeffery',\n",
       "    'Green',\n",
       "    'Rico',\n",
       "    'Corwin',\n",
       "    'Deonte',\n",
       "    'Shanika',\n",
       "    'Amare',\n",
       "    'Penelope',\n",
       "    'Shena',\n",
       "    'Brigette',\n",
       "    'Joanna',\n",
       "    'Jayleen',\n",
       "    'Skylar',\n",
       "    'Harl',\n",
       "    'Seneca',\n",
       "    'Tyesha',\n",
       "    'Letty',\n",
       "    'Jossie',\n",
       "    'Wenzel',\n",
       "    'Alvah',\n",
       "    'Armando',\n",
       "    'Neta',\n",
       "    'Mattye',\n",
       "    'Grayling',\n",
       "    'Rhett',\n",
       "    'Louis',\n",
       "    'Tobe',\n",
       "    'Napoleon',\n",
       "    'Maximilian',\n",
       "    'Henry',\n",
       "    'Annabelle',\n",
       "    'Kenley',\n",
       "    'Diana',\n",
       "    'Lionel',\n",
       "    'Juluis',\n",
       "    'North',\n",
       "    'Deidra',\n",
       "    'Collins',\n",
       "    'Elmore',\n",
       "    'Rozanne',\n",
       "    'Raven',\n",
       "    'January',\n",
       "    'Gifford',\n",
       "    'Daisie',\n",
       "    'Shelvie',\n",
       "    'Sadye',\n",
       "    'Mazie',\n",
       "    'Gidget',\n",
       "    'Matthew',\n",
       "    'Hezekiah',\n",
       "    'Sierra',\n",
       "    'Alden',\n",
       "    'Danelle',\n",
       "    'Paul',\n",
       "    'Demi',\n",
       "    'Celie',\n",
       "    'Ximena',\n",
       "    'Anice',\n",
       "    'Kash',\n",
       "    'Chantel',\n",
       "    'Caitlin',\n",
       "    'Elfrieda',\n",
       "    'Christie',\n",
       "    'Genaro',\n",
       "    'Elissa',\n",
       "    'Joella',\n",
       "    'Ula',\n",
       "    'Parley',\n",
       "    'Rogers',\n",
       "    'Osborne',\n",
       "    'Stoney',\n",
       "    'Aydan',\n",
       "    'Lindsey',\n",
       "    'Gray',\n",
       "    'Lance',\n",
       "    'Kalene',\n",
       "    'Millard',\n",
       "    'Ellison',\n",
       "    'Danielle',\n",
       "    'Aida',\n",
       "    'Lim',\n",
       "    'Debbie',\n",
       "    'Ole',\n",
       "    'Cleva',\n",
       "    'Samara',\n",
       "    'Hilmer',\n",
       "    'Pamala',\n",
       "    'Lavonda',\n",
       "    'Tammy',\n",
       "    'Acy',\n",
       "    'Creola',\n",
       "    'Indiana',\n",
       "    'Howell',\n",
       "    'Kazuo',\n",
       "    'Jorge',\n",
       "    'Annis',\n",
       "    'Juliana',\n",
       "    'Roosevelt',\n",
       "    'Esperanza',\n",
       "    'Aggie',\n",
       "    'Milton',\n",
       "    'Ena',\n",
       "    'Jajuan',\n",
       "    'Geoff',\n",
       "    'Aniyah',\n",
       "    'Jeffrey',\n",
       "    'Jacob',\n",
       "    'Osborn',\n",
       "    'Reece',\n",
       "    'Gaven',\n",
       "    'Arnett',\n",
       "    'Cleo',\n",
       "    'Shyann',\n",
       "    'Brittany',\n",
       "    'Marisela',\n",
       "    'Geneva',\n",
       "    'Okey',\n",
       "    'Lashanda',\n",
       "    'Hence',\n",
       "    'Arla',\n",
       "    'Derrek',\n",
       "    'Earlene',\n",
       "    'Gustavo',\n",
       "    'Denese',\n",
       "    'Chauncy',\n",
       "    'Anthoney',\n",
       "    'Vidal',\n",
       "    'Palmer',\n",
       "    'Misty',\n",
       "    'Lolita',\n",
       "    'Tristin',\n",
       "    'Katlynn',\n",
       "    'Ethelbert',\n",
       "    'Darrion',\n",
       "    'Liana',\n",
       "    'Benjman',\n",
       "    'Vollie',\n",
       "    'Sanjuana',\n",
       "    'Jannette',\n",
       "    'Conner',\n",
       "    'Raphael',\n",
       "    'Dylan',\n",
       "    'Red',\n",
       "    'Judah',\n",
       "    'Jordyn',\n",
       "    'Titus',\n",
       "    'Lilianna',\n",
       "    'Ahmad',\n",
       "    'Taina',\n",
       "    'Kiya',\n",
       "    'Alisson',\n",
       "    'Alycia',\n",
       "    'Vance',\n",
       "    'Cedric',\n",
       "    'Tripp',\n",
       "    'Corbin',\n",
       "    'Hiroshi',\n",
       "    'Almond',\n",
       "    'Rudolfo',\n",
       "    'Jamya',\n",
       "    'Aurelio',\n",
       "    'Karlie',\n",
       "    'Selma',\n",
       "    'Isadore',\n",
       "    'Felix',\n",
       "    'Alek',\n",
       "    'Elayne',\n",
       "    'Felice',\n",
       "    'Adilene',\n",
       "    'Tyquan',\n",
       "    'Tiffanie',\n",
       "    'Millie',\n",
       "    'Alize',\n",
       "    'Jaslene',\n",
       "    'Hermine',\n",
       "    'Stephani',\n",
       "    'Butch',\n",
       "    'Kent',\n",
       "    'Harm',\n",
       "    'Tierra',\n",
       "    'Kathyrn',\n",
       "    'Spring',\n",
       "    'Yvette',\n",
       "    'Marcela',\n",
       "    'Allene',\n",
       "    'Berkley',\n",
       "    'Louisiana',\n",
       "    'Ama',\n",
       "    'Georgie',\n",
       "    'Daisy',\n",
       "    'Dorris',\n",
       "    'Mahala',\n",
       "    'Kylah',\n",
       "    'Javier',\n",
       "    'Michelina',\n",
       "    'Fitzgerald',\n",
       "    'Brien',\n",
       "    'Donavon',\n",
       "    'Florene',\n",
       "    'Lukas',\n",
       "    'Trevon',\n",
       "    'Tosha',\n",
       "    'Eileen',\n",
       "    'Mozelle',\n",
       "    'Merle',\n",
       "    'Abdul',\n",
       "    'Rosita',\n",
       "    'Darin',\n",
       "    'Namon',\n",
       "    'Annetta',\n",
       "    'Pansy',\n",
       "    'Kennard',\n",
       "    'Lindell',\n",
       "    'Mohammad',\n",
       "    'Theda',\n",
       "    'Horace',\n",
       "    'Tracey',\n",
       "    'Corene',\n",
       "    'Marius',\n",
       "    'Faye',\n",
       "    'Alec',\n",
       "    'Cicely',\n",
       "    'Cason',\n",
       "    'Dorthy',\n",
       "    'Malcolm',\n",
       "    'Alferd',\n",
       "    'Jackeline',\n",
       "    'Chestina',\n",
       "    'Xavier',\n",
       "    'Soren',\n",
       "    'Etta',\n",
       "    'Nigel',\n",
       "    'Lavenia',\n",
       "    'Laurel',\n",
       "    'Florine',\n",
       "    'Heather',\n",
       "    'Christa',\n",
       "    'Arbie',\n",
       "    'Demian',\n",
       "    'Archie',\n",
       "    'Damion',\n",
       "    'Brock',\n",
       "    'Elizabeth',\n",
       "    'Saniyah',\n",
       "    'Rory',\n",
       "    'Eulah',\n",
       "    'Rock',\n",
       "    'Kassidy',\n",
       "    'Diann',\n",
       "    'Yaakov',\n",
       "    'Faustino',\n",
       "    'Lillard',\n",
       "    'Chancy',\n",
       "    'Toccara',\n",
       "    'Authur',\n",
       "    'Leland',\n",
       "    'Christian',\n",
       "    'Adams',\n",
       "    'Torry',\n",
       "    'Bennie',\n",
       "    'Hedwig',\n",
       "    'Miranda',\n",
       "    'Agustus',\n",
       "    'Octavia',\n",
       "    'Chaka',\n",
       "    'Basil',\n",
       "    'Jon',\n",
       "    'Collin',\n",
       "    'Deirdre',\n",
       "    'Jammie',\n",
       "    'Foy',\n",
       "    'Arnoldo',\n",
       "    'Delton',\n",
       "    'Braeden',\n",
       "    'Keith',\n",
       "    'Mario',\n",
       "    'Nelia',\n",
       "    'Yessenia',\n",
       "    'Emelia',\n",
       "    'Orlin',\n",
       "    'Kevan',\n",
       "    'Fredie',\n",
       "    'Armin',\n",
       "    'Jadon',\n",
       "    'Raynard',\n",
       "    'Jameel',\n",
       "    'Bronson',\n",
       "    'Laurence',\n",
       "    'Ressie',\n",
       "    'Almeta',\n",
       "    'Scottie',\n",
       "    'Wayde',\n",
       "    'Davian',\n",
       "    'Jan',\n",
       "    'Jolene',\n",
       "    'Clora',\n",
       "    'Roswell',\n",
       "    'Martine',\n",
       "    'Meghan',\n",
       "    'Maud',\n",
       "    'Governor',\n",
       "    'Taurean',\n",
       "    'Wilford',\n",
       "    'Cleon',\n",
       "    'Rebecca',\n",
       "    'Renae',\n",
       "    'Hayleigh',\n",
       "    'Cherrelle',\n",
       "    'Finn',\n",
       "    'Ida',\n",
       "    'Allena',\n",
       "    'Taft',\n",
       "    'Sloane',\n",
       "    'Samir',\n",
       "    'Shad',\n",
       "    'Arvo',\n",
       "    'Darryl',\n",
       "    'Coy',\n",
       "    'Zack',\n",
       "    'Ruth',\n",
       "    'Hughes',\n",
       "    'Fonda',\n",
       "    'Jared',\n",
       "    'Gina',\n",
       "    'Johny',\n",
       "    'Leilani',\n",
       "    'Britni',\n",
       "    'Cressie',\n",
       "    'Kirby',\n",
       "    'Kendal',\n",
       "    'Rosie',\n",
       "    'Johnna',\n",
       "    'Humphrey',\n",
       "    'Kendell',\n",
       "    'Hazelle',\n",
       "    'Odelia',\n",
       "    'Annamarie',\n",
       "    'Mervin',\n",
       "    'Chaney',\n",
       "    'Kourtney',\n",
       "    'Kathern',\n",
       "    'Keanu',\n",
       "    'Eathel',\n",
       "    'Malissie',\n",
       "    'Barbra',\n",
       "    'Gust',\n",
       "    'Olivine',\n",
       "    'Zeta',\n",
       "    'Griffith',\n",
       "    'Mikel',\n",
       "    'Gasper',\n",
       "    'Aliyah',\n",
       "    'Price',\n",
       "    'Damien',\n",
       "    'Gaige',\n",
       "    'Shelba',\n",
       "    'Melton',\n",
       "    'Jovanny',\n",
       "    'Rueben',\n",
       "    'Donie',\n",
       "    'Evangeline',\n",
       "    'Mara',\n",
       "    'Nathaly',\n",
       "    'Crista',\n",
       "    'Christ',\n",
       "    'Alvaro',\n",
       "    'Nick',\n",
       "    'Hobson',\n",
       "    'Mac',\n",
       "    'Oliva',\n",
       "    'Charlotta',\n",
       "    'Roddy',\n",
       "    'Beula',\n",
       "    'Dedrick',\n",
       "    'Haywood',\n",
       "    'Prudie',\n",
       "    'Melisa',\n",
       "    'Arline',\n",
       "    'Lakisha',\n",
       "    'Lavelle',\n",
       "    'Clay',\n",
       "    'Merlene',\n",
       "    'Carleigh',\n",
       "    'Cristi',\n",
       "    'Litzy',\n",
       "    'Lelia',\n",
       "    'Lolla',\n",
       "    'Fronnie',\n",
       "    'Ashlea',\n",
       "    'Delano',\n",
       "    'Toya',\n",
       "    'Verona',\n",
       "    'Brandee',\n",
       "    'Graydon',\n",
       "    'Hershel',\n",
       "    'Edson',\n",
       "    'Constantine',\n",
       "    'Artie',\n",
       "    'Aden',\n",
       "    'Kandace',\n",
       "    'Cristine',\n",
       "    'Pratt',\n",
       "    'Anjali',\n",
       "    'Mabell',\n",
       "    'Verna',\n",
       "    'Iyana',\n",
       "    'Evan',\n",
       "    'Rosalind',\n",
       "    'Gloria',\n",
       "    'Mahalia',\n",
       "    'Thos',\n",
       "    'Belia',\n",
       "    'Niki',\n",
       "    'Curtis',\n",
       "    'Audrianna',\n",
       "    'Rianna',\n",
       "    'Lota',\n",
       "    'Maxwell',\n",
       "    'Shaniece',\n",
       "    'Trish',\n",
       "    'Ambers',\n",
       "    'Hedy',\n",
       "    'Bert',\n",
       "    'Agness',\n",
       "    'Jesenia',\n",
       "    'Brianna',\n",
       "    'Michell',\n",
       "    'Joanie',\n",
       "    'Ava',\n",
       "    'Sienna',\n",
       "    'Tim',\n",
       "    'Lilla',\n",
       "    'Margery',\n",
       "    'Chase',\n",
       "    'Alvin',\n",
       "    'Leonidas',\n",
       "    'Jarrett',\n",
       "    'Dollie',\n",
       "    'Kaye',\n",
       "    'Mae',\n",
       "    'Nicklaus',\n",
       "    'Winford',\n",
       "    'Dallin',\n",
       "    'Lovie',\n",
       "    'Clemie',\n",
       "    'Carli',\n",
       "    'Ninnie',\n",
       "    'Shenna',\n",
       "    'Clella',\n",
       "    'Garnet',\n",
       "    'Ardelia',\n",
       "    'Irvine',\n",
       "    'Brogan',\n",
       "    'Victory',\n",
       "    'Dulce',\n",
       "    'Barry',\n",
       "    'Maryam',\n",
       "    'Kami',\n",
       "    'Prince',\n",
       "    'Mildred',\n",
       "    'Raquel',\n",
       "    'Nanie',\n",
       "    'Miles',\n",
       "    'Anabella',\n",
       "    'Keon',\n",
       "    'Emanuel',\n",
       "    'Sabina',\n",
       "    'Maleah',\n",
       "    'Arlin',\n",
       "    'Kya',\n",
       "    'Claudette',\n",
       "    'Ronan',\n",
       "    'Sean',\n",
       "    'Coleman',\n",
       "    'Nancie',\n",
       "    'Ovila',\n",
       "    'Derek',\n",
       "    'Albertine',\n",
       "    'Lamont',\n",
       "    'Kellie',\n",
       "    'Matthias',\n",
       "    'Joselyn',\n",
       "    'Berton',\n",
       "    'Omar',\n",
       "    'Novella',\n",
       "    'Savannah',\n",
       "    'Bob',\n",
       "    'Lorena',\n",
       "    'Glinda',\n",
       "    'Danial',\n",
       "    'Leonardo',\n",
       "    'Paola',\n",
       "    'Brett',\n",
       "    'Latosha',\n",
       "    'Will',\n",
       "    'Larry',\n",
       "    'Otha',\n",
       "    'Aarav',\n",
       "    'Alline',\n",
       "    'Starling',\n",
       "    'Mozell',\n",
       "    'Zina',\n",
       "    'Marshall',\n",
       "    'Hymen',\n",
       "    'Letta',\n",
       "    'Macie',\n",
       "    'Adelyn',\n",
       "    'Reba',\n",
       "    'Omer',\n",
       "    'Young',\n",
       "    'Wynona',\n",
       "    'Josef',\n",
       "    'Ryker',\n",
       "    'Jeana',\n",
       "    'Anfernee',\n",
       "    'Rosamond',\n",
       "    'Kesha',\n",
       "    'Juliann',\n",
       "    'Eleonora',\n",
       "    'Nikki',\n",
       "    'Barron',\n",
       "    'Crystal',\n",
       "    'Hilton',\n",
       "    'Neola',\n",
       "    'Buell',\n",
       "    'Nasir',\n",
       "    'Rachel',\n",
       "    'Bethel',\n",
       "    'Nova',\n",
       "    'Rozella',\n",
       "    'Journey',\n",
       "    'Colten',\n",
       "    'Elroy',\n",
       "    'Nevaeh',\n",
       "    'Clydie',\n",
       "    'Madilynn',\n",
       "    'Verner',\n",
       "    'Babyboy',\n",
       "    'Dena',\n",
       "    'Colleen',\n",
       "    'Osvaldo',\n",
       "    'Kandy',\n",
       "    'Caleigh',\n",
       "    'Nickolas',\n",
       "    'Welton',\n",
       "    'Juan',\n",
       "    'Masao',\n",
       "    'Norman',\n",
       "    'Dellia',\n",
       "    'Webster',\n",
       "    'Ford',\n",
       "    'Althea',\n",
       "    'Deanna',\n",
       "    'Zona',\n",
       "    'Nile',\n",
       "    'Lex',\n",
       "    'Cass',\n",
       "    'Mariyah',\n",
       "    'Warner',\n",
       "    'Virgel',\n",
       "    'Consuela',\n",
       "    'Alaina',\n",
       "    'Cinnamon',\n",
       "    'Dianne',\n",
       "    'Raheem',\n",
       "    'Geraldo',\n",
       "    'Montana',\n",
       "    'Minoru',\n",
       "    'Sharla',\n",
       "    'Hanna',\n",
       "    'Rena',\n",
       "    'Porsha',\n",
       "    'Coraima',\n",
       "    'Wyatt',\n",
       "    'Meadow',\n",
       "    'Abram',\n",
       "    'Alabama',\n",
       "    'Anibal',\n",
       "    'Sergio',\n",
       "    'Alayna',\n",
       "    'Carson',\n",
       "    'Rayshawn',\n",
       "    'Davie',\n",
       "    'Almus',\n",
       "    'Brinda',\n",
       "    'Fernando',\n",
       "    'Sheryll',\n",
       "    'Joann',\n",
       "    'Maverick',\n",
       "    'Alby',\n",
       "    'Adin',\n",
       "    'Hayden',\n",
       "    'Jameson',\n",
       "    'Lexis',\n",
       "    'Keagan',\n",
       "    'Nikia',\n",
       "    'Dicy',\n",
       "    'Shirleyann',\n",
       "    'Benjiman',\n",
       "    'Derrell',\n",
       "    'Lita',\n",
       "    'Kegan',\n",
       "    'Sada',\n",
       "    'Verda',\n",
       "    'Patric',\n",
       "    'Aydin',\n",
       "    'Carley',\n",
       "    'Tenisha',\n",
       "    'Dante',\n",
       "    'Bjorn',\n",
       "    'Mona',\n",
       "    'Cristina',\n",
       "    'Davonte',\n",
       "    'Layla',\n",
       "    'Doc',\n",
       "    'Lenna',\n",
       "    'Orion',\n",
       "    'Leesa',\n",
       "    'Lafayette',\n",
       "    'Waylon',\n",
       "    'Winter',\n",
       "    'Rustin',\n",
       "    'Elzada',\n",
       "    'Rashawn',\n",
       "    'Hellen',\n",
       "    'Rosemarie',\n",
       "    'Kem',\n",
       "    'Maudie',\n",
       "    'Tanika',\n",
       "    'Leatha',\n",
       "    'Breonna',\n",
       "    'Clayton',\n",
       "    'Jaymes',\n",
       "    'Estela',\n",
       "    'Ismael',\n",
       "    'Marcia',\n",
       "    'Domenick',\n",
       "    'Hal',\n",
       "    'Vicente',\n",
       "    'Harlie',\n",
       "    'Ashleigh',\n",
       "    'Durward',\n",
       "    'Louella',\n",
       "    'Shaquita',\n",
       "    'Brantley',\n",
       "    'Karla',\n",
       "    'Uriah',\n",
       "    'Brennan',\n",
       "    'Venus',\n",
       "    'Elvia',\n",
       "    'Konnor',\n",
       "    'Shaquana',\n",
       "    'Maude',\n",
       "    'Kiley',\n",
       "    'Vernice',\n",
       "    'Benny',\n",
       "    'Nakisha',\n",
       "    'Kelli',\n",
       "    'Toby',\n",
       "    'Warren',\n",
       "    'Bama',\n",
       "    'Silvio',\n",
       "    'Collier',\n",
       "    'Nyasia',\n",
       "    'Dillard',\n",
       "    'Yesenia',\n",
       "    'Amey',\n",
       "    'Vernell',\n",
       "    'Rayne',\n",
       "    'Jeanne',\n",
       "    'Antionette',\n",
       "    'Aurthur',\n",
       "    'Anissa',\n",
       "    'Solon',\n",
       "    'Destinee',\n",
       "    'Mills',\n",
       "    'Yaritza',\n",
       "    'Machelle',\n",
       "    'Savon',\n",
       "    'Gaines',\n",
       "    'Zoe',\n",
       "    'Genevieve',\n",
       "    'Charlie',\n",
       "    'Connor',\n",
       "    'India',\n",
       "    'Angelica',\n",
       "    'Emilee',\n",
       "    'Pierre',\n",
       "    'Clarissa',\n",
       "    'Jefferson',\n",
       "    'Graves',\n",
       "    'Kaci',\n",
       "    'Clarke',\n",
       "    'Eartha',\n",
       "    'Kade',\n",
       "    'Lark',\n",
       "    'Abe',\n",
       "    'Mamie',\n",
       "    'Charly',\n",
       "    'Cyrus',\n",
       "    'Lue',\n",
       "    'Breanna',\n",
       "    'Lydia',\n",
       "    'Ova',\n",
       "    'Axel',\n",
       "    'Demarcus',\n",
       "    'Chanel',\n",
       "    'Bee',\n",
       "    'Mertie',\n",
       "    'Zechariah',\n",
       "    'Djuna',\n",
       "    'Almedia',\n",
       "    'Jodie',\n",
       "    'Savion',\n",
       "    'Kate',\n",
       "    'Unknown',\n",
       "    'Sherilyn',\n",
       "    'Izaiah',\n",
       "    'Charlsie',\n",
       "    'Estel',\n",
       "    'Shelli',\n",
       "    'Renada',\n",
       "    'Bettylou',\n",
       "    'Ayden',\n",
       "    'Donny',\n",
       "    'Launa',\n",
       "    'Boston',\n",
       "    'Jamison',\n",
       "    'Joseluis',\n",
       "    'Stanford',\n",
       "    'Tex',\n",
       "    'Darlene',\n",
       "    'Elodie',\n",
       "    'Whitley',\n",
       "    'Lonie',\n",
       "    'Julia',\n",
       "    'Gerardo',\n",
       "    'Hallie',\n",
       "    'Fannie',\n",
       "    'Raul',\n",
       "    'Maddison',\n",
       "    'Darcie',\n",
       "    'Ashby',\n",
       "    'Hung',\n",
       "    'Uriel',\n",
       "    'Julian',\n",
       "    'Darien',\n",
       "    'Anatole',\n",
       "    'Adan',\n",
       "    'Corinna',\n",
       "    'Tevin',\n",
       "    'Dariana',\n",
       "    'Rome',\n",
       "    'Gianna',\n",
       "    'Ezequiel',\n",
       "    'Thornton',\n",
       "    'Sheilah',\n",
       "    'Georgianna',\n",
       "    'Lucie',\n",
       "    'Carra',\n",
       "    'Betty',\n",
       "    'Quinn',\n",
       "    'Ima',\n",
       "    'Lanie',\n",
       "    'Alexandria',\n",
       "    'Malaya',\n",
       "    'Genesis',\n",
       "    'Angeles',\n",
       "    'Mal',\n",
       "    'Hayward',\n",
       "    'Jasiah',\n",
       "    'Alda',\n",
       "    'Carmine',\n",
       "    'Laurine',\n",
       "    'Tiney',\n",
       "    'Waldo',\n",
       "    'Bernice',\n",
       "    'Ronal',\n",
       "    'Rufus',\n",
       "    'Evie',\n",
       "    'Deric',\n",
       "    'Sabrina',\n",
       "    'Martha',\n",
       "    'Johnny',\n",
       "    'Cathi',\n",
       "    'Paityn',\n",
       "    'Merlin',\n",
       "    'Krish',\n",
       "    'Ryleigh',\n",
       "    'Mckenzie',\n",
       "    'Shakira',\n",
       "    'Latanya',\n",
       "    'Timmie',\n",
       "    'Krysten',\n",
       "    'Lorin',\n",
       "    'Roberta',\n",
       "    'Inez',\n",
       "    'Timothy',\n",
       "    'Dirk',\n",
       "    'Lilie',\n",
       "    'Yoshio',\n",
       "    'Sallie',\n",
       "    'Emmit',\n",
       "    'Chelsea',\n",
       "    'Garey',\n",
       "    'Lisette',\n",
       "    'Clementina',\n",
       "    'Dominque',\n",
       "    'Rod',\n",
       "    'Jakayla',\n",
       "    'Norton',\n",
       "    'Jake',\n",
       "    'Shirlie',\n",
       "    'Tarsha',\n",
       "    'Signa',\n",
       "    'Dorsey',\n",
       "    'Schuyler',\n",
       "    'Arba',\n",
       "    'Kerwin',\n",
       "    'Sincere',\n",
       "    'Odus',\n",
       "    'Cleta',\n",
       "    'Carlee',\n",
       "    'Sky',\n",
       "    'Ozell',\n",
       "    'Olen',\n",
       "    'Iola',\n",
       "    'Kwame',\n",
       "    'Raymon',\n",
       "    'Jemal',\n",
       "    'Trenton',\n",
       "    'Eldora',\n",
       "    'Eura',\n",
       "    'Noelia',\n",
       "    'Lavern',\n",
       "    'Alston',\n",
       "    'Hortensia',\n",
       "    'Camren',\n",
       "    'Virgia',\n",
       "    'Sanai',\n",
       "    'Karter',\n",
       "    'Deante',\n",
       "    'Gaylord',\n",
       "    'Darion',\n",
       "    'Jaylan',\n",
       "    'Jose',\n",
       "    'Baldwin',\n",
       "    'Dorene',\n",
       "    'Eben',\n",
       "    'Twila',\n",
       "    'Laila',\n",
       "    'Alexandr',\n",
       "    'Dion',\n",
       "    'Owens',\n",
       "    'Kimber',\n",
       "    'Bryn',\n",
       "    'Cena',\n",
       "    'Kermit',\n",
       "    'Carri',\n",
       "    'Ewart',\n",
       "    'Immanuel',\n",
       "    'Emmanuel',\n",
       "    'Coolidge',\n",
       "    'Bode',\n",
       "    'Audry',\n",
       "    'Irene',\n",
       "    'York',\n",
       "    'Rhona',\n",
       "    'Andres',\n",
       "    'Sinda',\n",
       "    'Gaither',\n",
       "    'Lise',\n",
       "    'Rita',\n",
       "    'Linus',\n",
       "    'Dewayne',\n",
       "    'Felicia',\n",
       "    'Naima',\n",
       "    'Dahlia',\n",
       "    'Paulette',\n",
       "    'Marcellus',\n",
       "    ...]],\n",
       "  []],\n",
       " 'state': [array(['MA', 'TX', 'CT', 'VA', 'VT', 'CA', 'WA', 'NH', 'NY', 'OH', 'IN',\n",
       "         'ID', 'TN', 'NV', 'CO', 'UT', 'AL', 'GA', 'FL', 'NC', 'KY', 'ND',\n",
       "         'MT', 'OR', 'AZ', 'ME', 'RI', 'PA'], dtype=object),\n",
       "  [['Massachussets'],\n",
       "   ['Texas'],\n",
       "   ['Connecticut'],\n",
       "   ['Virginia'],\n",
       "   ['Vermony'],\n",
       "   ['California'],\n",
       "   ['Washington'],\n",
       "   ['New Hampshire'],\n",
       "   ['New York'],\n",
       "   ['Ohio'],\n",
       "   ['Indiana'],\n",
       "   ['Idaho'],\n",
       "   ['Tennessee'],\n",
       "   ['Nevada'],\n",
       "   ['Colarado'],\n",
       "   ['Utah'],\n",
       "   ['Alabama'],\n",
       "   ['Georgia'],\n",
       "   ['Florida'],\n",
       "   ['North Carolina'],\n",
       "   ['Kentucky'],\n",
       "   ['North Dakota'],\n",
       "   ['Montana'],\n",
       "   ['Oregon'],\n",
       "   ['Arizona'],\n",
       "   ['Maine'],\n",
       "   ['Rhode Island'],\n",
       "   ['Pennsylvania']],\n",
       "  ['state',\n",
       "   'state of birth',\n",
       "   'state of residence',\n",
       "   'office location',\n",
       "   'location',\n",
       "   'out of state',\n",
       "   'live',\n",
       "   'lives',\n",
       "   'live in',\n",
       "   'based in',\n",
       "   'lives in',\n",
       "   'where',\n",
       "   'works in',\n",
       "   'works at',\n",
       "   'where is',\n",
       "   'cali']],\n",
       " 'age': [['32',\n",
       "   '33',\n",
       "   '31',\n",
       "   '29',\n",
       "   '30',\n",
       "   '38',\n",
       "   '63',\n",
       "   '46',\n",
       "   '36',\n",
       "   '47',\n",
       "   '37',\n",
       "   '44',\n",
       "   '54',\n",
       "   '49',\n",
       "   '28',\n",
       "   '48',\n",
       "   '42',\n",
       "   '53',\n",
       "   '66',\n",
       "   '34',\n",
       "   '52',\n",
       "   '39',\n",
       "   '45',\n",
       "   '41',\n",
       "   '40',\n",
       "   '62',\n",
       "   '43',\n",
       "   '59',\n",
       "   '27',\n",
       "   '67',\n",
       "   '50',\n",
       "   '35',\n",
       "   '26',\n",
       "   '25',\n",
       "   '65',\n",
       "   '51',\n",
       "   '58',\n",
       "   '56',\n",
       "   '64'],\n",
       "  [['old', 'years old', 'age of', 'ages of', 'age']],\n",
       "  ['age']],\n",
       " 'sex': [['male', 'female'],\n",
       "  [['men',\n",
       "    'males',\n",
       "    'guys',\n",
       "    'dudes',\n",
       "    'gents',\n",
       "    'gentlemen',\n",
       "    'boys',\n",
       "    'boy',\n",
       "    'male'],\n",
       "   ['women',\n",
       "    'females',\n",
       "    'ladies',\n",
       "    'lady',\n",
       "    'ladys',\n",
       "    'girls',\n",
       "    'gals',\n",
       "    'woman',\n",
       "    'girl',\n",
       "    'female']],\n",
       "  ['sex',\n",
       "   'gender',\n",
       "   'masculine',\n",
       "   'feminine',\n",
       "   'male person',\n",
       "   'm/f',\n",
       "   'male/female',\n",
       "   'M/F',\n",
       "   'Male/Female']],\n",
       " 'maritaldesc': [['married', 'divorced', 'single', 'separated', 'widowed'],\n",
       "  [['wed',\n",
       "    'legally married',\n",
       "    'espoused',\n",
       "    'joined in holy matrimony',\n",
       "    'hitched'],\n",
       "   nan,\n",
       "   ['unmarried', 'bachelor', 'bachelorette'],\n",
       "   nan,\n",
       "   nan],\n",
       "  ['husbandless',\n",
       "   'without a partner',\n",
       "   'unwedded',\n",
       "   'wifeless',\n",
       "   'no longer married',\n",
       "   'without a husband',\n",
       "   'without a wife',\n",
       "   'maritaldesc',\n",
       "   'marital status',\n",
       "   'spouse',\n",
       "   'husband',\n",
       "   'wife']],\n",
       " 'citizendesc': [['us citizen', 'non citizen'],\n",
       "  [['citizen',\n",
       "    'usa citizen',\n",
       "    'american citizen',\n",
       "    'citizen of the us',\n",
       "    'citizen of America',\n",
       "    'citizen of the usa',\n",
       "    'citizens'],\n",
       "   ['non citizen',\n",
       "    'not a citizen',\n",
       "    'non us citizen',\n",
       "    'not citizens',\n",
       "    'from abroad',\n",
       "    'immigrant',\n",
       "    'immigrants',\n",
       "    'eligble non citizen',\n",
       "    'non-citizen',\n",
       "    'non-citizens']],\n",
       "  ['h1 visa',\n",
       "   'foreigner',\n",
       "   'foreign',\n",
       "   'out of country',\n",
       "   'citizenship status',\n",
       "   'citizenship']],\n",
       " 'racedesc': [['black or african american',\n",
       "   'asian',\n",
       "   'two or more races',\n",
       "   'white',\n",
       "   'hispanic',\n",
       "   'american indian or alaska native'],\n",
       "  [['black', 'african american', 'african-american'],\n",
       "   ['from asia'],\n",
       "   ['multiracial',\n",
       "    'multi-racial',\n",
       "    'mixed',\n",
       "    'mixed race',\n",
       "    'biracial',\n",
       "    'interracial'],\n",
       "   ['caucasian'],\n",
       "   ['latino'],\n",
       "   ['native',\n",
       "    'natives',\n",
       "    'indians',\n",
       "    'indian',\n",
       "    'american indian',\n",
       "    'alaska native']],\n",
       "  ['ethnicity',\n",
       "   'race',\n",
       "   'racial background',\n",
       "   'ethnic group',\n",
       "   'ethnic type',\n",
       "   'racial indentity',\n",
       "   'community',\n",
       "   'minorities']],\n",
       " 'reason_for_termination': [['return to school',\n",
       "   'another position',\n",
       "   'unhappy',\n",
       "   'military',\n",
       "   'gross misconduct',\n",
       "   'hours',\n",
       "   'medical issues',\n",
       "   'relocation out of area',\n",
       "   'more money',\n",
       "   'career change',\n",
       "   'n/a - has not started yet',\n",
       "   'retiring',\n",
       "   'n/a - still employed',\n",
       "   'attendance',\n",
       "   'no-call no-show',\n",
       "   'maternity leave - did not return',\n",
       "   'performance'],\n",
       "  [['went back to school',\n",
       "    'had to go to school again',\n",
       "    'needed to go back to school',\n",
       "    'went back to college'],\n",
       "   ['took on another job',\n",
       "    'landed a new position',\n",
       "    'changed positions',\n",
       "    'got a new position',\n",
       "    'found a new position'],\n",
       "   [\"wasn't happy\",\n",
       "    \"didn't like his job\",\n",
       "    \"didn't like her job\",\n",
       "    'hated the job',\n",
       "    'disliked the job',\n",
       "    \"didn't enjoy the job\",\n",
       "    \"didn't like his work\",\n",
       "    \"didn't like her work\"],\n",
       "   ['joined the military',\n",
       "    'went to the military',\n",
       "    'left for the military',\n",
       "    'enlisted in the military',\n",
       "    'was drafted into the military'],\n",
       "   nan,\n",
       "   nan,\n",
       "   ['got sick', 'fell sick', 'medical problems', 'sick'],\n",
       "   ['was relocated',\n",
       "    'had to relocated',\n",
       "    'was assigned to a new location',\n",
       "    'was assigned to a different location'],\n",
       "   nan,\n",
       "   ['changed careers'],\n",
       "   nan,\n",
       "   ['retired', 'went into retirement'],\n",
       "   nan,\n",
       "   ['poor attendance', 'bad attendance'],\n",
       "   nan,\n",
       "   ['did not come back from maternity leave', 'had a kid and dissapeared'],\n",
       "   ['poor performance', 'performed below expectations']],\n",
       "  []],\n",
       " 'employment_status': [['terminated for cause',\n",
       "   'leave of absence',\n",
       "   'active',\n",
       "   'voluntarily terminated',\n",
       "   'future start'],\n",
       "  [['fired', 'let go', 'evicted', 'kicked out', 'removed', 'dismissed'],\n",
       "   ['on absence leave'],\n",
       "   ['currently employed',\n",
       "    'currently working',\n",
       "    'currently works',\n",
       "    'still works at',\n",
       "    'still working at',\n",
       "    'still work at',\n",
       "    'actively employed'],\n",
       "   ['quit', 'quitted', 'resigned', 'sent in a resignation'],\n",
       "   ['will start at a future time',\n",
       "    'will start later',\n",
       "    'will start some time in the future']],\n",
       "  ['renounce', 'employment status', 'current job status']],\n",
       " 'department': [['executive office',\n",
       "   'admin offices',\n",
       "   'production',\n",
       "   'it/is',\n",
       "   'software engineering',\n",
       "   'sales'],\n",
       "  [nan,\n",
       "   ['administration',\n",
       "    'office of admin',\n",
       "    'office of administration',\n",
       "    'admin office',\n",
       "    'administration office'],\n",
       "   nan,\n",
       "   ['IT',\n",
       "    'IS',\n",
       "    'Information Technology',\n",
       "    'Information Systems',\n",
       "    'Info Tech',\n",
       "    'Info Sys'],\n",
       "   ['programming', 'coding', 'software development'],\n",
       "   nan],\n",
       "  ['department',\n",
       "   'team',\n",
       "   'group',\n",
       "   'section',\n",
       "   'division',\n",
       "   'sector',\n",
       "   'office',\n",
       "   'office group',\n",
       "   'dpt',\n",
       "   'dept',\n",
       "   'dept.',\n",
       "   'branch',\n",
       "   'organization',\n",
       "   'organisation',\n",
       "   'org',\n",
       "   'company',\n",
       "   'corporation']],\n",
       " 'position': [['it manager - infra',\n",
       "   'cio',\n",
       "   'sales manager',\n",
       "   'president & ceo',\n",
       "   'administrative assistant',\n",
       "   'database administrator',\n",
       "   'area sales manager',\n",
       "   'it director',\n",
       "   'sr. accountant',\n",
       "   'it manager - support',\n",
       "   'production technician ii',\n",
       "   'network engineer',\n",
       "   'sr. network engineer',\n",
       "   'shared services manager',\n",
       "   'accountant i',\n",
       "   'it support',\n",
       "   'software engineering manager',\n",
       "   'production technician i',\n",
       "   'director of operations',\n",
       "   'director of sales',\n",
       "   'sr. dba',\n",
       "   'it manager - db',\n",
       "   'software engineer',\n",
       "   'production manager'],\n",
       "  [nan,\n",
       "   ['chief information officer'],\n",
       "   nan,\n",
       "   ['chief executive officer',\n",
       "    'ceo',\n",
       "    'prez',\n",
       "    'president',\n",
       "    'executive',\n",
       "    'highest rank',\n",
       "    'highest ranked',\n",
       "    'CEO',\n",
       "    'highest ranking'],\n",
       "   nan,\n",
       "   ['db admin', 'db administrator', 'database admin'],\n",
       "   nan,\n",
       "   ['director of it'],\n",
       "   ['senior accountant'],\n",
       "   nan,\n",
       "   ['production technician 2', 'production technician two'],\n",
       "   nan,\n",
       "   ['senior network engineer'],\n",
       "   nan,\n",
       "   ['accountant 1', 'accountant one'],\n",
       "   ['tech support'],\n",
       "   nan,\n",
       "   ['production technician 1', 'production technician one'],\n",
       "   ['operations director'],\n",
       "   ['sales director'],\n",
       "   ['senior database administrator',\n",
       "    'senior db admin',\n",
       "    'senior db administrator'],\n",
       "   nan,\n",
       "   ['software developer', 'programmer'],\n",
       "   nan],\n",
       "  ['title',\n",
       "   'job title',\n",
       "   'role',\n",
       "   'position',\n",
       "   'level in the organization',\n",
       "   'level',\n",
       "   'job',\n",
       "   'occupation']],\n",
       " 'manager': [['manager'],\n",
       "  [['manager name',\n",
       "    'manager',\n",
       "    'incharge',\n",
       "    'supervisor',\n",
       "    'mentor',\n",
       "    'leadership',\n",
       "    'boss',\n",
       "    'management',\n",
       "    'head',\n",
       "    'lead',\n",
       "    'chairman',\n",
       "    'working for',\n",
       "    'works for',\n",
       "    'work for',\n",
       "    'manage',\n",
       "    'managed by',\n",
       "    'managing',\n",
       "    'manages',\n",
       "    'reports to',\n",
       "    'report to',\n",
       "    'reporting to',\n",
       "    'reporting',\n",
       "    'working under',\n",
       "    'is under',\n",
       "    'leads',\n",
       "    'in charge of']],\n",
       "  []],\n",
       " 'employee_source': [['information session',\n",
       "   'company intranet - partner',\n",
       "   'social networks - facebook twitter etc',\n",
       "   'newspager/magazine',\n",
       "   'internet search',\n",
       "   'billboard',\n",
       "   'pay per click',\n",
       "   'on-line web application',\n",
       "   'glassdoor',\n",
       "   'professional society',\n",
       "   'monster.com',\n",
       "   'diversity job fair',\n",
       "   'careerbuilder',\n",
       "   'mbta ads',\n",
       "   'word of mouth',\n",
       "   'other',\n",
       "   'vendor referral',\n",
       "   'on-campus recruiting',\n",
       "   'website banner ads',\n",
       "   'employee referral'],\n",
       "  [['info session'],\n",
       "   nan,\n",
       "   ['social media',\n",
       "    'social media apps',\n",
       "    'facebook',\n",
       "    'instagram',\n",
       "    'twitter',\n",
       "    'snapchat',\n",
       "    'social network'],\n",
       "   ['newspaper', 'magazine'],\n",
       "   ['google',\n",
       "    'bing',\n",
       "    'yahoo',\n",
       "    \"search engine - google bing yahoo'\",\n",
       "    'search engine'],\n",
       "   ['poster'],\n",
       "   ['ppc', 'google ads', 'google ppc', 'ppc google'],\n",
       "   ['application potal', 'job portal'],\n",
       "   ['glass door'],\n",
       "   ['professional group'],\n",
       "   ['monster'],\n",
       "   nan,\n",
       "   nan,\n",
       "   ['advertisement', 'ads'],\n",
       "   ['verbal mention'],\n",
       "   nan,\n",
       "   ['referred by vendor', 'vendor referred'],\n",
       "   ['on-campus job fair', 'career fair'],\n",
       "   nan,\n",
       "   ['referred by employee']],\n",
       "  ['how did you learn about this position',\n",
       "   'how did you find out about this job',\n",
       "   'how did you find out about this position',\n",
       "   'how did you learn about this job. how did you hear about this',\n",
       "   'heard about us',\n",
       "   'hear about us',\n",
       "   'how you heard about us',\n",
       "   'how did you hear of us',\n",
       "   'hear of us']],\n",
       " 'performance_score': [['exceptional',\n",
       "   'fully meets',\n",
       "   'n/a- too early to review',\n",
       "   'pip',\n",
       "   'needs improvement',\n",
       "   'exceeds',\n",
       "   '90-day meets'],\n",
       "  [['extraordinary'],\n",
       "   ['up to the mark', 'meet expectations', 'meet', 'meets'],\n",
       "   nan,\n",
       "   nan,\n",
       "   ['performing badly',\n",
       "    'performing below expectations',\n",
       "    'not meeting standards',\n",
       "    'not meeting expectations',\n",
       "    'poor performance',\n",
       "    'performing poorly',\n",
       "    'poorly performing',\n",
       "    'does not meet',\n",
       "    'do not meet'],\n",
       "   ['beyond expectations',\n",
       "    'more than expected',\n",
       "    'better than expected',\n",
       "    'higher than excpected',\n",
       "    'exceed expectations'],\n",
       "   nan],\n",
       "  ['performance rating',\n",
       "   'performance score',\n",
       "   'performance evaluation',\n",
       "   'performance eval',\n",
       "   'evalation',\n",
       "   'eval',\n",
       "   'performance evaluation history',\n",
       "   'performance eval history',\n",
       "   'performance',\n",
       "   'performance history',\n",
       "   'how well']],\n",
       " 'money': [['pay rate'],\n",
       "  [['salary',\n",
       "    'income',\n",
       "    'pay',\n",
       "    'earn',\n",
       "    'earnings',\n",
       "    'make',\n",
       "    'dollars',\n",
       "    '$',\n",
       "    'paycheck',\n",
       "    'earns',\n",
       "    'earning',\n",
       "    'earners',\n",
       "    'earner',\n",
       "    'incomes',\n",
       "    'paycheck',\n",
       "    'compensation']],\n",
       "  ['earns', 'makes', 'amount']],\n",
       " 'comparator': [['more than', 'equals to', 'less than', 'between'],\n",
       "  [['greater than',\n",
       "    'higher than',\n",
       "    'longer',\n",
       "    'over',\n",
       "    'older than',\n",
       "    'above',\n",
       "    'bigger than',\n",
       "    'larger than'],\n",
       "   ['is exactly', 'is equal to', 'equates to', 'equal to'],\n",
       "   ['lower than', 'below', 'under', 'fewer than', 'younger than'],\n",
       "   ['between', 'in between']],\n",
       "  []],\n",
       " 'dob': [['dob'],\n",
       "  [['birthday',\n",
       "    'birthdate',\n",
       "    'birth date',\n",
       "    'date of birth',\n",
       "    'day of birth',\n",
       "    'born on',\n",
       "    'born on the',\n",
       "    'born in',\n",
       "    'born after',\n",
       "    'born before',\n",
       "    'DOB']],\n",
       "  []],\n",
       " 'time_interval': [['2000s',\n",
       "   '2010s',\n",
       "   '1920s',\n",
       "   '1930s',\n",
       "   '1940s',\n",
       "   '1950s',\n",
       "   '1960s',\n",
       "   '1970s',\n",
       "   '1980s',\n",
       "   '1990s'],\n",
       "  [[\"00's\", \"2000's\", 'two thousands'],\n",
       "   [\"10's\", 'two thousand tens', 'tens', \"2010's\"],\n",
       "   [\"20's\", 'nineteen twenties', 'twenties', \"1920's\"],\n",
       "   [\"30's\", 'nineteen thirties', 'thirties', \"1930's\"],\n",
       "   [\"40's\", 'nineteen forties', 'forties', \"1940's\"],\n",
       "   [\"50's\", 'nineteen fifties', 'fifties', \"1950's\"],\n",
       "   [\"60's\", 'nineteen sixties', 'sixties', \"1960's\"],\n",
       "   [\"70's\", 'nineteen seventies', 'seventies', \"1970's\"],\n",
       "   [\"80's\", 'nineteen eighties', 'eighties', \"1980's\"],\n",
       "   [\"90's\", 'nineteen nineties', 'nineties', \"1990's\"]],\n",
       "  []],\n",
       " 'time_recur': [['yearly', 'monthly', 'weekly', 'daily', 'hourly'],\n",
       "  [['by the year',\n",
       "    'every year',\n",
       "    'each year',\n",
       "    'annually',\n",
       "    'on a yearly basis',\n",
       "    'per year',\n",
       "    'annual',\n",
       "    'in a year',\n",
       "    'in the year'],\n",
       "   ['by the month',\n",
       "    'every month',\n",
       "    'each month',\n",
       "    'month to month',\n",
       "    'month-to-month',\n",
       "    'on a monthly basis',\n",
       "    'per month',\n",
       "    'in a month',\n",
       "    'in the month'],\n",
       "   ['by the week',\n",
       "    'every week',\n",
       "    'each week',\n",
       "    'week by week',\n",
       "    'on a weekly basis',\n",
       "    'per week',\n",
       "    'in a week',\n",
       "    'in the week'],\n",
       "   ['daily',\n",
       "    'every day',\n",
       "    'day by day',\n",
       "    'each day',\n",
       "    'on a daily basis',\n",
       "    'per day',\n",
       "    'in a day',\n",
       "    'in the day'],\n",
       "   ['every hour',\n",
       "    'each hour',\n",
       "    'on an hourly basis',\n",
       "    'on the hour',\n",
       "    'per hour',\n",
       "    'in an hour',\n",
       "    'in  a hour',\n",
       "    'hour',\n",
       "    'in the hour']],\n",
       "  []],\n",
       " 'function': [['percent', 'sum', 'average', 'count'],\n",
       "  [['fraction',\n",
       "    'portion',\n",
       "    'proportion',\n",
       "    'percentage',\n",
       "    '%',\n",
       "    'ratio',\n",
       "    'ratios',\n",
       "    'pct',\n",
       "    'distribution'],\n",
       "   ['total',\n",
       "    'cumulative',\n",
       "    'added up',\n",
       "    'summed up',\n",
       "    'totalled',\n",
       "    'summed',\n",
       "    'combined',\n",
       "    'aggregate'],\n",
       "   ['mean', 'typical', 'typically', 'median', 'avg', 'range'],\n",
       "   ['how many', 'number', 'number of', 'num of', 'headcount', 'count of']],\n",
       "  ['turn over rate']],\n",
       " 'extreme': [['highest', 'lowest'],\n",
       "  [['top', 'maximum', 'most', 'greatest', 'max', 'oldest', 'eldest', 'latest'],\n",
       "   ['least', 'minimum', 'bottom', 'lowest', 'min', 'youngest', 'earliest']],\n",
       "  []],\n",
       " 'employment_action': [['hired', 'fired'],\n",
       "  [['employed',\n",
       "    'recruited',\n",
       "    'start date',\n",
       "    'date of starting employment',\n",
       "    'hiring date',\n",
       "    'date of hire',\n",
       "    'join',\n",
       "    'joined',\n",
       "    'date of hiring',\n",
       "    'began her employment',\n",
       "    'began his employment',\n",
       "    'started working',\n",
       "    'join date',\n",
       "    'worked here',\n",
       "    'started',\n",
       "    'been with us',\n",
       "    'began working for',\n",
       "    'started her experience',\n",
       "    'started his experience',\n",
       "    'been working here',\n",
       "    'been with the company',\n",
       "    'been here',\n",
       "    'long has worked here',\n",
       "    'years of experience',\n",
       "    'of experience',\n",
       "    'employees that have been here',\n",
       "    'working here for'],\n",
       "   ['terminated',\n",
       "    'let go',\n",
       "    'end date',\n",
       "    'date of leaving job',\n",
       "    'date of ending employment',\n",
       "    'date of termination',\n",
       "    'firing date',\n",
       "    'end employment',\n",
       "    'end his employment',\n",
       "    'end her employment',\n",
       "    'out of the company',\n",
       "    'kicked out',\n",
       "    'booted from the company',\n",
       "    'booted from the corporation']],\n",
       "  []],\n",
       " 'date_compare': [['prev', 'post'],\n",
       "  [['before', 'pre', 'prior to'],\n",
       "   ['after',\n",
       "    'last',\n",
       "    'post',\n",
       "    'this year',\n",
       "    'this month',\n",
       "    'this week',\n",
       "    'atleast',\n",
       "    'since']],\n",
       "  []]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_dict['name'][1].append(baby_names)\n",
    "ent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6782"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(baby_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['William LaRotonda',\n",
       " 'Tyrone Steans',\n",
       " 'Estelle Howard',\n",
       " 'Leigh Smith',\n",
       " 'Brandon LeBlanc',\n",
       " 'Sean Quinn',\n",
       " 'Bonalyn Boutwell',\n",
       " 'Amy Foster-Baker',\n",
       " 'Janet King',\n",
       " 'Jennifer Zamora',\n",
       " 'Renee Becker',\n",
       " 'Taisha Goble',\n",
       " 'Daniff Hernandez',\n",
       " 'Jayne Horton',\n",
       " 'Noelle Johnson',\n",
       " 'Thomas Murray',\n",
       " 'Randall Pearson',\n",
       " 'Thelma Petrowsky',\n",
       " 'Lori Roby',\n",
       " 'Jason Salter',\n",
       " 'Kramer Simard',\n",
       " 'Simon Roup',\n",
       " 'Ricardo Ruiz',\n",
       " 'Peter Monroe',\n",
       " 'Eric Dougall',\n",
       " 'Rick Clayton',\n",
       " 'Lisa Galia',\n",
       " 'Leonara Lindsay',\n",
       " 'Alejandro Bacong',\n",
       " 'Anthony Cisco',\n",
       " 'Linda Dolan',\n",
       " 'Maria Gonzalez',\n",
       " 'Carlos Merlos',\n",
       " 'Tanya Morway',\n",
       " 'Anita Shepard',\n",
       " 'Neville Tredinnick',\n",
       " 'Jumil Turpin',\n",
       " 'Karthikeyan Ait Sidi',\n",
       " 'Claudia Carr',\n",
       " 'Donald Favis',\n",
       " 'Bianca Roehrich',\n",
       " 'Ann Daniele',\n",
       " 'Jyoti Lajiri',\n",
       " 'Jeremiah Semizoglou',\n",
       " 'Joe South',\n",
       " 'Sarah Warfield',\n",
       " 'Elisa Bramante',\n",
       " 'Michael Albert',\n",
       " 'Charles Bozzi',\n",
       " 'Webster Butler',\n",
       " 'Elijiah Gray',\n",
       " 'Jonathan Hogland',\n",
       " 'Walter Immediato',\n",
       " 'Ketsia Liebig',\n",
       " 'Brannon Miller',\n",
       " 'Ebonee Peterson',\n",
       " 'Kelley Spirea',\n",
       " 'David Stanley',\n",
       " 'Kissy Sullivan',\n",
       " 'Courtney Wallace',\n",
       " 'Wilson Adinolfi',\n",
       " 'Trina Alagbe',\n",
       " 'Carol Anderson',\n",
       " 'Sam Athwal',\n",
       " 'Rachael Baczenski',\n",
       " 'Francesco Barone',\n",
       " 'Nader Barton',\n",
       " 'Lowan Biden',\n",
       " 'Helen Billis',\n",
       " 'Donna Brill',\n",
       " 'Josephine Bugali',\n",
       " 'Beatrice Chace',\n",
       " 'Lin Chan',\n",
       " 'Donovan Chang',\n",
       " 'Enola Chivukula',\n",
       " 'Caroline Cierpiszewski',\n",
       " 'Elijian Clukey',\n",
       " 'James Cockel',\n",
       " 'Spencer Cole',\n",
       " 'Jean Crimmings',\n",
       " \"Jene'ya Darson\",\n",
       " 'Carl Desimone',\n",
       " 'Geoff Dickinson',\n",
       " 'Lily DiNocco',\n",
       " 'Denisa Dobrin',\n",
       " 'Marianne Eaton',\n",
       " 'Rex England',\n",
       " 'Miguel Estremera',\n",
       " 'April Evensen',\n",
       " 'Susan Ferguson',\n",
       " 'Nilson Fernandes',\n",
       " 'Violeta Ferreira',\n",
       " 'Libby Fidelia',\n",
       " 'Raul Garcia',\n",
       " 'Hamish Garneau',\n",
       " 'Barbara Gaul',\n",
       " 'Mildred Gentry',\n",
       " 'Melisa Gerke',\n",
       " 'Alex Gilles',\n",
       " 'Evelyn Girifalco',\n",
       " 'Shenice Gold',\n",
       " 'Roxana Goyal',\n",
       " 'Paula Gross',\n",
       " 'Joanne Handschiegl',\n",
       " 'Ludwick Harrell',\n",
       " 'Christie Harrington',\n",
       " 'Kara Harrison',\n",
       " 'Rose Ivey',\n",
       " 'Maryellen Jackson',\n",
       " 'Hannah Jacobi',\n",
       " 'Sneha Jhaveri',\n",
       " 'Judy Jung',\n",
       " 'Kathleen Kinsella',\n",
       " 'Alexandra Kirill',\n",
       " 'Bradley Knapp',\n",
       " 'John Kretschmer',\n",
       " 'Enrico Langton',\n",
       " 'Dallas Leach',\n",
       " 'Marilyn Linares',\n",
       " 'Allison Lydon',\n",
       " 'Lindsay Lynch',\n",
       " 'Samuel MacLennan',\n",
       " 'Lauren Mahoney',\n",
       " 'Debbie Mangal',\n",
       " 'Shana Maurice',\n",
       " 'Sandy Mckenna',\n",
       " 'Elizabeth Meads',\n",
       " 'Dawn Motlagh',\n",
       " 'Colombui Ndzi',\n",
       " 'Richard Newman',\n",
       " 'Shari Ngodup',\n",
       " 'Lei-Ming Nguyen',\n",
       " \"Lynn O'hare\",\n",
       " 'Adeel Osturnka',\n",
       " 'Clinton Owad',\n",
       " 'Nina Panjwani',\n",
       " 'Emil Pelech',\n",
       " 'Shakira Perry',\n",
       " 'Hong Pham',\n",
       " 'Brad Pitt',\n",
       " 'Morissa Power',\n",
       " 'Louis Punjabhi',\n",
       " 'Janine Purinton',\n",
       " 'Quinn Rarrick',\n",
       " 'Haley Rivera',\n",
       " 'Alain Robinson',\n",
       " 'Ashley Rose',\n",
       " 'Bruno Rossetti',\n",
       " 'Melinda Saar-Beckles',\n",
       " 'Nore Sadki',\n",
       " 'Kamrin Sander',\n",
       " 'Nori Sewkumar',\n",
       " 'Seffi Shields',\n",
       " 'Taylor Sparks',\n",
       " 'Kristen Squatrito',\n",
       " 'Desiree Tavares',\n",
       " 'Sophia Theamstern',\n",
       " 'Theresa Tinto',\n",
       " 'Jeanette Tippett',\n",
       " 'Mei Trang',\n",
       " 'Abdellah Veera',\n",
       " 'Colleen Volk',\n",
       " 'Anna Von Massenbach',\n",
       " 'Scott Whittier',\n",
       " 'Barry Wilber',\n",
       " 'Jacquelyn Williams',\n",
       " 'Catherine Ybarra',\n",
       " 'Kimberly Beak',\n",
       " 'Dianna Blount',\n",
       " 'Betsy Bondwell',\n",
       " 'Joseph Buccheri',\n",
       " 'Joelle Burke',\n",
       " 'Benjamin Burkett',\n",
       " 'Phil Close',\n",
       " 'Daniel Davis',\n",
       " 'Carla Demita',\n",
       " 'Angela Erilus',\n",
       " 'Megan Faller',\n",
       " 'Nicole Fancett',\n",
       " 'Phylicia Gosciminski',\n",
       " 'Earnest Hankard',\n",
       " 'Adrienne Homberger',\n",
       " 'Julissa Hunts',\n",
       " 'Rosalie Hutter',\n",
       " 'Ming Huynh',\n",
       " 'Tayana Jeannite',\n",
       " 'Yen Johnston',\n",
       " 'Lindsey Langford',\n",
       " 'Mohammed Latif',\n",
       " 'Mathew Linden',\n",
       " 'Robyn Manchester',\n",
       " 'Karen Mancuso',\n",
       " 'Brigit McCarthy',\n",
       " 'Erasumus Monkfish',\n",
       " 'Luisa Monterro',\n",
       " 'Patrick Moran',\n",
       " 'Maliki Moumanil',\n",
       " 'Kristie Nowlan',\n",
       " 'Brooke Oliver',\n",
       " 'Ermine Pelletier',\n",
       " 'May Roberson',\n",
       " 'Adil Sahoo',\n",
       " 'Constance Sloan',\n",
       " 'Lenora Tejeda',\n",
       " 'Kenneth Thibaud',\n",
       " 'Cybil Trzeciak',\n",
       " 'Roger Walker',\n",
       " 'Jordan Winthrop',\n",
       " 'Hang Wolk',\n",
       " 'Edward Buck',\n",
       " 'Jessica Bunbury',\n",
       " 'Michelle Carter',\n",
       " 'Latia Costa',\n",
       " 'Jenna Dietrich',\n",
       " 'Alfred Digitale',\n",
       " 'Maruk Fraval',\n",
       " 'Gerry Friedman',\n",
       " 'Whitney Gill',\n",
       " 'Myriam Givens',\n",
       " 'Mike Guilianno',\n",
       " 'Jeremy Prater',\n",
       " 'Bartholemew Khemmich',\n",
       " 'Giovanni Leruth',\n",
       " 'Jac McKinzie',\n",
       " 'Howard Mullaney',\n",
       " 'Jasmine Onque',\n",
       " 'Travis Ozark',\n",
       " 'Xana Potts',\n",
       " 'Caitrin Strong',\n",
       " 'Sharlene Terry',\n",
       " 'Jackie Valentin',\n",
       " 'Noah Villanueva',\n",
       " 'Debra Houlihan',\n",
       " 'Donysha Kampew',\n",
       " 'Colby Andreola',\n",
       " 'Judith Carabbio',\n",
       " 'Keyla Del Bosque',\n",
       " 'Sandra Martin',\n",
       " 'Luke Patronick',\n",
       " 'Adell Saada',\n",
       " 'Andrew Szabo',\n",
       " 'Mia Brown',\n",
       " 'Ivan Rogers',\n",
       " 'Julia Soto',\n",
       " 'Nan Singh',\n",
       " '']"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_dict['name'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['andrew szabo', 'Andrew', 'andrew', 'Szabo', 'szabo']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_dict['name'][1][240]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Labelling Check</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>get_info</th>\n",
       "      <th>get_aggregate</th>\n",
       "      <th>get_employees</th>\n",
       "      <th>get_salary</th>\n",
       "      <th>get_salary_aggregate</th>\n",
       "      <th>get_salary_employees</th>\n",
       "      <th>get_date</th>\n",
       "      <th>get_date_range_aggregate</th>\n",
       "      <th>get_date_range_employees</th>\n",
       "      <th>get_hierarchy_up</th>\n",
       "      <th>get_hierarchy_down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is {Phylicia Gosciminski|name}s org role</td>\n",
       "      <td>{percent|function} employees {below|comparator...</td>\n",
       "      <td>{female|sex} employees</td>\n",
       "      <td>Amount that {Julia|name} gets {paid|money}</td>\n",
       "      <td>among all of the employees that found their jo...</td>\n",
       "      <td>Which {Sr. DBA|position} {earns|money} the {mo...</td>\n",
       "      <td>What year was {Lily DiNocco|name} {let go|empl...</td>\n",
       "      <td>{percent|function} of employees {born|dob} in ...</td>\n",
       "      <td>I want {male|sex} {born|dob} in the {1930s|tim...</td>\n",
       "      <td>is {Charles Bozzi|name} the {mentor|manager} f...</td>\n",
       "      <td>can i have the names of employees who {report ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What position is {ivan|name} in?</td>\n",
       "      <td>{count|function} of workers are {less than|com...</td>\n",
       "      <td>employees {hispanic|racedesc}?</td>\n",
       "      <td>{joanne handschiegl|name} {each month|time_rec...</td>\n",
       "      <td>{sum|function} {pay|money} for {female|sex}?</td>\n",
       "      <td>Which employee(s) have {lowest|extreme} {incom...</td>\n",
       "      <td>Has {Sarah Warfield|name} been working here fo...</td>\n",
       "      <td>{1974|sys_time} {born|dob} employees {percent|...</td>\n",
       "      <td>Which employees did we {get rid of|employment_...</td>\n",
       "      <td>is {Peter Monroe|name} {managing|manager} {Amy...</td>\n",
       "      <td>which employees is {Ivan singh|name} the {mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why did {Megan|name} get {fired|employment_act...</td>\n",
       "      <td>{How many|function} employees are {C-levels|po...</td>\n",
       "      <td>get me the {youngest|extreme} {five|sys_number...</td>\n",
       "      <td>{Mia|name} {earns|money} what amount {each day...</td>\n",
       "      <td>give me the {mean|function} {salary|money} for...</td>\n",
       "      <td>give me the {earners|money} for all of the emp...</td>\n",
       "      <td>What was the exact date when {desiree|name} wa...</td>\n",
       "      <td>What {percentage|function} of employees were {...</td>\n",
       "      <td>{forties|time_interval} {born|dob} employees w...</td>\n",
       "      <td>who is {helen billis|name}s {managing|manager}...</td>\n",
       "      <td>Who are those employees that are {under|compar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Which department is {adrienne homberger|name} in?</td>\n",
       "      <td>Gimme the {percent|function} of {50|age} year ...</td>\n",
       "      <td>give me a list of {separated employees|marital...</td>\n",
       "      <td>What does {mia|name}'s {paycheck|money} look l...</td>\n",
       "      <td>what is the {highest|extreme} {amount|money} t...</td>\n",
       "      <td>give me the {earnings|money} for all of the em...</td>\n",
       "      <td>How long has Mr.{Knapp|name} worked here?</td>\n",
       "      <td>{1945|sys_time} {born|dob} employees {percent|...</td>\n",
       "      <td>Which are the employees such that in {2005|sys...</td>\n",
       "      <td>who is the {manager|manager} assigned to {luis...</td>\n",
       "      <td>I want to know if {Amy Dunn|name} is a {manger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>is {abdellah veera|name} a {cio|position} or not?</td>\n",
       "      <td>{How many|function} people are {performing bad...</td>\n",
       "      <td>employees that live in {california|state}</td>\n",
       "      <td>{webster|name} is {earning|money} what amount ...</td>\n",
       "      <td>What is the {total|function} {earnings|money} ...</td>\n",
       "      <td>what are {network engineers|position} {making|...</td>\n",
       "      <td>Has {Nicole|name} been working here for {4 yea...</td>\n",
       "      <td>What {percent|function} of employees were {hir...</td>\n",
       "      <td>i want the employees that have been {hired |em...</td>\n",
       "      <td>I want to know if {Sam Athwal|name} {works for...</td>\n",
       "      <td>{Jenna Dietrich|name} is the {supervisor|manag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Is {Mohammed Latif|name} a citizen of the us?</td>\n",
       "      <td>{cumulative|function} {count|function} of empl...</td>\n",
       "      <td>Which employees have been {terminated|employme...</td>\n",
       "      <td>Does {54,000|sys_number} exceed what {jessica|...</td>\n",
       "      <td>what are {women|sex} {making|money} on {averag...</td>\n",
       "      <td>all the {earnings|money} of {female|sex} in th...</td>\n",
       "      <td>What was the date when {ivan rogers|name} was ...</td>\n",
       "      <td>What {percentage|function} of employees have b...</td>\n",
       "      <td>Give me the employees that have a {join date|e...</td>\n",
       "      <td>who is {Thelma Petrowsky|name}'s {managing|man...</td>\n",
       "      <td>Which are all of the employees who are having ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Where does {ivan rogers|name} live?</td>\n",
       "      <td>{average|function} {age of|age} the employees ...</td>\n",
       "      <td>Who {has worked here|employment_action} based ...</td>\n",
       "      <td>{ivan|name} {Salary|money} {Yearly|time_recur}</td>\n",
       "      <td>of all the {sales manager|position}s, what is ...</td>\n",
       "      <td>who {makes|money} the {minimum|extreme} {incom...</td>\n",
       "      <td>When {Sophia Theamstern|name} was {hired|emplo...</td>\n",
       "      <td>can you please tell me what {fraction|function...</td>\n",
       "      <td>Fetch me a list of workers that have their {bi...</td>\n",
       "      <td>does {Dianna Blount|name} {report|manager} to ...</td>\n",
       "      <td>Tell me which employees have {Patrick Moran|na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I want {sarah warfield|name}'s state</td>\n",
       "      <td>What's the {summed|function} {num of|function}...</td>\n",
       "      <td>give me a list of employees that are based in ...</td>\n",
       "      <td>What does {Rose Ivey|name} get for {income|mon...</td>\n",
       "      <td>get me the {average|function} amount that the ...</td>\n",
       "      <td>Get me the {lowest|extreme} {six|sys_number} {...</td>\n",
       "      <td>Fetch me {Francesco Barone|name}'s {Bday|dob}</td>\n",
       "      <td>What {pct|function} of our staff have a {bday|...</td>\n",
       "      <td>get me {senior database admins|position} {born...</td>\n",
       "      <td>get me a list of all of the employees who {sup...</td>\n",
       "      <td>Who are those employees that right now have {C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>how did {dawn|name} hear about our corporation</td>\n",
       "      <td>What is the {total|function} {number of|functi...</td>\n",
       "      <td>Which employees have been with the company lon...</td>\n",
       "      <td>According to the {payroll|money}, how much doe...</td>\n",
       "      <td>{number of|function} people {earning|money} {f...</td>\n",
       "      <td>which employees are {making|money} {less than|...</td>\n",
       "      <td>{Leigh Smith|name} {date of birth|dob}</td>\n",
       "      <td>What {percentage|function} of employees were {...</td>\n",
       "      <td>I want all of the employees in the {sales depa...</td>\n",
       "      <td>list employees who {leads|manager} {Adrienne H...</td>\n",
       "      <td>Gimmmie a list of employees that are currently...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Does {Michael|name} {still work at|employment_...</td>\n",
       "      <td>{average|function} {age of|age} workers who ar...</td>\n",
       "      <td>employees are {under|comparator} {45|sys_numbe...</td>\n",
       "      <td>What is {Brooke oliver|name}'s {each year|time...</td>\n",
       "      <td>give me the {typical|function} take home {sala...</td>\n",
       "      <td>{non-citizen|citizendesc} {paycheck|money}s</td>\n",
       "      <td>{Ashley Rose|name} {birthday|dob}</td>\n",
       "      <td>I want the {total|function} {number of|functio...</td>\n",
       "      <td>Can you tell me whether there are any {June|sy...</td>\n",
       "      <td>{amy dunn|name} {manager|manager} name</td>\n",
       "      <td>i want the name of everyone that is {working f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>is {Ivan Rogers|name} {currently active|employ...</td>\n",
       "      <td>What {count|function} of employees {meet 90-da...</td>\n",
       "      <td>who is {working for|manager} {IT support|posit...</td>\n",
       "      <td>{april Evensen|name} {incomes|money}</td>\n",
       "      <td>What is the {sum|function} of {earnings|money}...</td>\n",
       "      <td>what are {accountant i|position} {paid|money} ...</td>\n",
       "      <td>When was {Francesco Barone|name}'s {hiring dat...</td>\n",
       "      <td>Tell me the {pct|function} of staff that have ...</td>\n",
       "      <td>{November|sys_time} {born|dob} employees</td>\n",
       "      <td>so who is {Rose Ivey|name}'s reporting {manage...</td>\n",
       "      <td>{Janine Purinton|name} is the {mentor|manager}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Is the {software engineering|department} the d...</td>\n",
       "      <td>whats the {added up|function} number of employ...</td>\n",
       "      <td>{eligible noncitizen|citizendesc} employees</td>\n",
       "      <td>{Ivan Rogers|name} {Salary|money} {Daily|time_...</td>\n",
       "      <td>of all the {network engineer|position}s, what ...</td>\n",
       "      <td>who {make|money} a {salary|money} {more than|c...</td>\n",
       "      <td>The date was what when {Allison Lydon|name} be...</td>\n",
       "      <td>{1980|sys_time} {born|dob} employees {total|fu...</td>\n",
       "      <td>who are our {1940's|time_interval} {born|dob} ...</td>\n",
       "      <td>who all is {management|manager} of {Estelle Ho...</td>\n",
       "      <td>I want an employee list with all of the folks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{Adell Saada|name}'s occupation?</td>\n",
       "      <td>Fetch me the {count|function} of managers in t...</td>\n",
       "      <td>Tell me Which employees who are not {us citize...</td>\n",
       "      <td>When we let {ivan rogers|name} go {fired|emplo...</td>\n",
       "      <td>What's the {ratios|function} {earnings|money} ...</td>\n",
       "      <td>{earnings|money} {female|sex}</td>\n",
       "      <td>Please get me {DOB|dob} of {Ludwick Harrell|name}</td>\n",
       "      <td>Fetch me {percent|function} that {started work...</td>\n",
       "      <td>{hispanic|racedesc} employees {born|dob} {afte...</td>\n",
       "      <td>employees that directly {manage|manager} {Jere...</td>\n",
       "      <td>Give me all of the employees hv {Karen Mancuso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>what's {Shakira|name}'s role at the organization</td>\n",
       "      <td>What is the {percentage|function} of {engineer...</td>\n",
       "      <td>All employees from {Alabama|state} state</td>\n",
       "      <td>What does {Rose Ivey|name}'s {make|money} look...</td>\n",
       "      <td>{sr. accountant|position} {total|function} {sa...</td>\n",
       "      <td>Of the employees {hired|employment_action} {af...</td>\n",
       "      <td>{nan|name} {birth date|dob}</td>\n",
       "      <td>{ratio|function} out of all of the employees t...</td>\n",
       "      <td>Which workers at the company have a {birthday|...</td>\n",
       "      <td>Tell me who is Mr.{Enrico Langton|name}'s {man...</td>\n",
       "      <td>{works for|manager} {scott|name}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What is {Julia|name}'s race?</td>\n",
       "      <td>{distribution|function} in department with pri...</td>\n",
       "      <td>show me {multi-racial|racedesc} employees</td>\n",
       "      <td>{Payrate|money} {Mia Brown|name}</td>\n",
       "      <td>{total|function} {number of|function} employee...</td>\n",
       "      <td>{paycheck|money} {male|sex}</td>\n",
       "      <td>What was {Estelle|name}s {start date|employmen...</td>\n",
       "      <td>what is the {fraction|function} of employees t...</td>\n",
       "      <td>{seventies|time_interval} {born|dob} employees...</td>\n",
       "      <td>is {Andrew Szabo|name} {head|manager} of {Patr...</td>\n",
       "      <td>Which employees have {ivan|name} as their {man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>how did {Ivan Rogers|name} hear about us</td>\n",
       "      <td>{ratio|function} employees work in {OH|state}</td>\n",
       "      <td>{widowed|maritaldesc} employees</td>\n",
       "      <td>Tell me how much {Robyn Manchester|name} {earn...</td>\n",
       "      <td>fetch me the {min|extreme} {paycheck|money} fo...</td>\n",
       "      <td>Who {earns|money} the {most|extreme} in the {p...</td>\n",
       "      <td>When was {ivan rogers|name} {born|dob}?</td>\n",
       "      <td>{count|function} employees {born|dob} {before|...</td>\n",
       "      <td>Get me list of employees that have a {DOB|dob}...</td>\n",
       "      <td>which employees that have a {manager name|mana...</td>\n",
       "      <td>can you tell me whether {Amy|name} is a {boss|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>what is {thomas murray|name}'s race?</td>\n",
       "      <td>What is the {average|function} {performance sc...</td>\n",
       "      <td>employee {managers|position}</td>\n",
       "      <td>What does {Maliki|name}'s {salary|money} look ...</td>\n",
       "      <td>{avg|function} {income|money} for {on-line web...</td>\n",
       "      <td>get the {salaries|money} of employees in the {...</td>\n",
       "      <td>Please Get me {Kelley Spirea|name}'s {Bday|dob}</td>\n",
       "      <td>For all of those that {joined|employment_actio...</td>\n",
       "      <td>Give me a list of employees that were {hired|e...</td>\n",
       "      <td>is {Amy Dunn|name} {managed by|manager} {Peter...</td>\n",
       "      <td>Who are those employees that directly {report|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tell me what is {nan singh|name}'s citizenship...</td>\n",
       "      <td>{How many|function} people are {over|comparato...</td>\n",
       "      <td>Who is our {maximum|extreme} employee?</td>\n",
       "      <td>Does {Brad Pitt|name} {income|money} {more tha...</td>\n",
       "      <td>{How many|function} people are {paid|money} {l...</td>\n",
       "      <td>who are the company's {lowest|extreme} {7|sys_...</td>\n",
       "      <td>What is {nan singh|name}'s {date of birth|dob}?</td>\n",
       "      <td>how many {joined|employment_action} {prior to|...</td>\n",
       "      <td>Tell me about employees who were {hired|employ...</td>\n",
       "      <td>is {Peter Monroe|name} the {manager|manager} f...</td>\n",
       "      <td>All of the employees that are {reporting to|ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>which branch is the one that {Brannon Miller|n...</td>\n",
       "      <td>{sum|function} employees live in {UT|state}?</td>\n",
       "      <td>Show {single|maritaldesc} employees</td>\n",
       "      <td>how much {$|money} does {Carl Desimone|name} m...</td>\n",
       "      <td>amount of {money|money} {earned|money} by {fem...</td>\n",
       "      <td>{income|money} of {female|sex} in the org</td>\n",
       "      <td>When did {Seffi Shields|name} get {fired|emplo...</td>\n",
       "      <td>Is there anyone who {joined|employment_action}...</td>\n",
       "      <td>Which employees are {DOB|dob} in the second we...</td>\n",
       "      <td>get me ms. {dunn|name}'s {manager|manager} ful...</td>\n",
       "      <td>is {mia|name} the {manager|manager} of {julia|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What does {sophia theamstern|name} do?</td>\n",
       "      <td>What is the {combined|function} number of empl...</td>\n",
       "      <td>provide me a list of {it manager - infra|posit...</td>\n",
       "      <td>Does {Howard Mullaney|name}'s {$|money} {less ...</td>\n",
       "      <td>what is the {typical|function} {earning|money}...</td>\n",
       "      <td>show me the {min|extreme} {earners|money} that...</td>\n",
       "      <td>When was {Charles Bozzi|name} {hired|employmen...</td>\n",
       "      <td>{count|function} of employees {born|dob} {befo...</td>\n",
       "      <td>{2011|sys_time} {started working here|employme...</td>\n",
       "      <td>{Amy Dunn|name} {manager|manager}</td>\n",
       "      <td>can i get the employee names for those {report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tell me, is {Julissa Hunts|name} a {widowed|ma...</td>\n",
       "      <td>what is the {summed|function} tenure of employ...</td>\n",
       "      <td>employees that are {director of sales|position}</td>\n",
       "      <td>What is {julia soto|name}'s exact {salary|mone...</td>\n",
       "      <td>what is the {average|function} {salary|money} ...</td>\n",
       "      <td>{software engineering|department} {pay|money}</td>\n",
       "      <td>I want the date when {julia soto|name} {starti...</td>\n",
       "      <td>{total|function} employees that have {been wit...</td>\n",
       "      <td>find me the {black or african american|racedes...</td>\n",
       "      <td>is {smith|name} {reporting to|manager} {christ...</td>\n",
       "      <td>{Amy Dunn|name} {manages|manager} which indivi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>is Mr.{julia soto|name} based in {Oregon|state}</td>\n",
       "      <td>{percent|function} employees work in {IN|state}</td>\n",
       "      <td>get me a list of {cio|position} staff</td>\n",
       "      <td>{jeanette|name} {earns|money} {every year|time...</td>\n",
       "      <td>what {portion|function} of employees that {wor...</td>\n",
       "      <td>I want a list with {pay|money} of employees th...</td>\n",
       "      <td>When was {Carla Demita|name}'s {join|employmen...</td>\n",
       "      <td>{How many|function} employees were {born|dob} ...</td>\n",
       "      <td>Which employees are {born|dob} in the second w...</td>\n",
       "      <td>who is Ms. {Debra Houlihan|name} {supervisor|m...</td>\n",
       "      <td>Get me an employee list with people who {work ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>what {department|department} does {nan singh|n...</td>\n",
       "      <td>{total|function} employees are that {female|sex}?</td>\n",
       "      <td>employee with the {highest|extreme} {age|age}</td>\n",
       "      <td>How much is {nan|name} {making|money} on {Payr...</td>\n",
       "      <td>what is the {min|extreme} {earning|money} in t...</td>\n",
       "      <td>what are {it director|position} {making|money}...</td>\n",
       "      <td>What was {nan|name}'s {date of hiring|employme...</td>\n",
       "      <td>what is the {total|function} {number of|functi...</td>\n",
       "      <td>Show me {female|sex}s {born|dob} in the {ninet...</td>\n",
       "      <td>whats the person that {Anita Shepard|name} has...</td>\n",
       "      <td>for which employees is {christie|name} the {bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>how {old|age} is {Michael|name} and is he a bo...</td>\n",
       "      <td>{percentage|function} working here that r {mal...</td>\n",
       "      <td>{accountant i|position} employees</td>\n",
       "      <td>How much does Cisco give {nan|name} in {$|mone...</td>\n",
       "      <td>what is the {fraction|function} of {female|sex...</td>\n",
       "      <td>Tell me the employee that {works under|manager...</td>\n",
       "      <td>tell me {birth date|dob} of {Lei-Ming Nguyen|n...</td>\n",
       "      <td>Can you {count|function} the number of people ...</td>\n",
       "      <td>Which employees were not yet {born|dob} when {...</td>\n",
       "      <td>{Nori Sewkumar|name} is the {reporting|manager...</td>\n",
       "      <td>if There is anyone {working for|manager} Mr. {...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>whats {Daniff HerIvandez|name}'s race?</td>\n",
       "      <td>{How many|function} employees work for {Michae...</td>\n",
       "      <td>Which employees were {join date|employment_act...</td>\n",
       "      <td>Is {50k|sys_number} {more than|comparator} wha...</td>\n",
       "      <td>what is the {total|function} amount of {money|...</td>\n",
       "      <td>Which employee(s) have {highest|extreme} {payc...</td>\n",
       "      <td>When {Amy|name} was {born|dob}, what was the m...</td>\n",
       "      <td>i want the {count|function} of employees that ...</td>\n",
       "      <td>Which people weren't yet {born|dob} when {9/11...</td>\n",
       "      <td>who is the {boss|manager} of {James Cockel|nam...</td>\n",
       "      <td>who {works for|manager} {Ivan Rogers|name}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What is {Hakim|name}'s level in the organization?</td>\n",
       "      <td>{cumulative|function} {num of|function} employ...</td>\n",
       "      <td>employees have a {start date|employment_action...</td>\n",
       "      <td>{melisa|name} {each day|time_recur} {earnings|...</td>\n",
       "      <td>{Mean|function} {pay|money} of workers {hired|...</td>\n",
       "      <td>list employees {making|money} {more than|compa...</td>\n",
       "      <td>When was it that {Barry Wilber|name} {started ...</td>\n",
       "      <td>{last|date_compare} {three months|sys_duration...</td>\n",
       "      <td>{June|sys_time} {born|dob} in - employees</td>\n",
       "      <td>Find me who is the person {Jackie|name} is {re...</td>\n",
       "      <td>can i have all of the names who report to {Nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>the reason for {paula gross|name}'s sudden {en...</td>\n",
       "      <td>{How many|function} employees are {above|compa...</td>\n",
       "      <td>which staff work in {IT|department}</td>\n",
       "      <td>What does {Eric Dougall|name} {earnings|money}...</td>\n",
       "      <td>Describe the {salary|money} {range|function} f...</td>\n",
       "      <td>give me the {salaries|money} of {interracial|r...</td>\n",
       "      <td>What was day when {nan singh|name} was {born|dob}</td>\n",
       "      <td>Were there more {men|sex} with {birthdays|dob}...</td>\n",
       "      <td>{2013|sys_time} {hired|employment_action} empl...</td>\n",
       "      <td>Get me the person who is {managing|manager} {e...</td>\n",
       "      <td>Is {Amy Dunn|name} a {manager|manager}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>how {old|age} is {hogland|name} and is he a {b...</td>\n",
       "      <td>{cumulative|function} of Employees in departme...</td>\n",
       "      <td>employees between the {age of|age} {20|sys_num...</td>\n",
       "      <td>What does {thelma petrowsky|name} {earner|mone...</td>\n",
       "      <td>what do {men|sex} {make|money} here on {averag...</td>\n",
       "      <td>For employees {hired|employment_action} {betwe...</td>\n",
       "      <td>Has {Kristen Squatrito|name} been working here...</td>\n",
       "      <td>{how many|function} new employees based out of...</td>\n",
       "      <td>{fifteen|sys_number} {most|extreme} recently {...</td>\n",
       "      <td>{boss|manager} name for mr {Bradley Knapp|name}</td>\n",
       "      <td>Are there any workers who {report to|manager} ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Is {28|age} the {age of|age} {lauren mahoney|n...</td>\n",
       "      <td>{Number of|function} {Married|maritaldesc} emp...</td>\n",
       "      <td>who are the {top|extreme} {10|sys_number}{perc...</td>\n",
       "      <td>{dianna blount|name} {earns|money} how much {b...</td>\n",
       "      <td>what is the {lowest|extreme} {income|money} th...</td>\n",
       "      <td>{earnings|money} for people working in the {it...</td>\n",
       "      <td>When {Alexandra Kirill|name} was {joining|empl...</td>\n",
       "      <td>{total|function} of workers {DOB|dob} {prior t...</td>\n",
       "      <td>have there been any employees that have been w...</td>\n",
       "      <td>which employees currently have a {boss|manager...</td>\n",
       "      <td>for which employees is {Jeanette Tippett|name}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>What is Mrs.{Nowlan|name}'s position?</td>\n",
       "      <td>Calculate the {total|function} of employees th...</td>\n",
       "      <td>Which employees {quit working|employment_statu...</td>\n",
       "      <td>What is {Brannon|name}'s {daily basis|time_rec...</td>\n",
       "      <td>what is the {average|function} {income|money} ...</td>\n",
       "      <td>Of all the {area sales manager|position}, whic...</td>\n",
       "      <td>{Violeta Ferreira|name} {started|employment_ac...</td>\n",
       "      <td>{started employment|employment_action} {less t...</td>\n",
       "      <td>{1960's|time_interval} {born|dob} {asian|raced...</td>\n",
       "      <td>Who is {John Reeder|name}'s {manager|manager}?</td>\n",
       "      <td>Tell me who is the worker {reporting|manager} ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>what is {ivan|name} department</td>\n",
       "      <td>NaN</td>\n",
       "      <td>is anyone {married|maritaldesc}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>what is {mia|name}'s department</td>\n",
       "      <td>NaN</td>\n",
       "      <td>is there anyone who is {married|maritaldesc}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>what is {george|name}'s department</td>\n",
       "      <td>NaN</td>\n",
       "      <td>is there anyone that is {married|maritaldesc}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>what is {Nan Singh|name}s department</td>\n",
       "      <td>NaN</td>\n",
       "      <td>is anyone thats {married|maritaldesc}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>{eric|name}'s position is what</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people who are {married|maritaldesc}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>{miguel|name}'s position is what</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people who are {married|maritaldesc}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>{mey|name}'s position is what</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the {highest ranking|position} employee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>{abdellah|name}'s position is what</td>\n",
       "      <td>NaN</td>\n",
       "      <td>who is the {highest ranking|position} employee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>what is {eric|name} position</td>\n",
       "      <td>NaN</td>\n",
       "      <td>find me the {highest ranking|position} employee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>what is {bruno|name}'s position</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{highest ranking|position} person in the company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>what is {shakira|name}'s position</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{highest ranking|position} people in the company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>what is {timothy|name}s position</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{highest ranking|position} employees in the co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>what is the race of {bruno|name}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>who is the {highest ranking|position}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>tell me the race of {mia|name}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>is there anyone {older than|comparator} {67|sy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>get me the race of {nan|name}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>is there anyone {older than|comparator} {67|sy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>find me the race of {taylor|name}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people {older than|comparator} {54|sys_number}...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>i want to know what {taylor|name}'s race is</td>\n",
       "      <td>NaN</td>\n",
       "      <td>employees {older than|comparator} {67|sys_numb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>tell me what is {taylor|name}'s race</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anybody {older than|comparator} {67|sys_number...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>what is the race of {taylor|name}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>who all are {older than|comparator} {29|sys_nu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>what race is {mia|name}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anyone here {younger than|comparator} {67|sys_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>what race is {nan|name}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{younger than|comparator} {12|sys_number} {yea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>what is the race of {nan|name}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>what is the race of {ivan|name}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>what is the position of {bruno|name}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>whats the position of {ivan|name}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>what department is {mia|name} in?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>which department is {mia|name} in?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>what is {mia|name}'s job title</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>what is {bruno|name}'s job title</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>what is {ivan|name}'s job title</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              get_info  \\\n",
       "2        what is {Phylicia Gosciminski|name}s org role   \n",
       "3                     What position is {ivan|name} in?   \n",
       "4    Why did {Megan|name} get {fired|employment_act...   \n",
       "5    Which department is {adrienne homberger|name} in?   \n",
       "6    is {abdellah veera|name} a {cio|position} or not?   \n",
       "7        Is {Mohammed Latif|name} a citizen of the us?   \n",
       "8                  Where does {ivan rogers|name} live?   \n",
       "9                 I want {sarah warfield|name}'s state   \n",
       "10      how did {dawn|name} hear about our corporation   \n",
       "11   Does {Michael|name} {still work at|employment_...   \n",
       "12   is {Ivan Rogers|name} {currently active|employ...   \n",
       "13   Is the {software engineering|department} the d...   \n",
       "14                    {Adell Saada|name}'s occupation?   \n",
       "15    what's {Shakira|name}'s role at the organization   \n",
       "16                        What is {Julia|name}'s race?   \n",
       "17            how did {Ivan Rogers|name} hear about us   \n",
       "18                what is {thomas murray|name}'s race?   \n",
       "19   tell me what is {nan singh|name}'s citizenship...   \n",
       "20   which branch is the one that {Brannon Miller|n...   \n",
       "21              What does {sophia theamstern|name} do?   \n",
       "22   tell me, is {Julissa Hunts|name} a {widowed|ma...   \n",
       "23     is Mr.{julia soto|name} based in {Oregon|state}   \n",
       "24   what {department|department} does {nan singh|n...   \n",
       "25   how {old|age} is {Michael|name} and is he a bo...   \n",
       "26              whats {Daniff HerIvandez|name}'s race?   \n",
       "27   What is {Hakim|name}'s level in the organization?   \n",
       "28   the reason for {paula gross|name}'s sudden {en...   \n",
       "29   how {old|age} is {hogland|name} and is he a {b...   \n",
       "30   Is {28|age} the {age of|age} {lauren mahoney|n...   \n",
       "31               What is Mrs.{Nowlan|name}'s position?   \n",
       "..                                                 ...   \n",
       "332                     what is {ivan|name} department   \n",
       "333                    what is {mia|name}'s department   \n",
       "334                 what is {george|name}'s department   \n",
       "335               what is {Nan Singh|name}s department   \n",
       "336                    {eric|name}'s position is what    \n",
       "337                  {miguel|name}'s position is what    \n",
       "338                     {mey|name}'s position is what    \n",
       "339                {abdellah|name}'s position is what    \n",
       "340                       what is {eric|name} position   \n",
       "341                    what is {bruno|name}'s position   \n",
       "342                  what is {shakira|name}'s position   \n",
       "343                   what is {timothy|name}s position   \n",
       "344                   what is the race of {bruno|name}   \n",
       "345                     tell me the race of {mia|name}   \n",
       "346                      get me the race of {nan|name}   \n",
       "347                  find me the race of {taylor|name}   \n",
       "348        i want to know what {taylor|name}'s race is   \n",
       "349               tell me what is {taylor|name}'s race   \n",
       "350                  what is the race of {taylor|name}   \n",
       "351                            what race is {mia|name}   \n",
       "352                            what race is {nan|name}   \n",
       "353                     what is the race of {nan|name}   \n",
       "354                    what is the race of {ivan|name}   \n",
       "355               what is the position of {bruno|name}   \n",
       "356                  whats the position of {ivan|name}   \n",
       "357                  what department is {mia|name} in?   \n",
       "358                 which department is {mia|name} in?   \n",
       "359                     what is {mia|name}'s job title   \n",
       "360                   what is {bruno|name}'s job title   \n",
       "361                    what is {ivan|name}'s job title   \n",
       "\n",
       "                                         get_aggregate  \\\n",
       "2    {percent|function} employees {below|comparator...   \n",
       "3    {count|function} of workers are {less than|com...   \n",
       "4    {How many|function} employees are {C-levels|po...   \n",
       "5    Gimme the {percent|function} of {50|age} year ...   \n",
       "6    {How many|function} people are {performing bad...   \n",
       "7    {cumulative|function} {count|function} of empl...   \n",
       "8    {average|function} {age of|age} the employees ...   \n",
       "9    What's the {summed|function} {num of|function}...   \n",
       "10   What is the {total|function} {number of|functi...   \n",
       "11   {average|function} {age of|age} workers who ar...   \n",
       "12   What {count|function} of employees {meet 90-da...   \n",
       "13   whats the {added up|function} number of employ...   \n",
       "14   Fetch me the {count|function} of managers in t...   \n",
       "15   What is the {percentage|function} of {engineer...   \n",
       "16   {distribution|function} in department with pri...   \n",
       "17       {ratio|function} employees work in {OH|state}   \n",
       "18   What is the {average|function} {performance sc...   \n",
       "19   {How many|function} people are {over|comparato...   \n",
       "20        {sum|function} employees live in {UT|state}?   \n",
       "21   What is the {combined|function} number of empl...   \n",
       "22   what is the {summed|function} tenure of employ...   \n",
       "23     {percent|function} employees work in {IN|state}   \n",
       "24   {total|function} employees are that {female|sex}?   \n",
       "25   {percentage|function} working here that r {mal...   \n",
       "26   {How many|function} employees work for {Michae...   \n",
       "27   {cumulative|function} {num of|function} employ...   \n",
       "28   {How many|function} employees are {above|compa...   \n",
       "29   {cumulative|function} of Employees in departme...   \n",
       "30   {Number of|function} {Married|maritaldesc} emp...   \n",
       "31   Calculate the {total|function} of employees th...   \n",
       "..                                                 ...   \n",
       "332                                                NaN   \n",
       "333                                                NaN   \n",
       "334                                                NaN   \n",
       "335                                                NaN   \n",
       "336                                                NaN   \n",
       "337                                                NaN   \n",
       "338                                                NaN   \n",
       "339                                                NaN   \n",
       "340                                                NaN   \n",
       "341                                                NaN   \n",
       "342                                                NaN   \n",
       "343                                                NaN   \n",
       "344                                                NaN   \n",
       "345                                                NaN   \n",
       "346                                                NaN   \n",
       "347                                                NaN   \n",
       "348                                                NaN   \n",
       "349                                                NaN   \n",
       "350                                                NaN   \n",
       "351                                                NaN   \n",
       "352                                                NaN   \n",
       "353                                                NaN   \n",
       "354                                                NaN   \n",
       "355                                                NaN   \n",
       "356                                                NaN   \n",
       "357                                                NaN   \n",
       "358                                                NaN   \n",
       "359                                                NaN   \n",
       "360                                                NaN   \n",
       "361                                                NaN   \n",
       "\n",
       "                                         get_employees  \\\n",
       "2                               {female|sex} employees   \n",
       "3                       employees {hispanic|racedesc}?   \n",
       "4    get me the {youngest|extreme} {five|sys_number...   \n",
       "5    give me a list of {separated employees|marital...   \n",
       "6            employees that live in {california|state}   \n",
       "7    Which employees have been {terminated|employme...   \n",
       "8    Who {has worked here|employment_action} based ...   \n",
       "9    give me a list of employees that are based in ...   \n",
       "10   Which employees have been with the company lon...   \n",
       "11   employees are {under|comparator} {45|sys_numbe...   \n",
       "12   who is {working for|manager} {IT support|posit...   \n",
       "13         {eligible noncitizen|citizendesc} employees   \n",
       "14   Tell me Which employees who are not {us citize...   \n",
       "15            All employees from {Alabama|state} state   \n",
       "16           show me {multi-racial|racedesc} employees   \n",
       "17                     {widowed|maritaldesc} employees   \n",
       "18                        employee {managers|position}   \n",
       "19              Who is our {maximum|extreme} employee?   \n",
       "20                 Show {single|maritaldesc} employees   \n",
       "21   provide me a list of {it manager - infra|posit...   \n",
       "22     employees that are {director of sales|position}   \n",
       "23               get me a list of {cio|position} staff   \n",
       "24       employee with the {highest|extreme} {age|age}   \n",
       "25                   {accountant i|position} employees   \n",
       "26   Which employees were {join date|employment_act...   \n",
       "27   employees have a {start date|employment_action...   \n",
       "28                 which staff work in {IT|department}   \n",
       "29   employees between the {age of|age} {20|sys_num...   \n",
       "30   who are the {top|extreme} {10|sys_number}{perc...   \n",
       "31   Which employees {quit working|employment_statu...   \n",
       "..                                                 ...   \n",
       "332                    is anyone {married|maritaldesc}   \n",
       "333       is there anyone who is {married|maritaldesc}   \n",
       "334      is there anyone that is {married|maritaldesc}   \n",
       "335              is anyone thats {married|maritaldesc}   \n",
       "336               people who are {married|maritaldesc}   \n",
       "337               people who are {married|maritaldesc}   \n",
       "338            the {highest ranking|position} employee   \n",
       "339     who is the {highest ranking|position} employee   \n",
       "340    find me the {highest ranking|position} employee   \n",
       "341   {highest ranking|position} person in the company   \n",
       "342   {highest ranking|position} people in the company   \n",
       "343  {highest ranking|position} employees in the co...   \n",
       "344              who is the {highest ranking|position}   \n",
       "345  is there anyone {older than|comparator} {67|sy...   \n",
       "346  is there anyone {older than|comparator} {67|sy...   \n",
       "347  people {older than|comparator} {54|sys_number}...   \n",
       "348  employees {older than|comparator} {67|sys_numb...   \n",
       "349  anybody {older than|comparator} {67|sys_number...   \n",
       "350  who all are {older than|comparator} {29|sys_nu...   \n",
       "351  anyone here {younger than|comparator} {67|sys_...   \n",
       "352  {younger than|comparator} {12|sys_number} {yea...   \n",
       "353                                                NaN   \n",
       "354                                                NaN   \n",
       "355                                                NaN   \n",
       "356                                                NaN   \n",
       "357                                                NaN   \n",
       "358                                                NaN   \n",
       "359                                                NaN   \n",
       "360                                                NaN   \n",
       "361                                                NaN   \n",
       "\n",
       "                                            get_salary  \\\n",
       "2           Amount that {Julia|name} gets {paid|money}   \n",
       "3    {joanne handschiegl|name} {each month|time_rec...   \n",
       "4    {Mia|name} {earns|money} what amount {each day...   \n",
       "5    What does {mia|name}'s {paycheck|money} look l...   \n",
       "6    {webster|name} is {earning|money} what amount ...   \n",
       "7    Does {54,000|sys_number} exceed what {jessica|...   \n",
       "8       {ivan|name} {Salary|money} {Yearly|time_recur}   \n",
       "9    What does {Rose Ivey|name} get for {income|mon...   \n",
       "10   According to the {payroll|money}, how much doe...   \n",
       "11   What is {Brooke oliver|name}'s {each year|time...   \n",
       "12                {april Evensen|name} {incomes|money}   \n",
       "13   {Ivan Rogers|name} {Salary|money} {Daily|time_...   \n",
       "14   When we let {ivan rogers|name} go {fired|emplo...   \n",
       "15   What does {Rose Ivey|name}'s {make|money} look...   \n",
       "16                    {Payrate|money} {Mia Brown|name}   \n",
       "17   Tell me how much {Robyn Manchester|name} {earn...   \n",
       "18   What does {Maliki|name}'s {salary|money} look ...   \n",
       "19   Does {Brad Pitt|name} {income|money} {more tha...   \n",
       "20   how much {$|money} does {Carl Desimone|name} m...   \n",
       "21   Does {Howard Mullaney|name}'s {$|money} {less ...   \n",
       "22   What is {julia soto|name}'s exact {salary|mone...   \n",
       "23   {jeanette|name} {earns|money} {every year|time...   \n",
       "24   How much is {nan|name} {making|money} on {Payr...   \n",
       "25   How much does Cisco give {nan|name} in {$|mone...   \n",
       "26   Is {50k|sys_number} {more than|comparator} wha...   \n",
       "27   {melisa|name} {each day|time_recur} {earnings|...   \n",
       "28   What does {Eric Dougall|name} {earnings|money}...   \n",
       "29   What does {thelma petrowsky|name} {earner|mone...   \n",
       "30   {dianna blount|name} {earns|money} how much {b...   \n",
       "31   What is {Brannon|name}'s {daily basis|time_rec...   \n",
       "..                                                 ...   \n",
       "332                                                NaN   \n",
       "333                                                NaN   \n",
       "334                                                NaN   \n",
       "335                                                NaN   \n",
       "336                                                NaN   \n",
       "337                                                NaN   \n",
       "338                                                NaN   \n",
       "339                                                NaN   \n",
       "340                                                NaN   \n",
       "341                                                NaN   \n",
       "342                                                NaN   \n",
       "343                                                NaN   \n",
       "344                                                NaN   \n",
       "345                                                NaN   \n",
       "346                                                NaN   \n",
       "347                                                NaN   \n",
       "348                                                NaN   \n",
       "349                                                NaN   \n",
       "350                                                NaN   \n",
       "351                                                NaN   \n",
       "352                                                NaN   \n",
       "353                                                NaN   \n",
       "354                                                NaN   \n",
       "355                                                NaN   \n",
       "356                                                NaN   \n",
       "357                                                NaN   \n",
       "358                                                NaN   \n",
       "359                                                NaN   \n",
       "360                                                NaN   \n",
       "361                                                NaN   \n",
       "\n",
       "                                  get_salary_aggregate  \\\n",
       "2    among all of the employees that found their jo...   \n",
       "3         {sum|function} {pay|money} for {female|sex}?   \n",
       "4    give me the {mean|function} {salary|money} for...   \n",
       "5    what is the {highest|extreme} {amount|money} t...   \n",
       "6    What is the {total|function} {earnings|money} ...   \n",
       "7    what are {women|sex} {making|money} on {averag...   \n",
       "8    of all the {sales manager|position}s, what is ...   \n",
       "9    get me the {average|function} amount that the ...   \n",
       "10   {number of|function} people {earning|money} {f...   \n",
       "11   give me the {typical|function} take home {sala...   \n",
       "12   What is the {sum|function} of {earnings|money}...   \n",
       "13   of all the {network engineer|position}s, what ...   \n",
       "14   What's the {ratios|function} {earnings|money} ...   \n",
       "15   {sr. accountant|position} {total|function} {sa...   \n",
       "16   {total|function} {number of|function} employee...   \n",
       "17   fetch me the {min|extreme} {paycheck|money} fo...   \n",
       "18   {avg|function} {income|money} for {on-line web...   \n",
       "19   {How many|function} people are {paid|money} {l...   \n",
       "20   amount of {money|money} {earned|money} by {fem...   \n",
       "21   what is the {typical|function} {earning|money}...   \n",
       "22   what is the {average|function} {salary|money} ...   \n",
       "23   what {portion|function} of employees that {wor...   \n",
       "24   what is the {min|extreme} {earning|money} in t...   \n",
       "25   what is the {fraction|function} of {female|sex...   \n",
       "26   what is the {total|function} amount of {money|...   \n",
       "27   {Mean|function} {pay|money} of workers {hired|...   \n",
       "28   Describe the {salary|money} {range|function} f...   \n",
       "29   what do {men|sex} {make|money} here on {averag...   \n",
       "30   what is the {lowest|extreme} {income|money} th...   \n",
       "31   what is the {average|function} {income|money} ...   \n",
       "..                                                 ...   \n",
       "332                                                NaN   \n",
       "333                                                NaN   \n",
       "334                                                NaN   \n",
       "335                                                NaN   \n",
       "336                                                NaN   \n",
       "337                                                NaN   \n",
       "338                                                NaN   \n",
       "339                                                NaN   \n",
       "340                                                NaN   \n",
       "341                                                NaN   \n",
       "342                                                NaN   \n",
       "343                                                NaN   \n",
       "344                                                NaN   \n",
       "345                                                NaN   \n",
       "346                                                NaN   \n",
       "347                                                NaN   \n",
       "348                                                NaN   \n",
       "349                                                NaN   \n",
       "350                                                NaN   \n",
       "351                                                NaN   \n",
       "352                                                NaN   \n",
       "353                                                NaN   \n",
       "354                                                NaN   \n",
       "355                                                NaN   \n",
       "356                                                NaN   \n",
       "357                                                NaN   \n",
       "358                                                NaN   \n",
       "359                                                NaN   \n",
       "360                                                NaN   \n",
       "361                                                NaN   \n",
       "\n",
       "                                  get_salary_employees  \\\n",
       "2    Which {Sr. DBA|position} {earns|money} the {mo...   \n",
       "3    Which employee(s) have {lowest|extreme} {incom...   \n",
       "4    give me the {earners|money} for all of the emp...   \n",
       "5    give me the {earnings|money} for all of the em...   \n",
       "6    what are {network engineers|position} {making|...   \n",
       "7    all the {earnings|money} of {female|sex} in th...   \n",
       "8    who {makes|money} the {minimum|extreme} {incom...   \n",
       "9    Get me the {lowest|extreme} {six|sys_number} {...   \n",
       "10   which employees are {making|money} {less than|...   \n",
       "11         {non-citizen|citizendesc} {paycheck|money}s   \n",
       "12   what are {accountant i|position} {paid|money} ...   \n",
       "13   who {make|money} a {salary|money} {more than|c...   \n",
       "14                       {earnings|money} {female|sex}   \n",
       "15   Of the employees {hired|employment_action} {af...   \n",
       "16                         {paycheck|money} {male|sex}   \n",
       "17   Who {earns|money} the {most|extreme} in the {p...   \n",
       "18   get the {salaries|money} of employees in the {...   \n",
       "19   who are the company's {lowest|extreme} {7|sys_...   \n",
       "20           {income|money} of {female|sex} in the org   \n",
       "21   show me the {min|extreme} {earners|money} that...   \n",
       "22       {software engineering|department} {pay|money}   \n",
       "23   I want a list with {pay|money} of employees th...   \n",
       "24   what are {it director|position} {making|money}...   \n",
       "25   Tell me the employee that {works under|manager...   \n",
       "26   Which employee(s) have {highest|extreme} {payc...   \n",
       "27   list employees {making|money} {more than|compa...   \n",
       "28   give me the {salaries|money} of {interracial|r...   \n",
       "29   For employees {hired|employment_action} {betwe...   \n",
       "30   {earnings|money} for people working in the {it...   \n",
       "31   Of all the {area sales manager|position}, whic...   \n",
       "..                                                 ...   \n",
       "332                                                NaN   \n",
       "333                                                NaN   \n",
       "334                                                NaN   \n",
       "335                                                NaN   \n",
       "336                                                NaN   \n",
       "337                                                NaN   \n",
       "338                                                NaN   \n",
       "339                                                NaN   \n",
       "340                                                NaN   \n",
       "341                                                NaN   \n",
       "342                                                NaN   \n",
       "343                                                NaN   \n",
       "344                                                NaN   \n",
       "345                                                NaN   \n",
       "346                                                NaN   \n",
       "347                                                NaN   \n",
       "348                                                NaN   \n",
       "349                                                NaN   \n",
       "350                                                NaN   \n",
       "351                                                NaN   \n",
       "352                                                NaN   \n",
       "353                                                NaN   \n",
       "354                                                NaN   \n",
       "355                                                NaN   \n",
       "356                                                NaN   \n",
       "357                                                NaN   \n",
       "358                                                NaN   \n",
       "359                                                NaN   \n",
       "360                                                NaN   \n",
       "361                                                NaN   \n",
       "\n",
       "                                              get_date  \\\n",
       "2    What year was {Lily DiNocco|name} {let go|empl...   \n",
       "3    Has {Sarah Warfield|name} been working here fo...   \n",
       "4    What was the exact date when {desiree|name} wa...   \n",
       "5            How long has Mr.{Knapp|name} worked here?   \n",
       "6    Has {Nicole|name} been working here for {4 yea...   \n",
       "7    What was the date when {ivan rogers|name} was ...   \n",
       "8    When {Sophia Theamstern|name} was {hired|emplo...   \n",
       "9        Fetch me {Francesco Barone|name}'s {Bday|dob}   \n",
       "10              {Leigh Smith|name} {date of birth|dob}   \n",
       "11                   {Ashley Rose|name} {birthday|dob}   \n",
       "12   When was {Francesco Barone|name}'s {hiring dat...   \n",
       "13   The date was what when {Allison Lydon|name} be...   \n",
       "14   Please get me {DOB|dob} of {Ludwick Harrell|name}   \n",
       "15                         {nan|name} {birth date|dob}   \n",
       "16   What was {Estelle|name}s {start date|employmen...   \n",
       "17             When was {ivan rogers|name} {born|dob}?   \n",
       "18     Please Get me {Kelley Spirea|name}'s {Bday|dob}   \n",
       "19     What is {nan singh|name}'s {date of birth|dob}?   \n",
       "20   When did {Seffi Shields|name} get {fired|emplo...   \n",
       "21   When was {Charles Bozzi|name} {hired|employmen...   \n",
       "22   I want the date when {julia soto|name} {starti...   \n",
       "23   When was {Carla Demita|name}'s {join|employmen...   \n",
       "24   What was {nan|name}'s {date of hiring|employme...   \n",
       "25   tell me {birth date|dob} of {Lei-Ming Nguyen|n...   \n",
       "26   When {Amy|name} was {born|dob}, what was the m...   \n",
       "27   When was it that {Barry Wilber|name} {started ...   \n",
       "28   What was day when {nan singh|name} was {born|dob}   \n",
       "29   Has {Kristen Squatrito|name} been working here...   \n",
       "30   When {Alexandra Kirill|name} was {joining|empl...   \n",
       "31   {Violeta Ferreira|name} {started|employment_ac...   \n",
       "..                                                 ...   \n",
       "332                                                NaN   \n",
       "333                                                NaN   \n",
       "334                                                NaN   \n",
       "335                                                NaN   \n",
       "336                                                NaN   \n",
       "337                                                NaN   \n",
       "338                                                NaN   \n",
       "339                                                NaN   \n",
       "340                                                NaN   \n",
       "341                                                NaN   \n",
       "342                                                NaN   \n",
       "343                                                NaN   \n",
       "344                                                NaN   \n",
       "345                                                NaN   \n",
       "346                                                NaN   \n",
       "347                                                NaN   \n",
       "348                                                NaN   \n",
       "349                                                NaN   \n",
       "350                                                NaN   \n",
       "351                                                NaN   \n",
       "352                                                NaN   \n",
       "353                                                NaN   \n",
       "354                                                NaN   \n",
       "355                                                NaN   \n",
       "356                                                NaN   \n",
       "357                                                NaN   \n",
       "358                                                NaN   \n",
       "359                                                NaN   \n",
       "360                                                NaN   \n",
       "361                                                NaN   \n",
       "\n",
       "                              get_date_range_aggregate  \\\n",
       "2    {percent|function} of employees {born|dob} in ...   \n",
       "3    {1974|sys_time} {born|dob} employees {percent|...   \n",
       "4    What {percentage|function} of employees were {...   \n",
       "5    {1945|sys_time} {born|dob} employees {percent|...   \n",
       "6    What {percent|function} of employees were {hir...   \n",
       "7    What {percentage|function} of employees have b...   \n",
       "8    can you please tell me what {fraction|function...   \n",
       "9    What {pct|function} of our staff have a {bday|...   \n",
       "10   What {percentage|function} of employees were {...   \n",
       "11   I want the {total|function} {number of|functio...   \n",
       "12   Tell me the {pct|function} of staff that have ...   \n",
       "13   {1980|sys_time} {born|dob} employees {total|fu...   \n",
       "14   Fetch me {percent|function} that {started work...   \n",
       "15   {ratio|function} out of all of the employees t...   \n",
       "16   what is the {fraction|function} of employees t...   \n",
       "17   {count|function} employees {born|dob} {before|...   \n",
       "18   For all of those that {joined|employment_actio...   \n",
       "19   how many {joined|employment_action} {prior to|...   \n",
       "20   Is there anyone who {joined|employment_action}...   \n",
       "21   {count|function} of employees {born|dob} {befo...   \n",
       "22   {total|function} employees that have {been wit...   \n",
       "23   {How many|function} employees were {born|dob} ...   \n",
       "24   what is the {total|function} {number of|functi...   \n",
       "25   Can you {count|function} the number of people ...   \n",
       "26   i want the {count|function} of employees that ...   \n",
       "27   {last|date_compare} {three months|sys_duration...   \n",
       "28   Were there more {men|sex} with {birthdays|dob}...   \n",
       "29   {how many|function} new employees based out of...   \n",
       "30   {total|function} of workers {DOB|dob} {prior t...   \n",
       "31   {started employment|employment_action} {less t...   \n",
       "..                                                 ...   \n",
       "332                                                NaN   \n",
       "333                                                NaN   \n",
       "334                                                NaN   \n",
       "335                                                NaN   \n",
       "336                                                NaN   \n",
       "337                                                NaN   \n",
       "338                                                NaN   \n",
       "339                                                NaN   \n",
       "340                                                NaN   \n",
       "341                                                NaN   \n",
       "342                                                NaN   \n",
       "343                                                NaN   \n",
       "344                                                NaN   \n",
       "345                                                NaN   \n",
       "346                                                NaN   \n",
       "347                                                NaN   \n",
       "348                                                NaN   \n",
       "349                                                NaN   \n",
       "350                                                NaN   \n",
       "351                                                NaN   \n",
       "352                                                NaN   \n",
       "353                                                NaN   \n",
       "354                                                NaN   \n",
       "355                                                NaN   \n",
       "356                                                NaN   \n",
       "357                                                NaN   \n",
       "358                                                NaN   \n",
       "359                                                NaN   \n",
       "360                                                NaN   \n",
       "361                                                NaN   \n",
       "\n",
       "                              get_date_range_employees  \\\n",
       "2    I want {male|sex} {born|dob} in the {1930s|tim...   \n",
       "3    Which employees did we {get rid of|employment_...   \n",
       "4    {forties|time_interval} {born|dob} employees w...   \n",
       "5    Which are the employees such that in {2005|sys...   \n",
       "6    i want the employees that have been {hired |em...   \n",
       "7    Give me the employees that have a {join date|e...   \n",
       "8    Fetch me a list of workers that have their {bi...   \n",
       "9    get me {senior database admins|position} {born...   \n",
       "10   I want all of the employees in the {sales depa...   \n",
       "11   Can you tell me whether there are any {June|sy...   \n",
       "12            {November|sys_time} {born|dob} employees   \n",
       "13   who are our {1940's|time_interval} {born|dob} ...   \n",
       "14   {hispanic|racedesc} employees {born|dob} {afte...   \n",
       "15   Which workers at the company have a {birthday|...   \n",
       "16   {seventies|time_interval} {born|dob} employees...   \n",
       "17   Get me list of employees that have a {DOB|dob}...   \n",
       "18   Give me a list of employees that were {hired|e...   \n",
       "19   Tell me about employees who were {hired|employ...   \n",
       "20   Which employees are {DOB|dob} in the second we...   \n",
       "21   {2011|sys_time} {started working here|employme...   \n",
       "22   find me the {black or african american|racedes...   \n",
       "23   Which employees are {born|dob} in the second w...   \n",
       "24   Show me {female|sex}s {born|dob} in the {ninet...   \n",
       "25   Which employees were not yet {born|dob} when {...   \n",
       "26   Which people weren't yet {born|dob} when {9/11...   \n",
       "27           {June|sys_time} {born|dob} in - employees   \n",
       "28   {2013|sys_time} {hired|employment_action} empl...   \n",
       "29   {fifteen|sys_number} {most|extreme} recently {...   \n",
       "30   have there been any employees that have been w...   \n",
       "31   {1960's|time_interval} {born|dob} {asian|raced...   \n",
       "..                                                 ...   \n",
       "332                                                NaN   \n",
       "333                                                NaN   \n",
       "334                                                NaN   \n",
       "335                                                NaN   \n",
       "336                                                NaN   \n",
       "337                                                NaN   \n",
       "338                                                NaN   \n",
       "339                                                NaN   \n",
       "340                                                NaN   \n",
       "341                                                NaN   \n",
       "342                                                NaN   \n",
       "343                                                NaN   \n",
       "344                                                NaN   \n",
       "345                                                NaN   \n",
       "346                                                NaN   \n",
       "347                                                NaN   \n",
       "348                                                NaN   \n",
       "349                                                NaN   \n",
       "350                                                NaN   \n",
       "351                                                NaN   \n",
       "352                                                NaN   \n",
       "353                                                NaN   \n",
       "354                                                NaN   \n",
       "355                                                NaN   \n",
       "356                                                NaN   \n",
       "357                                                NaN   \n",
       "358                                                NaN   \n",
       "359                                                NaN   \n",
       "360                                                NaN   \n",
       "361                                                NaN   \n",
       "\n",
       "                                      get_hierarchy_up  \\\n",
       "2    is {Charles Bozzi|name} the {mentor|manager} f...   \n",
       "3    is {Peter Monroe|name} {managing|manager} {Amy...   \n",
       "4    who is {helen billis|name}s {managing|manager}...   \n",
       "5    who is the {manager|manager} assigned to {luis...   \n",
       "6    I want to know if {Sam Athwal|name} {works for...   \n",
       "7    who is {Thelma Petrowsky|name}'s {managing|man...   \n",
       "8    does {Dianna Blount|name} {report|manager} to ...   \n",
       "9    get me a list of all of the employees who {sup...   \n",
       "10   list employees who {leads|manager} {Adrienne H...   \n",
       "11              {amy dunn|name} {manager|manager} name   \n",
       "12   so who is {Rose Ivey|name}'s reporting {manage...   \n",
       "13   who all is {management|manager} of {Estelle Ho...   \n",
       "14   employees that directly {manage|manager} {Jere...   \n",
       "15   Tell me who is Mr.{Enrico Langton|name}'s {man...   \n",
       "16   is {Andrew Szabo|name} {head|manager} of {Patr...   \n",
       "17   which employees that have a {manager name|mana...   \n",
       "18   is {Amy Dunn|name} {managed by|manager} {Peter...   \n",
       "19   is {Peter Monroe|name} the {manager|manager} f...   \n",
       "20   get me ms. {dunn|name}'s {manager|manager} ful...   \n",
       "21                   {Amy Dunn|name} {manager|manager}   \n",
       "22   is {smith|name} {reporting to|manager} {christ...   \n",
       "23   who is Ms. {Debra Houlihan|name} {supervisor|m...   \n",
       "24   whats the person that {Anita Shepard|name} has...   \n",
       "25   {Nori Sewkumar|name} is the {reporting|manager...   \n",
       "26   who is the {boss|manager} of {James Cockel|nam...   \n",
       "27   Find me who is the person {Jackie|name} is {re...   \n",
       "28   Get me the person who is {managing|manager} {e...   \n",
       "29     {boss|manager} name for mr {Bradley Knapp|name}   \n",
       "30   which employees currently have a {boss|manager...   \n",
       "31      Who is {John Reeder|name}'s {manager|manager}?   \n",
       "..                                                 ...   \n",
       "332                                                NaN   \n",
       "333                                                NaN   \n",
       "334                                                NaN   \n",
       "335                                                NaN   \n",
       "336                                                NaN   \n",
       "337                                                NaN   \n",
       "338                                                NaN   \n",
       "339                                                NaN   \n",
       "340                                                NaN   \n",
       "341                                                NaN   \n",
       "342                                                NaN   \n",
       "343                                                NaN   \n",
       "344                                                NaN   \n",
       "345                                                NaN   \n",
       "346                                                NaN   \n",
       "347                                                NaN   \n",
       "348                                                NaN   \n",
       "349                                                NaN   \n",
       "350                                                NaN   \n",
       "351                                                NaN   \n",
       "352                                                NaN   \n",
       "353                                                NaN   \n",
       "354                                                NaN   \n",
       "355                                                NaN   \n",
       "356                                                NaN   \n",
       "357                                                NaN   \n",
       "358                                                NaN   \n",
       "359                                                NaN   \n",
       "360                                                NaN   \n",
       "361                                                NaN   \n",
       "\n",
       "                                    get_hierarchy_down  \n",
       "2    can i have the names of employees who {report ...  \n",
       "3    which employees is {Ivan singh|name} the {mana...  \n",
       "4    Who are those employees that are {under|compar...  \n",
       "5    I want to know if {Amy Dunn|name} is a {manger...  \n",
       "6    {Jenna Dietrich|name} is the {supervisor|manag...  \n",
       "7    Which are all of the employees who are having ...  \n",
       "8    Tell me which employees have {Patrick Moran|na...  \n",
       "9    Who are those employees that right now have {C...  \n",
       "10   Gimmmie a list of employees that are currently...  \n",
       "11   i want the name of everyone that is {working f...  \n",
       "12   {Janine Purinton|name} is the {mentor|manager}...  \n",
       "13   I want an employee list with all of the folks ...  \n",
       "14   Give me all of the employees hv {Karen Mancuso...  \n",
       "15                    {works for|manager} {scott|name}  \n",
       "16   Which employees have {ivan|name} as their {man...  \n",
       "17   can you tell me whether {Amy|name} is a {boss|...  \n",
       "18   Who are those employees that directly {report|...  \n",
       "19   All of the employees that are {reporting to|ma...  \n",
       "20   is {mia|name} the {manager|manager} of {julia|...  \n",
       "21   can i get the employee names for those {report...  \n",
       "22   {Amy Dunn|name} {manages|manager} which indivi...  \n",
       "23   Get me an employee list with people who {work ...  \n",
       "24   for which employees is {christie|name} the {bo...  \n",
       "25   if There is anyone {working for|manager} Mr. {...  \n",
       "26          who {works for|manager} {Ivan Rogers|name}  \n",
       "27   can i have all of the names who report to {Nor...  \n",
       "28              Is {Amy Dunn|name} a {manager|manager}  \n",
       "29   Are there any workers who {report to|manager} ...  \n",
       "30   for which employees is {Jeanette Tippett|name}...  \n",
       "31   Tell me who is the worker {reporting|manager} ...  \n",
       "..                                                 ...  \n",
       "332                                                NaN  \n",
       "333                                                NaN  \n",
       "334                                                NaN  \n",
       "335                                                NaN  \n",
       "336                                                NaN  \n",
       "337                                                NaN  \n",
       "338                                                NaN  \n",
       "339                                                NaN  \n",
       "340                                                NaN  \n",
       "341                                                NaN  \n",
       "342                                                NaN  \n",
       "343                                                NaN  \n",
       "344                                                NaN  \n",
       "345                                                NaN  \n",
       "346                                                NaN  \n",
       "347                                                NaN  \n",
       "348                                                NaN  \n",
       "349                                                NaN  \n",
       "350                                                NaN  \n",
       "351                                                NaN  \n",
       "352                                                NaN  \n",
       "353                                                NaN  \n",
       "354                                                NaN  \n",
       "355                                                NaN  \n",
       "356                                                NaN  \n",
       "357                                                NaN  \n",
       "358                                                NaN  \n",
       "359                                                NaN  \n",
       "360                                                NaN  \n",
       "361                                                NaN  \n",
       "\n",
       "[360 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_txt = pd.read_csv('./custom_scripts/HR Manager Schema - intent_master.csv')\n",
    "intent_txt = intent_txt.iloc[2:, :]\n",
    "intent_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#label_chk(intent_txt, ent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_labels(\"What is the {manager|manager} name of {Julia|name}?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Generate Gazetteers</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_gazetteers(ent_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Generate Mapping.json</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_map_json_files(ent_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Data Augmentation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_swap(sentence, positions, uniq):\n",
    "    chars = list(sentence)\n",
    "    for i in reversed(range(len(positions))):\n",
    "        pos = positions[i]\n",
    "        ent = ''.join(chars[pos[0]:(pos[1] + 1)])\n",
    "        excluded = [] #['age']\n",
    "        #print(\"ENTITY FOUND\")\n",
    "        #print(ent)\n",
    "        kv = get_kv([ent])\n",
    "        #print(kv)       \n",
    "        for i in range(len(kv[0])):\n",
    "            if kv[1][i] in uniq and kv[1][i] not in excluded:\n",
    "                new_ent = \"{\" + random.choice(uniq[kv[1][i]]) + \"|\" + kv[1][i] + '}'\n",
    "                chars[pos[0]:(pos[1]+1)] = list(new_ent)\n",
    "                #print(new_ent)\n",
    "    #print(\"FINAL\")\n",
    "    return \"\".join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Labelling\n",
    "def entity_label_remove(sentence, positions, uniq):\n",
    "    str_list = sentence.replace(\"{\", \"\").replace(\"}\", \"\").split()\n",
    "    for idx, elem in enumerate(str_list):\n",
    "        if \"|\" in elem: str_list[idx] = elem.split('|')[0]\n",
    "    return \" \".join(str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i like to jump'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entity_swap(\"What is the {manager|manager} name of {Julia|name}?\", [[12, 28], [38, 49]], uniq)\n",
    "\" \".join(\"i like to jump\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Variation in name\n",
    "# param name (str) - in form: \"Mia Brown\"\n",
    "# return name (str) - varied name\n",
    "def name_rotate(name):\n",
    "    split = name.split()\n",
    "    choice = random.choice([0,1,2,3])\n",
    "    if choice == 0: return split[0].lower()\n",
    "    elif choice == 1: return split[0] + ' ' + split[1]\n",
    "    elif choice == 2: return split[0].lower() + ' ' + split[1].lower()\n",
    "    else: return split[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kunal sharma'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_rotate('Kunal Sharma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for name in uniq['name']:\n",
    "    for i in ['position', 'job', 'role', 'job title', 'occupation']:\n",
    "        sentences.append(\"What is {\" + name_rotate(name) + \"|name}'s {\" + i + \"|position}?\")\n",
    "        sentences.append(\"What's {\" + name_rotate(name) + \"|name}s {\" + i + \"|position}\")\n",
    "        sentences.append(\"whats {\" + name_rotate(name) + \"|name} {\" + i + \"|position}?\")\n",
    "        sentences.append(\"{\" + name_rotate(name) + \"|name}'s {\" + i + \"|position}\")\n",
    "        sentences.append(\"{\" + name_rotate(name) + \"|name} {\" + i + \"|position}\")\n",
    "        sentences.append(\"{\" + i + \"|position} of {\" + name_rotate(name) + \"|name}\")\n",
    "    for i in ['race']:\n",
    "        sentences.append(\"What is {\" + name_rotate(name) + \"|name}'s {\" + i + \"|racedesc}?\")\n",
    "        sentences.append(\"what's {\" + name_rotate(name) + \"|name}'s {\" + i + \"|racedesc}\")\n",
    "        sentences.append(\"whats {\" + name_rotate(name) + \"|name} {\" + i + \"|racedesc}?\")\n",
    "        sentences.append(\"{\" + name_rotate(name) + \"|name}'s {\" + i + \"|racedesc}\")\n",
    "        sentences.append(\"{\" + i + \"|racedesc} of {\" + name_rotate(name) + \"|name}\")\n",
    "    for i in ['department', 'dept']:\n",
    "        sentences.append(\"what is {\" + name_rotate(name) + \"|name}'s {\" + i + \"|department}?\")\n",
    "        sentences.append(\"what's {\" + name_rotate(name) + \"|name}s {\" + i + \"|department}\")\n",
    "        sentences.append(\"whats {\" + name_rotate(name) + \"|name}'s {\" + i + \"|department}?\")\n",
    "        sentences.append(\"{\" + name_rotate(name) + \"|name}'s {\" + i + \"|department}\")\n",
    "        sentences.append(\"{\" + name_rotate(name) + \"|name} {\" + i + \"|department}\")\n",
    "        sentences.append(\"{\" + i + \"|department} of {\" + name_rotate(name) + \"|name}\")\n",
    "    for i in ['sex', 'gender']:\n",
    "        sentences.append(\"{\"+ name_rotate(name) +\"|name}\" + \" {\" + i +\"|sex}\")\n",
    "        sentences.append(\"what's {\"+ name_rotate(name) +\"|name}'s'\" + \" {\" + i +\"|sex}\")\n",
    "        sentences.append(\"what {\" + i + \"|sex} is \" + \"{\"+ name_rotate(name) +\"|name}?\")\n",
    "        sentences.append(\"{\" + i + \"|sex} of \" + \"{\"+ name_rotate(name) +\"|name}\")\n",
    "        sentences.append(\"what's the {\" + i + \"|sex} of \" + \"{\"+ name_rotate(name) +\"|name}\")\n",
    "        sentences.append(\"{\" + i + \"|sex} that \" + \"{\"+ name_rotate(name) +\"|name} is\")\n",
    "    # sex, gender\n",
    "    sentences.append(\"{\"+ name_rotate(name) +\"|name}\"+\" {state|state}\")\n",
    "    sentences.append(\"what {state|state} is \"+\"{\"+ name_rotate(name) +\"|name} from?\")\n",
    "    sentences.append(\"{state|state} of \"+\"{\"+ name_rotate(name) +\"|name}\")\n",
    "    sentences.append(\"{\"+ name_rotate(name) +\"|name} \"+\"{state|state}\")\n",
    "    sentences.append(\"{\"+ name_rotate(name) +\"|name}'s\"+\" {state|state}\")\n",
    "    sentences.append(\"{state|state} that \"+\"{\"+ name_rotate(name) +\"|name} is in\")\n",
    "    # employment status\n",
    "    sentences.append(\"{\"+ name_rotate(name) +\"|name}\"+\" {employment status|employment_status}\")\n",
    "    sentences.append(\"what is the {employment status|employment_status} of \"+\"{\"+ name_rotate(name) +\"|name}\")\n",
    "    sentences.append(\"{employment status|employment_status} of \"+\"{\"+ name_rotate(name) +\"|name}\")\n",
    "    sentences.append(\"{\"+ name_rotate(name) +\"|name} \" + \"{employment status|employment_status}\")\n",
    "    sentences.append(\"{\"+ name_rotate(name) +\"|name}'s\" + \" {status of employment|employment_status}\")\n",
    "    sentences.append(\"{status of employment|employment_status} that \" + \"{\"+ name_rotate(name) +\"|name} is in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employment status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for name in uniq['name']:\n",
    "    sentences.append(\"{\"+ name_rotate(name) +\"|name}\" + \" {state|state}\")\n",
    "    sentences.append(\"what {state|state} is \" + \"{\"+ name_rotate(name) +\"|name} from?\")\n",
    "    sentences.append(\"{state|state} of \" + \"{\"+ name_rotate(name) +\"|name}\")\n",
    "    sentences.append(\"{state|state} that \" + \"{\"+ name_rotate(name) +\"|name} is in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for emp in ['people', 'workers', 'employees']:\n",
    "    for i in ['non citizen', 'not a citizen', 'non us citizen', 'citizen', 'us citizen', 'not citizens', 'from abroad',\n",
    "                 'immigrant', 'immigrants', 'eligble non citizen', 'non-citizen', 'non-citizens', 'eligible non-citizens']:\n",
    "        sentences.append(\"whats the {count of|function} \"+emp+ \" that are {\"+i+\"|citizendesc}?\")\n",
    "        sentences.append(\"what's the {number of|function} \"+emp+ \" which are {\"+i+\"|citizendesc}\")\n",
    "        sentences.append(\"{total|function} {count of|function} {\"+i+\"|citizendesc}\")\n",
    "        sentences.append(\"{\"+i+\"|citizendesc} {total|function}\")\n",
    "        sentences.append(\"{how many|function} {\"+i+\"|citizendesc}\")\n",
    "        sentences.append(\"whats the {number of|function} {\"+i+\"|citizendesc}\")\n",
    "        sentences.append(\"{\"+i+\"|citizendesc} \" + \"{total|function} {count of|function}\")\n",
    "        sentences.append(\"{number of|function} {\"+i+\"|citizendesc} at this org\")\n",
    "        sentences.append(\"{number of|function} {\"+i+\"|citizendesc} in the company\")\n",
    "        sentences.append(\"{how many|function} {\"+i+\"|citizendesc} are working at this company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for emp in ['people', 'workers', 'employees']:\n",
    "    for i in ['non citizen', 'not a citizen', 'non us citizen', 'citizen', 'us citizen', 'not citizens', 'from abroad',\n",
    "                 'immigrant', 'immigrants', 'eligble non citizen', 'non-citizen', 'non-citizens', 'eligible non-citizens']:\n",
    "        sentences.append(\"what is the {typical|function} {salary|money} of {\"+i+\"|citizendesc} \"+ emp)\n",
    "        sentences.append(\"what is the {average|function} {pay|money} for {\"+i+\"|citizendesc} \"+ emp)\n",
    "        sentences.append(\"whats the {average|function} {pay|money} for {\"+i+\"|citizendesc} \"+ emp)\n",
    "        sentences.append(\"{average|function} {hourly|time_recur} {earnings|money} for {\"+i+\"|citizendesc}\")\n",
    "        sentences.append(\"how much do {\"+i+\"|citizendesc} {earn|money} on {average|function} {hourly|time_recur}\")\n",
    "        sentences.append(\"what do {\"+i+\"|citizendesc} {make|money} on {average|function} {yearly|time_recur}\")\n",
    "        sentences.append(\"{\"+i+\"|citizendesc}\" + \" {earnings|money} {total|function}\")\n",
    "        sentences.append(\"{\"+i+\"|citizendesc}\" + \" {pay|money} {sum|function}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for emp in ['people', 'workers', 'employees']:\n",
    "    for i in ['non citizen', 'not a citizen', 'non us citizen', 'citizen', 'us citizen', 'not citizens', 'from abroad',\n",
    "                 'immigrant', 'immigrants', 'eligble non citizen', 'non-citizen', 'non-citizens', 'eligible non-citizens']:\n",
    "        sentences.append(\"which {\"+i+\"|citizendesc} \" + emp + \" {earns|money} the {most|extreme}\")\n",
    "        sentences.append(\"{\"+i+\"|citizendesc} \" + emp + \" who {makes|money} the {least|extreme}\")\n",
    "        sentences.append(\"get me the {\"+i+\"|citizendesc} {earning|money} the {max|extreme}\")\n",
    "        sentences.append(\"find me the {\"+i+\"|citizendesc} \" + emp + \" {making|money} the {minimum|extreme}\")\n",
    "        sentences.append(\"{earnings|money} of {\"+i+\"|citizendesc} \" + emp)\n",
    "        sentences.append(\"{salaries|money} of {\"+i+\"|citizendesc}\")\n",
    "        sentences.append(\"{paychecks|money} {\"+i+\"|citizendesc}\")\n",
    "        sentences.append(\"{\"+i+\"|citizendesc} {salaries|money}\")\n",
    "        sentences.append(\"{\"+i+\"|citizendesc} \" + emp + \" {salaries|money}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for emp in ['people', 'workers', 'employees']:\n",
    "    for i in ['non citizen', 'not a citizen', 'non us citizen', 'citizen', 'us citizen', 'not citizens', 'from abroad',\n",
    "                 'immigrant', 'immigrants', 'eligble non citizen', 'non-citizen', 'non-citizens', 'eligible non-citizens']:\n",
    "        sentences.append(\"{count|function} of {\"+i+\"|citizendesc} \" + emp + \" {born|dob} {before|date_compare} {1994|sys_time}\")\n",
    "        sentences.append(\"{sum|function} of {\"+i+\"|citizendesc} \" + emp + \" {hired|employment_action} {after|date_compare} {2005|sys_time}\")\n",
    "        sentences.append(\"{count of|function} {\"+i+\"|citizendesc} {let go|employment_action} {prior to|date_compare} {2010|sys_time}\")\n",
    "        sentences.append(\"{\"+i+\"|citizendesc} \" + emp + \" with {birthday|dob} {before|date_compare} {1996|sys_time} {count|function}\" )\n",
    "        sentences.append(\"{\"+i+\"|citizendesc} \" + emp + \" that {joined|employment_action} {after|date_compare} {2013|sys_time} {how many|function}\")\n",
    "        sentences.append(\"{\"+i+\"|citizendesc} \" + emp + \" was {fired|employment_action} {prior to|date_compare} {2009|sys_time} {count|function}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for emp in ['people', 'workers', 'employees']:\n",
    "    for i in ['non citizen', 'not a citizen', 'non us citizen', 'citizen', 'us citizen', 'not citizens', 'from abroad',\n",
    "                 'immigrant', 'immigrants', 'eligble non citizen', 'non-citizen', 'non-citizens', 'eligible non-citizens']:\n",
    "        sentences.append(\"get me a list of {\"+i+\"|citizendesc} \" + emp + \"that have their {birthdays|dob} in the {1970's|time_interval}\")\n",
    "        sentences.append(\"which {\"+i+\"|citizendesc} \" + emp + \" have a {birthday|dob} in {1960|time_interval}\")\n",
    "        sentences.append(\"Find me the names of {\"+i+\"|citizendesc}\" + \" {hired|employment_action} in {2013|sys_time}\")\n",
    "        sentences.append(\"which {\"+i+\"|citizendesc} \"+ emp +\" {joined|employment_action} in {2012|sys_time}\")\n",
    "        sentences.append(\"{\"+i+\"|citizendesc}\"+\" employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['William LaRotonda',\n",
       " 'Tyrone Steans',\n",
       " 'Estelle Howard',\n",
       " 'Leigh Smith',\n",
       " 'Brandon LeBlanc',\n",
       " 'Sean Quinn',\n",
       " 'Bonalyn Boutwell',\n",
       " 'Amy Foster-Baker',\n",
       " 'Janet King',\n",
       " 'Jennifer Zamora',\n",
       " 'Renee Becker',\n",
       " 'Taisha Goble',\n",
       " 'Daniff Hernandez',\n",
       " 'Jayne Horton',\n",
       " 'Noelle Johnson',\n",
       " 'Thomas Murray',\n",
       " 'Randall Pearson',\n",
       " 'Thelma Petrowsky',\n",
       " 'Lori Roby',\n",
       " 'Jason Salter',\n",
       " 'Kramer Simard',\n",
       " 'Simon Roup',\n",
       " 'Ricardo Ruiz',\n",
       " 'Peter Monroe',\n",
       " 'Eric Dougall',\n",
       " 'Rick Clayton',\n",
       " 'Lisa Galia',\n",
       " 'Leonara Lindsay',\n",
       " 'Alejandro Bacong',\n",
       " 'Anthony Cisco',\n",
       " 'Linda Dolan',\n",
       " 'Maria Gonzalez',\n",
       " 'Carlos Merlos',\n",
       " 'Tanya Morway',\n",
       " 'Anita Shepard',\n",
       " 'Neville Tredinnick',\n",
       " 'Jumil Turpin',\n",
       " 'Karthikeyan Ait Sidi',\n",
       " 'Claudia Carr',\n",
       " 'Donald Favis',\n",
       " 'Bianca Roehrich',\n",
       " 'Ann Daniele',\n",
       " 'Jyoti Lajiri',\n",
       " 'Jeremiah Semizoglou',\n",
       " 'Joe South',\n",
       " 'Sarah Warfield',\n",
       " 'Elisa Bramante',\n",
       " 'Michael Albert',\n",
       " 'Charles Bozzi',\n",
       " 'Webster Butler',\n",
       " 'Elijiah Gray',\n",
       " 'Jonathan Hogland',\n",
       " 'Walter Immediato',\n",
       " 'Ketsia Liebig',\n",
       " 'Brannon Miller',\n",
       " 'Ebonee Peterson',\n",
       " 'Kelley Spirea',\n",
       " 'David Stanley',\n",
       " 'Kissy Sullivan',\n",
       " 'Courtney Wallace',\n",
       " 'Wilson Adinolfi',\n",
       " 'Trina Alagbe',\n",
       " 'Carol Anderson',\n",
       " 'Sam Athwal',\n",
       " 'Rachael Baczenski',\n",
       " 'Francesco Barone',\n",
       " 'Nader Barton',\n",
       " 'Lowan Biden',\n",
       " 'Helen Billis',\n",
       " 'Donna Brill',\n",
       " 'Josephine Bugali',\n",
       " 'Beatrice Chace',\n",
       " 'Lin Chan',\n",
       " 'Donovan Chang',\n",
       " 'Enola Chivukula',\n",
       " 'Caroline Cierpiszewski',\n",
       " 'Elijian Clukey',\n",
       " 'James Cockel',\n",
       " 'Spencer Cole',\n",
       " 'Jean Crimmings',\n",
       " \"Jene'ya Darson\",\n",
       " 'Carl Desimone',\n",
       " 'Geoff Dickinson',\n",
       " 'Lily DiNocco',\n",
       " 'Denisa Dobrin',\n",
       " 'Marianne Eaton',\n",
       " 'Rex England',\n",
       " 'Miguel Estremera',\n",
       " 'April Evensen',\n",
       " 'Susan Ferguson',\n",
       " 'Nilson Fernandes',\n",
       " 'Violeta Ferreira',\n",
       " 'Libby Fidelia',\n",
       " 'Raul Garcia',\n",
       " 'Hamish Garneau',\n",
       " 'Barbara Gaul',\n",
       " 'Mildred Gentry',\n",
       " 'Melisa Gerke',\n",
       " 'Alex Gilles',\n",
       " 'Evelyn Girifalco',\n",
       " 'Shenice Gold',\n",
       " 'Roxana Goyal',\n",
       " 'Paula Gross',\n",
       " 'Joanne Handschiegl',\n",
       " 'Ludwick Harrell',\n",
       " 'Christie Harrington',\n",
       " 'Kara Harrison',\n",
       " 'Rose Ivey',\n",
       " 'Maryellen Jackson',\n",
       " 'Hannah Jacobi',\n",
       " 'Sneha Jhaveri',\n",
       " 'Judy Jung',\n",
       " 'Kathleen Kinsella',\n",
       " 'Alexandra Kirill',\n",
       " 'Bradley Knapp',\n",
       " 'John Kretschmer',\n",
       " 'Enrico Langton',\n",
       " 'Dallas Leach',\n",
       " 'Marilyn Linares',\n",
       " 'Allison Lydon',\n",
       " 'Lindsay Lynch',\n",
       " 'Samuel MacLennan',\n",
       " 'Lauren Mahoney',\n",
       " 'Debbie Mangal',\n",
       " 'Shana Maurice',\n",
       " 'Sandy Mckenna',\n",
       " 'Elizabeth Meads',\n",
       " 'Dawn Motlagh',\n",
       " 'Colombui Ndzi',\n",
       " 'Richard Newman',\n",
       " 'Shari Ngodup',\n",
       " 'Lei-Ming Nguyen',\n",
       " \"Lynn O'hare\",\n",
       " 'Adeel Osturnka',\n",
       " 'Clinton Owad',\n",
       " 'Nina Panjwani',\n",
       " 'Emil Pelech',\n",
       " 'Shakira Perry',\n",
       " 'Hong Pham',\n",
       " 'Brad Pitt',\n",
       " 'Morissa Power',\n",
       " 'Louis Punjabhi',\n",
       " 'Janine Purinton',\n",
       " 'Quinn Rarrick',\n",
       " 'Haley Rivera',\n",
       " 'Alain Robinson',\n",
       " 'Ashley Rose',\n",
       " 'Bruno Rossetti',\n",
       " 'Melinda Saar-Beckles',\n",
       " 'Nore Sadki',\n",
       " 'Kamrin Sander',\n",
       " 'Nori Sewkumar',\n",
       " 'Seffi Shields',\n",
       " 'Taylor Sparks',\n",
       " 'Kristen Squatrito',\n",
       " 'Desiree Tavares',\n",
       " 'Sophia Theamstern',\n",
       " 'Theresa Tinto',\n",
       " 'Jeanette Tippett',\n",
       " 'Mei Trang',\n",
       " 'Abdellah Veera',\n",
       " 'Colleen Volk',\n",
       " 'Anna Von Massenbach',\n",
       " 'Scott Whittier',\n",
       " 'Barry Wilber',\n",
       " 'Jacquelyn Williams',\n",
       " 'Catherine Ybarra',\n",
       " 'Kimberly Beak',\n",
       " 'Dianna Blount',\n",
       " 'Betsy Bondwell',\n",
       " 'Joseph Buccheri',\n",
       " 'Joelle Burke',\n",
       " 'Benjamin Burkett',\n",
       " 'Phil Close',\n",
       " 'Daniel Davis',\n",
       " 'Carla Demita',\n",
       " 'Angela Erilus',\n",
       " 'Megan Faller',\n",
       " 'Nicole Fancett',\n",
       " 'Phylicia Gosciminski',\n",
       " 'Earnest Hankard',\n",
       " 'Adrienne Homberger',\n",
       " 'Julissa Hunts',\n",
       " 'Rosalie Hutter',\n",
       " 'Ming Huynh',\n",
       " 'Tayana Jeannite',\n",
       " 'Yen Johnston',\n",
       " 'Lindsey Langford',\n",
       " 'Mohammed Latif',\n",
       " 'Mathew Linden',\n",
       " 'Robyn Manchester',\n",
       " 'Karen Mancuso',\n",
       " 'Brigit McCarthy',\n",
       " 'Erasumus Monkfish',\n",
       " 'Luisa Monterro',\n",
       " 'Patrick Moran',\n",
       " 'Maliki Moumanil',\n",
       " 'Kristie Nowlan',\n",
       " 'Brooke Oliver',\n",
       " 'Ermine Pelletier',\n",
       " 'May Roberson',\n",
       " 'Adil Sahoo',\n",
       " 'Constance Sloan',\n",
       " 'Lenora Tejeda',\n",
       " 'Kenneth Thibaud',\n",
       " 'Cybil Trzeciak',\n",
       " 'Roger Walker',\n",
       " 'Jordan Winthrop',\n",
       " 'Hang Wolk',\n",
       " 'Edward Buck',\n",
       " 'Jessica Bunbury',\n",
       " 'Michelle Carter',\n",
       " 'Latia Costa',\n",
       " 'Jenna Dietrich',\n",
       " 'Alfred Digitale',\n",
       " 'Maruk Fraval',\n",
       " 'Gerry Friedman',\n",
       " 'Whitney Gill',\n",
       " 'Myriam Givens',\n",
       " 'Mike Guilianno',\n",
       " 'Jeremy Prater',\n",
       " 'Bartholemew Khemmich',\n",
       " 'Giovanni Leruth',\n",
       " 'Jac McKinzie',\n",
       " 'Howard Mullaney',\n",
       " 'Jasmine Onque',\n",
       " 'Travis Ozark',\n",
       " 'Xana Potts',\n",
       " 'Caitrin Strong',\n",
       " 'Sharlene Terry',\n",
       " 'Jackie Valentin',\n",
       " 'Noah Villanueva',\n",
       " 'Debra Houlihan',\n",
       " 'Donysha Kampew',\n",
       " 'Colby Andreola',\n",
       " 'Judith Carabbio',\n",
       " 'Keyla Del Bosque',\n",
       " 'Sandra Martin',\n",
       " 'Luke Patronick',\n",
       " 'Adell Saada',\n",
       " 'Andrew Szabo',\n",
       " 'Mia Brown',\n",
       " 'Ivan Rogers',\n",
       " 'Julia Soto',\n",
       " 'Nan Singh']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emp in ['people', 'workers', 'employees']:\n",
    "    for i in ['non citizen', 'not a citizen', 'non us citizen', 'citizen', 'us citizen', 'not citizens', 'from abroad',\n",
    "                 'immigrant', 'immigrants', 'eligble non citizen', 'non-citizen', 'non-citizens', 'eligible non-citizens']:\n",
    "        sentences.append(\"get me a list of {\"+i+\"|citizendesc} \" + emp + \"that have their {birthdays|dob} in the {1970's|time_interval}\")\n",
    "        sentences.append(\"which {\"+i+\"|citizendesc} \" + emp + \" have a {birthday|dob} in {1960|time_interval}\")\n",
    "        sentences.append(\"Find me the names of {\"+i+\"|citizendesc}\" + \" {hired|employment_action} in {2013|sys_time}\")\n",
    "        sentences.append(\"which {\"+i+\"|citizendesc} \"+ emp +\" {joined|employment_action} in {2012|sys_time}\")\n",
    "        sentences.append(\"{\"+i+\"|citizendesc}\"+\" employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for name in uniq['name']:\n",
    "    for i in ['non citizen', 'not a citizen', 'non us citizen', 'citizen', 'us citizen', 'not citizens', 'from abroad',\n",
    "                 'immigrant', 'immigrants', 'eligble non citizen', 'non-citizen', 'non-citizens', 'eligible non-citizens']:\n",
    "        sentences.append(\"is \" + name_rotate(name) + \" a \" + \"{\"+i+\"|citizendesc}?\")\n",
    "        sentences.append(name_rotate(name) + \" {\"+i+\"|citizendesc}?\")\n",
    "        sentences.append(\"{\"+i+\"|citizendesc} \" + name_rotate(name) + \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9555\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "illegal target for annotation (<ipython-input-158-81e9b6e59ee3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-158-81e9b6e59ee3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    '': print(\"op\")\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m illegal target for annotation\n"
     ]
    }
   ],
   "source": [
    "'': print(\"op\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: k[0]\n",
    "except: print(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get me a list of {non citizen|citizendesc} peoplethat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {non citizen|citizendesc} people have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {non citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {non citizen|citizendesc}people {joined|employment_action} in {2012|sys_time}\n",
      "{non citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {not a citizen|citizendesc} peoplethat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {not a citizen|citizendesc} people have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {not a citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {not a citizen|citizendesc}people {joined|employment_action} in {2012|sys_time}\n",
      "{not a citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {non us citizen|citizendesc} peoplethat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {non us citizen|citizendesc} people have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {non us citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {non us citizen|citizendesc}people {joined|employment_action} in {2012|sys_time}\n",
      "{non us citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {citizen|citizendesc} peoplethat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {citizen|citizendesc} people have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {citizen|citizendesc}people {joined|employment_action} in {2012|sys_time}\n",
      "{citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {us citizen|citizendesc} peoplethat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {us citizen|citizendesc} people have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {us citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {us citizen|citizendesc}people {joined|employment_action} in {2012|sys_time}\n",
      "{us citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {not citizens|citizendesc} peoplethat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {not citizens|citizendesc} people have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {not citizens|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {not citizens|citizendesc}people {joined|employment_action} in {2012|sys_time}\n",
      "{not citizens|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {from abroad|citizendesc} peoplethat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {from abroad|citizendesc} people have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {from abroad|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {from abroad|citizendesc}people {joined|employment_action} in {2012|sys_time}\n",
      "{from abroad|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {immigrant|citizendesc} peoplethat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {immigrant|citizendesc} people have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {immigrant|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {immigrant|citizendesc}people {joined|employment_action} in {2012|sys_time}\n",
      "{immigrant|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {immigrants|citizendesc} peoplethat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {immigrants|citizendesc} people have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {immigrants|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {immigrants|citizendesc}people {joined|employment_action} in {2012|sys_time}\n",
      "{immigrants|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {eligble non citizen|citizendesc} peoplethat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {eligble non citizen|citizendesc} people have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {eligble non citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {eligble non citizen|citizendesc}people {joined|employment_action} in {2012|sys_time}\n",
      "{eligble non citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {non-citizen|citizendesc} peoplethat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {non-citizen|citizendesc} people have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {non-citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {non-citizen|citizendesc}people {joined|employment_action} in {2012|sys_time}\n",
      "{non-citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {non-citizens|citizendesc} peoplethat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {non-citizens|citizendesc} people have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {non-citizens|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {non-citizens|citizendesc}people {joined|employment_action} in {2012|sys_time}\n",
      "{non-citizens|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {eligible non-citizens|citizendesc} peoplethat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {eligible non-citizens|citizendesc} people have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {eligible non-citizens|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {eligible non-citizens|citizendesc}people {joined|employment_action} in {2012|sys_time}\n",
      "{eligible non-citizens|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {non citizen|citizendesc} workersthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {non citizen|citizendesc} workers have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {non citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {non citizen|citizendesc}workers {joined|employment_action} in {2012|sys_time}\n",
      "{non citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {not a citizen|citizendesc} workersthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {not a citizen|citizendesc} workers have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {not a citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {not a citizen|citizendesc}workers {joined|employment_action} in {2012|sys_time}\n",
      "{not a citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {non us citizen|citizendesc} workersthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {non us citizen|citizendesc} workers have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {non us citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {non us citizen|citizendesc}workers {joined|employment_action} in {2012|sys_time}\n",
      "{non us citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {citizen|citizendesc} workersthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {citizen|citizendesc} workers have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {citizen|citizendesc}workers {joined|employment_action} in {2012|sys_time}\n",
      "{citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {us citizen|citizendesc} workersthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {us citizen|citizendesc} workers have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {us citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {us citizen|citizendesc}workers {joined|employment_action} in {2012|sys_time}\n",
      "{us citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {not citizens|citizendesc} workersthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {not citizens|citizendesc} workers have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {not citizens|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {not citizens|citizendesc}workers {joined|employment_action} in {2012|sys_time}\n",
      "{not citizens|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {from abroad|citizendesc} workersthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {from abroad|citizendesc} workers have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {from abroad|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {from abroad|citizendesc}workers {joined|employment_action} in {2012|sys_time}\n",
      "{from abroad|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {immigrant|citizendesc} workersthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {immigrant|citizendesc} workers have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {immigrant|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {immigrant|citizendesc}workers {joined|employment_action} in {2012|sys_time}\n",
      "{immigrant|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {immigrants|citizendesc} workersthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {immigrants|citizendesc} workers have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {immigrants|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {immigrants|citizendesc}workers {joined|employment_action} in {2012|sys_time}\n",
      "{immigrants|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {eligble non citizen|citizendesc} workersthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {eligble non citizen|citizendesc} workers have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {eligble non citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {eligble non citizen|citizendesc}workers {joined|employment_action} in {2012|sys_time}\n",
      "{eligble non citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {non-citizen|citizendesc} workersthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {non-citizen|citizendesc} workers have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {non-citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {non-citizen|citizendesc}workers {joined|employment_action} in {2012|sys_time}\n",
      "{non-citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {non-citizens|citizendesc} workersthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {non-citizens|citizendesc} workers have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {non-citizens|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {non-citizens|citizendesc}workers {joined|employment_action} in {2012|sys_time}\n",
      "{non-citizens|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {eligible non-citizens|citizendesc} workersthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {eligible non-citizens|citizendesc} workers have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {eligible non-citizens|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {eligible non-citizens|citizendesc}workers {joined|employment_action} in {2012|sys_time}\n",
      "{eligible non-citizens|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {non citizen|citizendesc} employeesthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {non citizen|citizendesc} employees have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {non citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {non citizen|citizendesc}employees {joined|employment_action} in {2012|sys_time}\n",
      "{non citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {not a citizen|citizendesc} employeesthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {not a citizen|citizendesc} employees have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {not a citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {not a citizen|citizendesc}employees {joined|employment_action} in {2012|sys_time}\n",
      "{not a citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {non us citizen|citizendesc} employeesthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {non us citizen|citizendesc} employees have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {non us citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {non us citizen|citizendesc}employees {joined|employment_action} in {2012|sys_time}\n",
      "{non us citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {citizen|citizendesc} employeesthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {citizen|citizendesc} employees have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {citizen|citizendesc}employees {joined|employment_action} in {2012|sys_time}\n",
      "{citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {us citizen|citizendesc} employeesthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {us citizen|citizendesc} employees have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {us citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {us citizen|citizendesc}employees {joined|employment_action} in {2012|sys_time}\n",
      "{us citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {not citizens|citizendesc} employeesthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {not citizens|citizendesc} employees have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {not citizens|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {not citizens|citizendesc}employees {joined|employment_action} in {2012|sys_time}\n",
      "{not citizens|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {from abroad|citizendesc} employeesthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {from abroad|citizendesc} employees have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {from abroad|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {from abroad|citizendesc}employees {joined|employment_action} in {2012|sys_time}\n",
      "{from abroad|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {immigrant|citizendesc} employeesthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {immigrant|citizendesc} employees have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {immigrant|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {immigrant|citizendesc}employees {joined|employment_action} in {2012|sys_time}\n",
      "{immigrant|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {immigrants|citizendesc} employeesthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {immigrants|citizendesc} employees have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {immigrants|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {immigrants|citizendesc}employees {joined|employment_action} in {2012|sys_time}\n",
      "{immigrants|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {eligble non citizen|citizendesc} employeesthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {eligble non citizen|citizendesc} employees have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {eligble non citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {eligble non citizen|citizendesc}employees {joined|employment_action} in {2012|sys_time}\n",
      "{eligble non citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {non-citizen|citizendesc} employeesthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {non-citizen|citizendesc} employees have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {non-citizen|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {non-citizen|citizendesc}employees {joined|employment_action} in {2012|sys_time}\n",
      "{non-citizen|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {non-citizens|citizendesc} employeesthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {non-citizens|citizendesc} employees have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {non-citizens|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {non-citizens|citizendesc}employees {joined|employment_action} in {2012|sys_time}\n",
      "{non-citizens|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n",
      "get me a list of {eligible non-citizens|citizendesc} employeesthat have their {birthdays|dob} in the {1970's|time_interval}\n",
      "which {eligible non-citizens|citizendesc} employees have a {birthday|dob} in {1960|time_interval}\n",
      "Find me the names of {eligible non-citizens|citizendesc} {hired|employment_action} in {2013|sys_time}\n",
      "which {eligible non-citizens|citizendesc}employees {joined|employment_action} in {2012|sys_time}\n",
      "{eligible non-citizens|citizendesc} employees were {fired|employment_action} in the {last|date_compare} {five years|sys_duration}?\n"
     ]
    }
   ],
   "source": [
    "for i in sentences: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{us citizen|citizendesc} Carol?\n",
      "hamish {non-citizens|citizendesc}?\n",
      "{from abroad|citizendesc} jeanette?\n",
      "{not citizens|citizendesc} maliki?\n",
      "{immigrants|citizendesc} Miguel Estremera?\n",
      "is dawn a {eligble non citizen|citizendesc}?\n",
      "bartholemew {us citizen|citizendesc}?\n",
      "is sarah warfield a {not citizens|citizendesc}?\n",
      "Donna Brill {non us citizen|citizendesc}?\n",
      "is shakira perry a {eligible non-citizens|citizendesc}?\n",
      "robyn manchester {eligble non citizen|citizendesc}?\n",
      "Colby {us citizen|citizendesc}?\n",
      "is Caitrin a {immigrants|citizendesc}?\n",
      "is maliki moumanil a {from abroad|citizendesc}?\n",
      "is Jeremiah a {immigrants|citizendesc}?\n",
      "quinn {eligible non-citizens|citizendesc}?\n",
      "webster butler {us citizen|citizendesc}?\n",
      "{eligible non-citizens|citizendesc} Robyn?\n",
      "is Barry a {non citizen|citizendesc}?\n",
      "{not citizens|citizendesc} Raul?\n",
      "Maliki Moumanil {us citizen|citizendesc}?\n",
      "lenora tejeda {not a citizen|citizendesc}?\n",
      "is mohammed a {non citizen|citizendesc}?\n",
      "is simon a {non citizen|citizendesc}?\n",
      "{non citizen|citizendesc} lauren mahoney?\n",
      "{non citizen|citizendesc} Phil Close?\n",
      "brigit {non-citizens|citizendesc}?\n",
      "Clinton Owad {from abroad|citizendesc}?\n",
      "{eligble non citizen|citizendesc} Thomas Murray?\n",
      "{non citizen|citizendesc} Megan?\n",
      "is Jeanette Tippett a {us citizen|citizendesc}?\n",
      "is Desiree Tavares a {from abroad|citizendesc}?\n",
      "is Lei-Ming Nguyen a {non us citizen|citizendesc}?\n",
      "is Roxana a {non citizen|citizendesc}?\n",
      "is thomas a {citizen|citizendesc}?\n",
      "is hamish a {eligible non-citizens|citizendesc}?\n",
      "is Thomas Murray a {from abroad|citizendesc}?\n",
      "is benjamin burkett a {from abroad|citizendesc}?\n",
      "is trina a {not citizens|citizendesc}?\n",
      "ming {citizen|citizendesc}?\n",
      "xana potts {not a citizen|citizendesc}?\n",
      "is thomas a {eligble non citizen|citizendesc}?\n",
      "is carla a {not citizens|citizendesc}?\n",
      "{citizen|citizendesc} May Roberson?\n",
      "is cybil trzeciak a {eligble non citizen|citizendesc}?\n",
      "April Evensen {immigrant|citizendesc}?\n",
      "Constance {eligible non-citizens|citizendesc}?\n",
      "lori {from abroad|citizendesc}?\n",
      "{us citizen|citizendesc} shakira?\n",
      "{eligble non citizen|citizendesc} latia costa?\n",
      "is nan a {non-citizen|citizendesc}?\n",
      "Judy Jung {non-citizens|citizendesc}?\n",
      "May {immigrant|citizendesc}?\n",
      "{not citizens|citizendesc} adeel?\n",
      "Ricardo {from abroad|citizendesc}?\n",
      "is noah a {eligble non citizen|citizendesc}?\n",
      "is gerry friedman a {non citizen|citizendesc}?\n",
      "is Carol a {from abroad|citizendesc}?\n",
      "{non-citizens|citizendesc} April?\n",
      "{from abroad|citizendesc} lei-ming?\n",
      "Dawn Motlagh {citizen|citizendesc}?\n",
      "brad pitt {non-citizens|citizendesc}?\n",
      "is giovanni a {non-citizen|citizendesc}?\n",
      "{eligible non-citizens|citizendesc} Kara Harrison?\n",
      "is Nori a {not a citizen|citizendesc}?\n",
      "{eligible non-citizens|citizendesc} Lei-Ming Nguyen?\n",
      "is nore a {non-citizens|citizendesc}?\n",
      "{citizen|citizendesc} Sean?\n",
      "{us citizen|citizendesc} may?\n",
      "Alex {non citizen|citizendesc}?\n"
     ]
    }
   ],
   "source": [
    "for i in random.sample(sentences, 70): print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"What is {mia|name}'s {job title|position}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>get_info</th>\n",
       "      <th>get_aggregate</th>\n",
       "      <th>get_employees</th>\n",
       "      <th>get_salary</th>\n",
       "      <th>get_salary_aggregate</th>\n",
       "      <th>get_salary_employees</th>\n",
       "      <th>get_date</th>\n",
       "      <th>get_date_range_aggregate</th>\n",
       "      <th>get date_range_employees</th>\n",
       "      <th>get_hierarchy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is {nan|name}'s race?</td>\n",
       "      <td>What is the {total|function} {number of|functi...</td>\n",
       "      <td>Give me employees who are {single|maritaldesc}</td>\n",
       "      <td>What is {Mia|name}'s {pay|money}?</td>\n",
       "      <td>What is the {median|function} {pay|money} of {...</td>\n",
       "      <td>Which employee(s) have {lowest|extreme} {incom...</td>\n",
       "      <td>What is the {date of hiring|employment_action}...</td>\n",
       "      <td>What {percentage|function} of employees were {...</td>\n",
       "      <td>Give me a list of people {hired|employment_act...</td>\n",
       "      <td>Who is {Mia|name}'s {manager|manager}?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is {Michael|name} {married|maritaldesc}?</td>\n",
       "      <td>What {percent|function} of employees {exceeded...</td>\n",
       "      <td>All employees from {MA|state}</td>\n",
       "      <td>Tell me who earned the {least|extreme} that wa...</td>\n",
       "      <td>what {percent|function} of employees {make|mon...</td>\n",
       "      <td>who is the {highest|extreme} {earning|money} {...</td>\n",
       "      <td>When did {Amy|name} {join|employment_action} t...</td>\n",
       "      <td>What {percent|function} of employees were {hir...</td>\n",
       "      <td>Tell me about employees who {started|employmen...</td>\n",
       "      <td>Which employees have {Julia|name} as their {ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is {Nan|name}'s official position?</td>\n",
       "      <td>What is the {percentage|function} of new grads...</td>\n",
       "      <td>Which employees have been recently {terminated...</td>\n",
       "      <td>What is the {pay rate|money} of {Julia|name}?</td>\n",
       "      <td>What is the {average|function} {pay rate|money}?</td>\n",
       "      <td>For employees {hired|employment_action} {betwe...</td>\n",
       "      <td>How long has {Ivan|name} been with the company?</td>\n",
       "      <td>What {percentage|function} of employees were {...</td>\n",
       "      <td>Which employees were not yet {born|dob} when {...</td>\n",
       "      <td>What is the name of {Julia|name}'s {manager|ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>did {Nan|name} hear about us through {Glassdoo...</td>\n",
       "      <td>What is the {average|function} {age|age}?</td>\n",
       "      <td>Which employees are not {US citizens|citizende...</td>\n",
       "      <td>What is {Nan|name}'s {pay rate|money}?</td>\n",
       "      <td>What is the {average|function} {pay|money} of ...</td>\n",
       "      <td>what are the {salaries|money} for employees th...</td>\n",
       "      <td>When was {Nan|name} {fired|employment_action}?</td>\n",
       "      <td>What {percent|function} of all our employees w...</td>\n",
       "      <td>list the employees who {joined|employment_acti...</td>\n",
       "      <td>Who is {Michael|name}'s {manager|manager}?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>give me {Nan|name}'s race please</td>\n",
       "      <td>What {percent|function} of employees are manag...</td>\n",
       "      <td>Which employees were {let go|employment_action...</td>\n",
       "      <td>How much does {Michael|name} {make|money}?</td>\n",
       "      <td>Calculate the {average|function} {pay rate|mon...</td>\n",
       "      <td>what are our {top|extreme} {earners|money} {ma...</td>\n",
       "      <td>How long was {Mia|name} working for?</td>\n",
       "      <td>What {percentage|function} of employees were {...</td>\n",
       "      <td>Which employess were {hired|employment_action}...</td>\n",
       "      <td>Who is {John Reeder|name}'s {manager|manager}?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is {Mia|name}'s employment status?</td>\n",
       "      <td>What's the {average|function} {age of|age} emp...</td>\n",
       "      <td>{managers|position}</td>\n",
       "      <td>Is {Mia|name} being {paid|money} {$40k|sys_amo...</td>\n",
       "      <td>{average|function} {pay rate|money} for {women...</td>\n",
       "      <td>{below|comparator} {average|function} {earning...</td>\n",
       "      <td>When was {Michael|name}'s {date of hire|employ...</td>\n",
       "      <td>{How many|function} employees were {hired|empl...</td>\n",
       "      <td>Which employees were {hired|employment_action}...</td>\n",
       "      <td>Who is {Mia Brown|name}'s {manager|manager}?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Is {Ivan|name} from out of state?</td>\n",
       "      <td>What {percentage|function} of the employees ar...</td>\n",
       "      <td>Which employees have been {terminated|employme...</td>\n",
       "      <td>Does {Mia|name} get {$|money}{70k|sys_number} ...</td>\n",
       "      <td>What's the {average|function} {pay rate|money}?</td>\n",
       "      <td>Tell me who all are {making|money} {more than|...</td>\n",
       "      <td>What is {Nan|name}'s {date of birth|dob}?</td>\n",
       "      <td>{How many|function} people were based out of {...</td>\n",
       "      <td>Who worked for Cisco for {less than|comparator...</td>\n",
       "      <td>Who is the {manager|manager} for {Bob|name}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Does {Michael|name} {still work at|employment_...</td>\n",
       "      <td>What {percentage|function} of employees are {e...</td>\n",
       "      <td>Which employees have been with the company lon...</td>\n",
       "      <td>When we let {Nan|name} go {fired|employment_ac...</td>\n",
       "      <td>What is the {average|function} {pay rate|money...</td>\n",
       "      <td>Which {software engineers|position} are {paid|...</td>\n",
       "      <td>What year was {Mia|name} {hired|employment_act...</td>\n",
       "      <td>What {percentage|function} of employees have b...</td>\n",
       "      <td>Which employees have been {hired|employment_ac...</td>\n",
       "      <td>What is {Mia|name}'s {manager|manager}'s name?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What is {Mia|name}'s {performance score|perfor...</td>\n",
       "      <td>What {percentage|function} of employees are {f...</td>\n",
       "      <td>Which employees have gotten only {positive fee...</td>\n",
       "      <td>{pay rate|money} of  {Mia|name}</td>\n",
       "      <td>{How many|function} employees are paid {above|...</td>\n",
       "      <td>Of all the {Production Managers|position}, whi...</td>\n",
       "      <td>When did we {fire|employment_action} {Jeff|name}?</td>\n",
       "      <td>{How many|function} employees were {born|dob} ...</td>\n",
       "      <td>Which employee was {hired|employment_action} w...</td>\n",
       "      <td>Who {reports|manager} into {Nan Singh|name}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What position is {Julia|name} in?</td>\n",
       "      <td>{Percentage|function} of Employees in departme...</td>\n",
       "      <td>Which employees have a {spouse|maritaldesc}?</td>\n",
       "      <td>how much {money|money} does {Mia|name} make?</td>\n",
       "      <td>what {number of|function} people {earn|money} ...</td>\n",
       "      <td>above {average|function} {earning|money} emplo...</td>\n",
       "      <td>How long has {Mia|name} worked here?</td>\n",
       "      <td>{How many|function} people have {worked here|e...</td>\n",
       "      <td>Which employees have {been with us|employment_...</td>\n",
       "      <td>can i have the names of employees who report t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Which department is {Michael|name} in?</td>\n",
       "      <td>What {percentage|function} of employees {meet|...</td>\n",
       "      <td>Which employees {quit working|employment_statu...</td>\n",
       "      <td>What does {Mia|name} {make|money}?</td>\n",
       "      <td>what {number of|function} people {earn|money} ...</td>\n",
       "      <td>who are the company's {top|extreme} {20|sys_nu...</td>\n",
       "      <td>When was {Mia|name}'s {date of hire|employment...</td>\n",
       "      <td>{How many|function} employees were {born|dob} ...</td>\n",
       "      <td>Give me the employees that have {been with us|...</td>\n",
       "      <td>Which employees are {under|comparator} the {Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>How did {Mia|name} hear about our company?</td>\n",
       "      <td>What {percentage|function} of employees are pa...</td>\n",
       "      <td>Which employees are {activley employed|employm...</td>\n",
       "      <td>How much {money|money} does {Mia|name} bring i...</td>\n",
       "      <td>{How many|function} people are {paid|money} {l...</td>\n",
       "      <td>give me the {salaries|money} for all of the em...</td>\n",
       "      <td>What was the {Amy|name}'s {date of hire|employ...</td>\n",
       "      <td>{number of|function} people working {since|dat...</td>\n",
       "      <td>I want a list of employees that were {born in|...</td>\n",
       "      <td>who {works for|manager} {Nan Singh|name}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Is {Nan|name} {married|maritaldesc}?</td>\n",
       "      <td>Give an estimate {total|function} of the {fema...</td>\n",
       "      <td>Which employees have the {highest|extreme} {pe...</td>\n",
       "      <td>{Each year|time_recur}, how much does {Mia|nam...</td>\n",
       "      <td>{How many|function} employees {make|money} {6 ...</td>\n",
       "      <td>{men|sex} {salaries|money}</td>\n",
       "      <td>When was {Michael|name} {hired|employment_acti...</td>\n",
       "      <td>{total|function} {number of|function} employee...</td>\n",
       "      <td>Which employees were {born in|dob} the {80's|t...</td>\n",
       "      <td>Tell who is {working under|manager} {Mr. Singh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Why did {Mia|name} get {fired|employment_action}?</td>\n",
       "      <td>What {percent|function} of people working here...</td>\n",
       "      <td>Who was {hired|employment_action} based on a {...</td>\n",
       "      <td>What are {Mia|name}'s {earnings|money} {year t...</td>\n",
       "      <td>What is the {total|function} {earnings|money} ...</td>\n",
       "      <td>{non citizen|citizendesc} {salaries|money}</td>\n",
       "      <td>When was {Mia|name} {hired|employment_action}?</td>\n",
       "      <td>what is the {fraction|function} of employees t...</td>\n",
       "      <td>Fetch me a list of workers that have their {bi...</td>\n",
       "      <td>employee list with {manager|manager} being {Na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Which department does {Mia|name} work for?</td>\n",
       "      <td>What is the {percentage|function} of employees...</td>\n",
       "      <td>Which employees are in the {engineering depart...</td>\n",
       "      <td>What is {Mia|name}'s {annual|time_recur} {sala...</td>\n",
       "      <td>How much does the {average|function} employee ...</td>\n",
       "      <td>get the {salaries|money} of workers that are {...</td>\n",
       "      <td>What was {Mia|name}'s {date of hiring|employme...</td>\n",
       "      <td>what is the {number of|function} employees {bo...</td>\n",
       "      <td>{white|racedesc} employees {born|dob} {after 1...</td>\n",
       "      <td>{Nan singh|name} is the {manager|manager} of w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>how did {Nan|name} hear about us</td>\n",
       "      <td>Tell me the {percent|function} of employees ar...</td>\n",
       "      <td>Which employees have the {lowest|extreme} {per...</td>\n",
       "      <td>What does {Mia|name} {make|money} {monthly|tim...</td>\n",
       "      <td>What is the {average|function} {amount of mone...</td>\n",
       "      <td>which employees are {making|money} {less than|...</td>\n",
       "      <td>What was the exact date when {Amy|name} {start...</td>\n",
       "      <td>can you please tell me what {fraction|function...</td>\n",
       "      <td>{90's|time_interval} {born|dob} {white|racedes...</td>\n",
       "      <td>which employees is {Nan singh|name} the {manag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How {old|age} is the {Ivan|name}?</td>\n",
       "      <td>What {fraction|function} of our employees are ...</td>\n",
       "      <td>Which employees are {asian|racedesc}?</td>\n",
       "      <td>How much does {Mia|name} {make|money} {every m...</td>\n",
       "      <td>What is the {total|function} {earnings|money} ...</td>\n",
       "      <td>what are the {salaries|money} for {active|empl...</td>\n",
       "      <td>Can you tell me how long has {Ivan|name} worke...</td>\n",
       "      <td>what is the {total|function} {number of|functi...</td>\n",
       "      <td>{asians|racedesc} {born|dob} in the {80's|time...</td>\n",
       "      <td>for which employees is {Nan singh|name} the {s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Is {Nan|name} {actively employed|employment_st...</td>\n",
       "      <td>What is the {percentage|function} of {senior e...</td>\n",
       "      <td>Which employees are {US citizens|citizendesc}?</td>\n",
       "      <td>How much does Cisco {pay|money} {Mia|name} {ea...</td>\n",
       "      <td>How much {money|money} did all the employees {...</td>\n",
       "      <td>Of all employees that {started at the company|...</td>\n",
       "      <td>Which date was {Nan|name} {let go|employment_a...</td>\n",
       "      <td>employees {born|dob} {before|date_compare} {19...</td>\n",
       "      <td>find me the {asians|racedesc} {born|dob} {betw...</td>\n",
       "      <td>{nan singh|name} is the {manager|manager} for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What is {Mia|name}'s position?</td>\n",
       "      <td>What {percentage|function} of workers are {old...</td>\n",
       "      <td>Show {married|maritaldesc} employees</td>\n",
       "      <td>How much {salary|money} does {Mia|name} {earn|...</td>\n",
       "      <td>Get me the {combined|function} {total|function...</td>\n",
       "      <td>Tell me the employee that {works for|manager} ...</td>\n",
       "      <td>Give me {Mia|name}'s {hiring date|employment_a...</td>\n",
       "      <td>i want the {count|function} of employees that ...</td>\n",
       "      <td>get me {accountants|position} {born|dob} {afte...</td>\n",
       "      <td>which of our employees have {nan singh|name} a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What was the reason for {Mia|name}'s {terminat...</td>\n",
       "      <td>What is the {median|function} {age of|age} emp...</td>\n",
       "      <td>Who is {married|maritaldesc} in {Collaboration...</td>\n",
       "      <td>Does {Mia|name} {make|money} {more than|compar...</td>\n",
       "      <td>Tell me about the {range|function} of {salarie...</td>\n",
       "      <td>show me the {highest|extreme} {earning|money} ...</td>\n",
       "      <td>When {Amy|name} was {hired|employment_action} ...</td>\n",
       "      <td>{percent|function} of employees {born|dob} in ...</td>\n",
       "      <td>who are our {90's|time_interval} {born|dob} {I...</td>\n",
       "      <td>get me a list of all of the employees that are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Where does {Mia|name} live?</td>\n",
       "      <td>What is the {voluntary attrition rate|function...</td>\n",
       "      <td>Which employees are {over|comparator} {30|sys_...</td>\n",
       "      <td>Does {Mia|name} {earn|money} {more|comparator}...</td>\n",
       "      <td>Describe the {salary|money} {range|function} f...</td>\n",
       "      <td>who {makes|money} the {least|extreme} {amount ...</td>\n",
       "      <td>Has {Ivan|name} been working here for {3 years...</td>\n",
       "      <td>{1980|sys_time} {born|dob} employees {total|fu...</td>\n",
       "      <td>{15|sys_number} {most|extreme} recently {fired...</td>\n",
       "      <td>employees that directly {report|manager} to {M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Where is {Mia|name} from?</td>\n",
       "      <td>What {fraction|function} of {terminations|empl...</td>\n",
       "      <td>Which employee(s) {do not meet|performance_sco...</td>\n",
       "      <td>What is {Mia|name}'s exact {salary|money} in {...</td>\n",
       "      <td>What {percent|function} of workers {made|money...</td>\n",
       "      <td>who {make|money} a {salary|money} {more than|c...</td>\n",
       "      <td>What was the date when {Mia|name} was {hired|e...</td>\n",
       "      <td>What {percent|function} of employees {began em...</td>\n",
       "      <td>{fifteen|sys_number} {most|extreme} recently {...</td>\n",
       "      <td>who is Ms. {Amy Dunn|name} {reporting|manager} to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What is {Hakim|name}'s level in the organization?</td>\n",
       "      <td>What {percentage|function} of employees are {m...</td>\n",
       "      <td>Which employees were {recruited|employment_act...</td>\n",
       "      <td>Tell me about {Mia|name}'s {month to month|tim...</td>\n",
       "      <td>Of all the workers that {started at the compan...</td>\n",
       "      <td>what are {network engineers|position} {making|...</td>\n",
       "      <td>When {Mia|name} {began her employment|employme...</td>\n",
       "      <td>Fetch me {percent|function} that {started work...</td>\n",
       "      <td>Which employees {joined|employment_action} the...</td>\n",
       "      <td>Does {Amy Dunn|name} have a {manager|manager},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What is {Nan Singh|name}'s {performance evalua...</td>\n",
       "      <td>What is the {percentage|function} of {engineer...</td>\n",
       "      <td>Which employees are {citizens|citizendesc}?</td>\n",
       "      <td>Is {50k|sys_number} {more than|comparator} wha...</td>\n",
       "      <td>Employees {hired|employment_action} between {2...</td>\n",
       "      <td>how much {money|money} does {julia|name} {make...</td>\n",
       "      <td>The date was what when {Mia|name} {started wor...</td>\n",
       "      <td>{ratio|function} {joined|employment_action} {l...</td>\n",
       "      <td>Give me a list of employees that were {hired|e...</td>\n",
       "      <td>I want to know the name of the {manager|manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>What is {Nan|name}'s last name?</td>\n",
       "      <td>what {proportion|function} of employees were {...</td>\n",
       "      <td>Which employees have a position?</td>\n",
       "      <td>Does {60,000|sys_number} exceed what {Mia|name...</td>\n",
       "      <td>{Mean|function} {pay|money} of workers {hired|...</td>\n",
       "      <td>get the {salaries|money} of employees in the {...</td>\n",
       "      <td>{Mia|name} {start date|employment_action}</td>\n",
       "      <td>Tell me {proportion|function} of workers at th...</td>\n",
       "      <td>Give me a list of folks {fired|employment_acti...</td>\n",
       "      <td>{Amy Dunn|name} {manager|manager}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Does {Mia|name}'s race affect her indulgence?</td>\n",
       "      <td>What is the {percentage|function} breakdown of...</td>\n",
       "      <td>Which employees are {married|maritaldesc}?</td>\n",
       "      <td>{Mia|name} {Salary|money} {Yearly|time_recur}</td>\n",
       "      <td>Of the employees {born|dob} {before|date_compa...</td>\n",
       "      <td>all the {salaries|money} of {women|sex} in the...</td>\n",
       "      <td>{Mia|name} {fire date|employment_action}</td>\n",
       "      <td>{ratio|function} out of all of the employees t...</td>\n",
       "      <td>Which employees did we {get rid of|employment_...</td>\n",
       "      <td>{amy dunn|name} {manager|manager} name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>How well is the employee doing?</td>\n",
       "      <td>What is the {average|function} tenure of emplo...</td>\n",
       "      <td>Which employees are {female|sex}?</td>\n",
       "      <td>{Mia|name} {Salary|money} {Monthly|time_recur}</td>\n",
       "      <td>What are workers {born|dob} {before|date_compa...</td>\n",
       "      <td>What are the {yearly|time_recur} {salaries|mon...</td>\n",
       "      <td>{start date|employment_action}, {Mia|name}</td>\n",
       "      <td>{total|function} {number of|function} of emplo...</td>\n",
       "      <td>Which employees are {born|dob} in {May|sys_time}</td>\n",
       "      <td>{manager|manager} name for ms {amy dunn|name}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What does {Michael|name} look like?</td>\n",
       "      <td>What {percent|function} of employees are {fema...</td>\n",
       "      <td>Who is our {oldest|extreme} employee?</td>\n",
       "      <td>{Mia|name} {Salary|money} {Daily|time_recur}</td>\n",
       "      <td>What is the {typical|function} {compensation|m...</td>\n",
       "      <td>{sales department|department} {salaries|money}</td>\n",
       "      <td>{fire date|employment_action}, {Ivan|name}</td>\n",
       "      <td>{headcount|function} people who {have worked h...</td>\n",
       "      <td>Give me a list of employees that have a {birth...</td>\n",
       "      <td>get me ms. {dunn|name}'s {manager|manager} ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Is {Mia|name} a citizen?</td>\n",
       "      <td>What's the {average|function} {performance|per...</td>\n",
       "      <td>Show me all of the {software engineering manag...</td>\n",
       "      <td>{Mia|name} {earning|money} amount {yearly|time...</td>\n",
       "      <td>on {average|function}, how much are {referred ...</td>\n",
       "      <td>show me the employee {salaries|money} for {fem...</td>\n",
       "      <td>Was {Mia|name} {fired on|employment_action} th...</td>\n",
       "      <td>{total|function} employees that have {been wit...</td>\n",
       "      <td>Which employees were {born|dob} in the month o...</td>\n",
       "      <td>is there anyone {reporting|manager} to Ms. {Am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Why was {Mia|name} fired?</td>\n",
       "      <td>What is the {distribution|function} of employe...</td>\n",
       "      <td>All the {September|sys_time} {birthdays|dob}</td>\n",
       "      <td>{Mia|name} {earning|money} amount {monthly|tim...</td>\n",
       "      <td>how much are {referred employees|employee_sour...</td>\n",
       "      <td>{lowest|extreme} {income|money} {salaries|money}</td>\n",
       "      <td>When was {Mia|name} {born|dob}?</td>\n",
       "      <td>Calculate the {total|function} {number of|func...</td>\n",
       "      <td>Give me all the employees that have a {birthda...</td>\n",
       "      <td>{manager|manager} of {amy dunn|name}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>give me a list of employees that are based in ...</td>\n",
       "      <td>{joanne handschiegl|name} {each month|time_rec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>list out of employees that are based in {AL|st...</td>\n",
       "      <td>{melisa|name} {each day|time_recur} {earnings|...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{PA|state} based employees</td>\n",
       "      <td>{patrick|name} {month to month|time_recur} {pa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{ID|state} based employees</td>\n",
       "      <td>{Jean Crimmings|name} {on the hour|time_recur}...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{GA|state} based employees</td>\n",
       "      <td>{charles|name} {every day|time_recur} {paychec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>employees based in {MA|state}</td>\n",
       "      <td>{Jumil Turpin|name} {month to month|time_recur...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>employees based in {CT|state}</td>\n",
       "      <td>How much does {Anna Von Massenbach|name} get i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>employees based in {CO|state}</td>\n",
       "      <td>How much does {Mildred Gentry|name} get in {ea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Which employees are {sr. dba|position}?</td>\n",
       "      <td>How much does {Lindsey|name} get for {salary|m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Which employees are {accountant i|position}?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Which employees are {it manager - db|position}?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>employees that are {director of sales|position}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>employees that are {area sales manager|position}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>employees that are {it manager - infra|position}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>list of {accountant i|position}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>list of {shared services manager|position}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>list of {president &amp; ceo|position}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{software engineer|position} list</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{it manager - db|position} list</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{it support|position} list</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{it manager - support|position} employees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{accountant i|position} employees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{administrative assistant|position} employees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>employee {database administrator|position}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>employee {it support|position}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>employee {it director|position}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{production manager|position}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{database administrator|position}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{sales manager|position}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male {headcount|function}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              get_info  \\\n",
       "2                           What is {nan|name}'s race?   \n",
       "3             Is {Michael|name} {married|maritaldesc}?   \n",
       "4              What is {Nan|name}'s official position?   \n",
       "5    did {Nan|name} hear about us through {Glassdoo...   \n",
       "6                     give me {Nan|name}'s race please   \n",
       "7              What is {Mia|name}'s employment status?   \n",
       "8                    Is {Ivan|name} from out of state?   \n",
       "9    Does {Michael|name} {still work at|employment_...   \n",
       "10   What is {Mia|name}'s {performance score|perfor...   \n",
       "11                   What position is {Julia|name} in?   \n",
       "12              Which department is {Michael|name} in?   \n",
       "13          How did {Mia|name} hear about our company?   \n",
       "14                Is {Nan|name} {married|maritaldesc}?   \n",
       "15   Why did {Mia|name} get {fired|employment_action}?   \n",
       "16          Which department does {Mia|name} work for?   \n",
       "17                    how did {Nan|name} hear about us   \n",
       "18                   How {old|age} is the {Ivan|name}?   \n",
       "19   Is {Nan|name} {actively employed|employment_st...   \n",
       "20                     What is {Mia|name}'s position?    \n",
       "21   What was the reason for {Mia|name}'s {terminat...   \n",
       "22                         Where does {Mia|name} live?   \n",
       "23                           Where is {Mia|name} from?   \n",
       "24   What is {Hakim|name}'s level in the organization?   \n",
       "25   What is {Nan Singh|name}'s {performance evalua...   \n",
       "26                     What is {Nan|name}'s last name?   \n",
       "27       Does {Mia|name}'s race affect her indulgence?   \n",
       "28                     How well is the employee doing?   \n",
       "29                 What does {Michael|name} look like?   \n",
       "30                            Is {Mia|name} a citizen?   \n",
       "31                           Why was {Mia|name} fired?   \n",
       "..                                                 ...   \n",
       "272                                                NaN   \n",
       "273                                                NaN   \n",
       "274                                                NaN   \n",
       "275                                                NaN   \n",
       "276                                                NaN   \n",
       "277                                                NaN   \n",
       "278                                                NaN   \n",
       "279                                                NaN   \n",
       "280                                                NaN   \n",
       "281                                                NaN   \n",
       "282                                                NaN   \n",
       "283                                                NaN   \n",
       "284                                                NaN   \n",
       "285                                                NaN   \n",
       "286                                                NaN   \n",
       "287                                                NaN   \n",
       "288                                                NaN   \n",
       "289                                                NaN   \n",
       "290                                                NaN   \n",
       "291                                                NaN   \n",
       "292                                                NaN   \n",
       "293                                                NaN   \n",
       "294                                                NaN   \n",
       "295                                                NaN   \n",
       "296                                                NaN   \n",
       "297                                                NaN   \n",
       "298                                                NaN   \n",
       "299                                                NaN   \n",
       "300                                                NaN   \n",
       "301                                                NaN   \n",
       "\n",
       "                                         get_aggregate  \\\n",
       "2    What is the {total|function} {number of|functi...   \n",
       "3    What {percent|function} of employees {exceeded...   \n",
       "4    What is the {percentage|function} of new grads...   \n",
       "5            What is the {average|function} {age|age}?   \n",
       "6    What {percent|function} of employees are manag...   \n",
       "7    What's the {average|function} {age of|age} emp...   \n",
       "8    What {percentage|function} of the employees ar...   \n",
       "9    What {percentage|function} of employees are {e...   \n",
       "10   What {percentage|function} of employees are {f...   \n",
       "11   {Percentage|function} of Employees in departme...   \n",
       "12   What {percentage|function} of employees {meet|...   \n",
       "13   What {percentage|function} of employees are pa...   \n",
       "14   Give an estimate {total|function} of the {fema...   \n",
       "15   What {percent|function} of people working here...   \n",
       "16   What is the {percentage|function} of employees...   \n",
       "17   Tell me the {percent|function} of employees ar...   \n",
       "18   What {fraction|function} of our employees are ...   \n",
       "19   What is the {percentage|function} of {senior e...   \n",
       "20   What {percentage|function} of workers are {old...   \n",
       "21   What is the {median|function} {age of|age} emp...   \n",
       "22   What is the {voluntary attrition rate|function...   \n",
       "23   What {fraction|function} of {terminations|empl...   \n",
       "24   What {percentage|function} of employees are {m...   \n",
       "25   What is the {percentage|function} of {engineer...   \n",
       "26   what {proportion|function} of employees were {...   \n",
       "27   What is the {percentage|function} breakdown of...   \n",
       "28   What is the {average|function} tenure of emplo...   \n",
       "29   What {percent|function} of employees are {fema...   \n",
       "30   What's the {average|function} {performance|per...   \n",
       "31   What is the {distribution|function} of employe...   \n",
       "..                                                 ...   \n",
       "272                                                NaN   \n",
       "273                                                NaN   \n",
       "274                                                NaN   \n",
       "275                                                NaN   \n",
       "276                                                NaN   \n",
       "277                                                NaN   \n",
       "278                                                NaN   \n",
       "279                                                NaN   \n",
       "280                                                NaN   \n",
       "281                                                NaN   \n",
       "282                                                NaN   \n",
       "283                                                NaN   \n",
       "284                                                NaN   \n",
       "285                                                NaN   \n",
       "286                                                NaN   \n",
       "287                                                NaN   \n",
       "288                                                NaN   \n",
       "289                                                NaN   \n",
       "290                                                NaN   \n",
       "291                                                NaN   \n",
       "292                                                NaN   \n",
       "293                                                NaN   \n",
       "294                                                NaN   \n",
       "295                                                NaN   \n",
       "296                                                NaN   \n",
       "297                                                NaN   \n",
       "298                                                NaN   \n",
       "299                                                NaN   \n",
       "300                                                NaN   \n",
       "301                                                NaN   \n",
       "\n",
       "                                         get_employees  \\\n",
       "2       Give me employees who are {single|maritaldesc}   \n",
       "3                        All employees from {MA|state}   \n",
       "4    Which employees have been recently {terminated...   \n",
       "5    Which employees are not {US citizens|citizende...   \n",
       "6    Which employees were {let go|employment_action...   \n",
       "7                                  {managers|position}   \n",
       "8    Which employees have been {terminated|employme...   \n",
       "9    Which employees have been with the company lon...   \n",
       "10   Which employees have gotten only {positive fee...   \n",
       "11        Which employees have a {spouse|maritaldesc}?   \n",
       "12   Which employees {quit working|employment_statu...   \n",
       "13   Which employees are {activley employed|employm...   \n",
       "14   Which employees have the {highest|extreme} {pe...   \n",
       "15   Who was {hired|employment_action} based on a {...   \n",
       "16   Which employees are in the {engineering depart...   \n",
       "17   Which employees have the {lowest|extreme} {per...   \n",
       "18               Which employees are {asian|racedesc}?   \n",
       "19      Which employees are {US citizens|citizendesc}?   \n",
       "20                Show {married|maritaldesc} employees   \n",
       "21   Who is {married|maritaldesc} in {Collaboration...   \n",
       "22   Which employees are {over|comparator} {30|sys_...   \n",
       "23   Which employee(s) {do not meet|performance_sco...   \n",
       "24   Which employees were {recruited|employment_act...   \n",
       "25         Which employees are {citizens|citizendesc}?   \n",
       "26                    Which employees have a position?   \n",
       "27          Which employees are {married|maritaldesc}?   \n",
       "28                   Which employees are {female|sex}?   \n",
       "29               Who is our {oldest|extreme} employee?   \n",
       "30   Show me all of the {software engineering manag...   \n",
       "31        All the {September|sys_time} {birthdays|dob}   \n",
       "..                                                 ...   \n",
       "272  give me a list of employees that are based in ...   \n",
       "273  list out of employees that are based in {AL|st...   \n",
       "274                         {PA|state} based employees   \n",
       "275                         {ID|state} based employees   \n",
       "276                         {GA|state} based employees   \n",
       "277                      employees based in {MA|state}   \n",
       "278                      employees based in {CT|state}   \n",
       "279                      employees based in {CO|state}   \n",
       "280            Which employees are {sr. dba|position}?   \n",
       "281       Which employees are {accountant i|position}?   \n",
       "282    Which employees are {it manager - db|position}?   \n",
       "283    employees that are {director of sales|position}   \n",
       "284   employees that are {area sales manager|position}   \n",
       "285   employees that are {it manager - infra|position}   \n",
       "286                    list of {accountant i|position}   \n",
       "287         list of {shared services manager|position}   \n",
       "288                 list of {president & ceo|position}   \n",
       "289                  {software engineer|position} list   \n",
       "290                    {it manager - db|position} list   \n",
       "291                         {it support|position} list   \n",
       "292          {it manager - support|position} employees   \n",
       "293                  {accountant i|position} employees   \n",
       "294      {administrative assistant|position} employees   \n",
       "295         employee {database administrator|position}   \n",
       "296                     employee {it support|position}   \n",
       "297                    employee {it director|position}   \n",
       "298                      {production manager|position}   \n",
       "299                  {database administrator|position}   \n",
       "300                           {sales manager|position}   \n",
       "301                          Male {headcount|function}   \n",
       "\n",
       "                                            get_salary  \\\n",
       "2                    What is {Mia|name}'s {pay|money}?   \n",
       "3    Tell me who earned the {least|extreme} that wa...   \n",
       "4        What is the {pay rate|money} of {Julia|name}?   \n",
       "5               What is {Nan|name}'s {pay rate|money}?   \n",
       "6           How much does {Michael|name} {make|money}?   \n",
       "7    Is {Mia|name} being {paid|money} {$40k|sys_amo...   \n",
       "8    Does {Mia|name} get {$|money}{70k|sys_number} ...   \n",
       "9    When we let {Nan|name} go {fired|employment_ac...   \n",
       "10                     {pay rate|money} of  {Mia|name}   \n",
       "11        how much {money|money} does {Mia|name} make?   \n",
       "12                  What does {Mia|name} {make|money}?   \n",
       "13   How much {money|money} does {Mia|name} bring i...   \n",
       "14   {Each year|time_recur}, how much does {Mia|nam...   \n",
       "15   What are {Mia|name}'s {earnings|money} {year t...   \n",
       "16   What is {Mia|name}'s {annual|time_recur} {sala...   \n",
       "17   What does {Mia|name} {make|money} {monthly|tim...   \n",
       "18   How much does {Mia|name} {make|money} {every m...   \n",
       "19   How much does Cisco {pay|money} {Mia|name} {ea...   \n",
       "20   How much {salary|money} does {Mia|name} {earn|...   \n",
       "21   Does {Mia|name} {make|money} {more than|compar...   \n",
       "22   Does {Mia|name} {earn|money} {more|comparator}...   \n",
       "23   What is {Mia|name}'s exact {salary|money} in {...   \n",
       "24   Tell me about {Mia|name}'s {month to month|tim...   \n",
       "25   Is {50k|sys_number} {more than|comparator} wha...   \n",
       "26   Does {60,000|sys_number} exceed what {Mia|name...   \n",
       "27       {Mia|name} {Salary|money} {Yearly|time_recur}   \n",
       "28      {Mia|name} {Salary|money} {Monthly|time_recur}   \n",
       "29        {Mia|name} {Salary|money} {Daily|time_recur}   \n",
       "30   {Mia|name} {earning|money} amount {yearly|time...   \n",
       "31   {Mia|name} {earning|money} amount {monthly|tim...   \n",
       "..                                                 ...   \n",
       "272  {joanne handschiegl|name} {each month|time_rec...   \n",
       "273  {melisa|name} {each day|time_recur} {earnings|...   \n",
       "274  {patrick|name} {month to month|time_recur} {pa...   \n",
       "275  {Jean Crimmings|name} {on the hour|time_recur}...   \n",
       "276  {charles|name} {every day|time_recur} {paychec...   \n",
       "277  {Jumil Turpin|name} {month to month|time_recur...   \n",
       "278  How much does {Anna Von Massenbach|name} get i...   \n",
       "279  How much does {Mildred Gentry|name} get in {ea...   \n",
       "280  How much does {Lindsey|name} get for {salary|m...   \n",
       "281                                                NaN   \n",
       "282                                                NaN   \n",
       "283                                                NaN   \n",
       "284                                                NaN   \n",
       "285                                                NaN   \n",
       "286                                                NaN   \n",
       "287                                                NaN   \n",
       "288                                                NaN   \n",
       "289                                                NaN   \n",
       "290                                                NaN   \n",
       "291                                                NaN   \n",
       "292                                                NaN   \n",
       "293                                                NaN   \n",
       "294                                                NaN   \n",
       "295                                                NaN   \n",
       "296                                                NaN   \n",
       "297                                                NaN   \n",
       "298                                                NaN   \n",
       "299                                                NaN   \n",
       "300                                                NaN   \n",
       "301                                                NaN   \n",
       "\n",
       "                                  get_salary_aggregate  \\\n",
       "2    What is the {median|function} {pay|money} of {...   \n",
       "3    what {percent|function} of employees {make|mon...   \n",
       "4     What is the {average|function} {pay rate|money}?   \n",
       "5    What is the {average|function} {pay|money} of ...   \n",
       "6    Calculate the {average|function} {pay rate|mon...   \n",
       "7    {average|function} {pay rate|money} for {women...   \n",
       "8      What's the {average|function} {pay rate|money}?   \n",
       "9    What is the {average|function} {pay rate|money...   \n",
       "10   {How many|function} employees are paid {above|...   \n",
       "11   what {number of|function} people {earn|money} ...   \n",
       "12   what {number of|function} people {earn|money} ...   \n",
       "13   {How many|function} people are {paid|money} {l...   \n",
       "14   {How many|function} employees {make|money} {6 ...   \n",
       "15   What is the {total|function} {earnings|money} ...   \n",
       "16   How much does the {average|function} employee ...   \n",
       "17   What is the {average|function} {amount of mone...   \n",
       "18   What is the {total|function} {earnings|money} ...   \n",
       "19   How much {money|money} did all the employees {...   \n",
       "20   Get me the {combined|function} {total|function...   \n",
       "21   Tell me about the {range|function} of {salarie...   \n",
       "22   Describe the {salary|money} {range|function} f...   \n",
       "23   What {percent|function} of workers {made|money...   \n",
       "24   Of all the workers that {started at the compan...   \n",
       "25   Employees {hired|employment_action} between {2...   \n",
       "26   {Mean|function} {pay|money} of workers {hired|...   \n",
       "27   Of the employees {born|dob} {before|date_compa...   \n",
       "28   What are workers {born|dob} {before|date_compa...   \n",
       "29   What is the {typical|function} {compensation|m...   \n",
       "30   on {average|function}, how much are {referred ...   \n",
       "31   how much are {referred employees|employee_sour...   \n",
       "..                                                 ...   \n",
       "272                                                NaN   \n",
       "273                                                NaN   \n",
       "274                                                NaN   \n",
       "275                                                NaN   \n",
       "276                                                NaN   \n",
       "277                                                NaN   \n",
       "278                                                NaN   \n",
       "279                                                NaN   \n",
       "280                                                NaN   \n",
       "281                                                NaN   \n",
       "282                                                NaN   \n",
       "283                                                NaN   \n",
       "284                                                NaN   \n",
       "285                                                NaN   \n",
       "286                                                NaN   \n",
       "287                                                NaN   \n",
       "288                                                NaN   \n",
       "289                                                NaN   \n",
       "290                                                NaN   \n",
       "291                                                NaN   \n",
       "292                                                NaN   \n",
       "293                                                NaN   \n",
       "294                                                NaN   \n",
       "295                                                NaN   \n",
       "296                                                NaN   \n",
       "297                                                NaN   \n",
       "298                                                NaN   \n",
       "299                                                NaN   \n",
       "300                                                NaN   \n",
       "301                                                NaN   \n",
       "\n",
       "                                  get_salary_employees  \\\n",
       "2    Which employee(s) have {lowest|extreme} {incom...   \n",
       "3    who is the {highest|extreme} {earning|money} {...   \n",
       "4    For employees {hired|employment_action} {betwe...   \n",
       "5    what are the {salaries|money} for employees th...   \n",
       "6    what are our {top|extreme} {earners|money} {ma...   \n",
       "7    {below|comparator} {average|function} {earning...   \n",
       "8    Tell me who all are {making|money} {more than|...   \n",
       "9    Which {software engineers|position} are {paid|...   \n",
       "10   Of all the {Production Managers|position}, whi...   \n",
       "11   above {average|function} {earning|money} emplo...   \n",
       "12   who are the company's {top|extreme} {20|sys_nu...   \n",
       "13   give me the {salaries|money} for all of the em...   \n",
       "14                          {men|sex} {salaries|money}   \n",
       "15          {non citizen|citizendesc} {salaries|money}   \n",
       "16   get the {salaries|money} of workers that are {...   \n",
       "17   which employees are {making|money} {less than|...   \n",
       "18   what are the {salaries|money} for {active|empl...   \n",
       "19   Of all employees that {started at the company|...   \n",
       "20   Tell me the employee that {works for|manager} ...   \n",
       "21   show me the {highest|extreme} {earning|money} ...   \n",
       "22   who {makes|money} the {least|extreme} {amount ...   \n",
       "23   who {make|money} a {salary|money} {more than|c...   \n",
       "24   what are {network engineers|position} {making|...   \n",
       "25   how much {money|money} does {julia|name} {make...   \n",
       "26   get the {salaries|money} of employees in the {...   \n",
       "27   all the {salaries|money} of {women|sex} in the...   \n",
       "28   What are the {yearly|time_recur} {salaries|mon...   \n",
       "29      {sales department|department} {salaries|money}   \n",
       "30   show me the employee {salaries|money} for {fem...   \n",
       "31    {lowest|extreme} {income|money} {salaries|money}   \n",
       "..                                                 ...   \n",
       "272                                                NaN   \n",
       "273                                                NaN   \n",
       "274                                                NaN   \n",
       "275                                                NaN   \n",
       "276                                                NaN   \n",
       "277                                                NaN   \n",
       "278                                                NaN   \n",
       "279                                                NaN   \n",
       "280                                                NaN   \n",
       "281                                                NaN   \n",
       "282                                                NaN   \n",
       "283                                                NaN   \n",
       "284                                                NaN   \n",
       "285                                                NaN   \n",
       "286                                                NaN   \n",
       "287                                                NaN   \n",
       "288                                                NaN   \n",
       "289                                                NaN   \n",
       "290                                                NaN   \n",
       "291                                                NaN   \n",
       "292                                                NaN   \n",
       "293                                                NaN   \n",
       "294                                                NaN   \n",
       "295                                                NaN   \n",
       "296                                                NaN   \n",
       "297                                                NaN   \n",
       "298                                                NaN   \n",
       "299                                                NaN   \n",
       "300                                                NaN   \n",
       "301                                                NaN   \n",
       "\n",
       "                                              get_date  \\\n",
       "2    What is the {date of hiring|employment_action}...   \n",
       "3    When did {Amy|name} {join|employment_action} t...   \n",
       "4      How long has {Ivan|name} been with the company?   \n",
       "5       When was {Nan|name} {fired|employment_action}?   \n",
       "6                 How long was {Mia|name} working for?   \n",
       "7    When was {Michael|name}'s {date of hire|employ...   \n",
       "8            What is {Nan|name}'s {date of birth|dob}?   \n",
       "9    What year was {Mia|name} {hired|employment_act...   \n",
       "10   When did we {fire|employment_action} {Jeff|name}?   \n",
       "11                How long has {Mia|name} worked here?   \n",
       "12   When was {Mia|name}'s {date of hire|employment...   \n",
       "13   What was the {Amy|name}'s {date of hire|employ...   \n",
       "14   When was {Michael|name} {hired|employment_acti...   \n",
       "15      When was {Mia|name} {hired|employment_action}?   \n",
       "16   What was {Mia|name}'s {date of hiring|employme...   \n",
       "17   What was the exact date when {Amy|name} {start...   \n",
       "18   Can you tell me how long has {Ivan|name} worke...   \n",
       "19   Which date was {Nan|name} {let go|employment_a...   \n",
       "20   Give me {Mia|name}'s {hiring date|employment_a...   \n",
       "21   When {Amy|name} was {hired|employment_action} ...   \n",
       "22   Has {Ivan|name} been working here for {3 years...   \n",
       "23   What was the date when {Mia|name} was {hired|e...   \n",
       "24   When {Mia|name} {began her employment|employme...   \n",
       "25   The date was what when {Mia|name} {started wor...   \n",
       "26           {Mia|name} {start date|employment_action}   \n",
       "27            {Mia|name} {fire date|employment_action}   \n",
       "28          {start date|employment_action}, {Mia|name}   \n",
       "29          {fire date|employment_action}, {Ivan|name}   \n",
       "30   Was {Mia|name} {fired on|employment_action} th...   \n",
       "31                     When was {Mia|name} {born|dob}?   \n",
       "..                                                 ...   \n",
       "272                                                NaN   \n",
       "273                                                NaN   \n",
       "274                                                NaN   \n",
       "275                                                NaN   \n",
       "276                                                NaN   \n",
       "277                                                NaN   \n",
       "278                                                NaN   \n",
       "279                                                NaN   \n",
       "280                                                NaN   \n",
       "281                                                NaN   \n",
       "282                                                NaN   \n",
       "283                                                NaN   \n",
       "284                                                NaN   \n",
       "285                                                NaN   \n",
       "286                                                NaN   \n",
       "287                                                NaN   \n",
       "288                                                NaN   \n",
       "289                                                NaN   \n",
       "290                                                NaN   \n",
       "291                                                NaN   \n",
       "292                                                NaN   \n",
       "293                                                NaN   \n",
       "294                                                NaN   \n",
       "295                                                NaN   \n",
       "296                                                NaN   \n",
       "297                                                NaN   \n",
       "298                                                NaN   \n",
       "299                                                NaN   \n",
       "300                                                NaN   \n",
       "301                                                NaN   \n",
       "\n",
       "                              get_date_range_aggregate  \\\n",
       "2    What {percentage|function} of employees were {...   \n",
       "3    What {percent|function} of employees were {hir...   \n",
       "4    What {percentage|function} of employees were {...   \n",
       "5    What {percent|function} of all our employees w...   \n",
       "6    What {percentage|function} of employees were {...   \n",
       "7    {How many|function} employees were {hired|empl...   \n",
       "8    {How many|function} people were based out of {...   \n",
       "9    What {percentage|function} of employees have b...   \n",
       "10   {How many|function} employees were {born|dob} ...   \n",
       "11   {How many|function} people have {worked here|e...   \n",
       "12   {How many|function} employees were {born|dob} ...   \n",
       "13   {number of|function} people working {since|dat...   \n",
       "14   {total|function} {number of|function} employee...   \n",
       "15   what is the {fraction|function} of employees t...   \n",
       "16   what is the {number of|function} employees {bo...   \n",
       "17   can you please tell me what {fraction|function...   \n",
       "18   what is the {total|function} {number of|functi...   \n",
       "19   employees {born|dob} {before|date_compare} {19...   \n",
       "20   i want the {count|function} of employees that ...   \n",
       "21   {percent|function} of employees {born|dob} in ...   \n",
       "22   {1980|sys_time} {born|dob} employees {total|fu...   \n",
       "23   What {percent|function} of employees {began em...   \n",
       "24   Fetch me {percent|function} that {started work...   \n",
       "25   {ratio|function} {joined|employment_action} {l...   \n",
       "26   Tell me {proportion|function} of workers at th...   \n",
       "27   {ratio|function} out of all of the employees t...   \n",
       "28   {total|function} {number of|function} of emplo...   \n",
       "29   {headcount|function} people who {have worked h...   \n",
       "30   {total|function} employees that have {been wit...   \n",
       "31   Calculate the {total|function} {number of|func...   \n",
       "..                                                 ...   \n",
       "272                                                NaN   \n",
       "273                                                NaN   \n",
       "274                                                NaN   \n",
       "275                                                NaN   \n",
       "276                                                NaN   \n",
       "277                                                NaN   \n",
       "278                                                NaN   \n",
       "279                                                NaN   \n",
       "280                                                NaN   \n",
       "281                                                NaN   \n",
       "282                                                NaN   \n",
       "283                                                NaN   \n",
       "284                                                NaN   \n",
       "285                                                NaN   \n",
       "286                                                NaN   \n",
       "287                                                NaN   \n",
       "288                                                NaN   \n",
       "289                                                NaN   \n",
       "290                                                NaN   \n",
       "291                                                NaN   \n",
       "292                                                NaN   \n",
       "293                                                NaN   \n",
       "294                                                NaN   \n",
       "295                                                NaN   \n",
       "296                                                NaN   \n",
       "297                                                NaN   \n",
       "298                                                NaN   \n",
       "299                                                NaN   \n",
       "300                                                NaN   \n",
       "301                                                NaN   \n",
       "\n",
       "                              get date_range_employees  \\\n",
       "2    Give me a list of people {hired|employment_act...   \n",
       "3    Tell me about employees who {started|employmen...   \n",
       "4    Which employees were not yet {born|dob} when {...   \n",
       "5    list the employees who {joined|employment_acti...   \n",
       "6    Which employess were {hired|employment_action}...   \n",
       "7    Which employees were {hired|employment_action}...   \n",
       "8    Who worked for Cisco for {less than|comparator...   \n",
       "9    Which employees have been {hired|employment_ac...   \n",
       "10   Which employee was {hired|employment_action} w...   \n",
       "11   Which employees have {been with us|employment_...   \n",
       "12   Give me the employees that have {been with us|...   \n",
       "13   I want a list of employees that were {born in|...   \n",
       "14   Which employees were {born in|dob} the {80's|t...   \n",
       "15   Fetch me a list of workers that have their {bi...   \n",
       "16   {white|racedesc} employees {born|dob} {after 1...   \n",
       "17   {90's|time_interval} {born|dob} {white|racedes...   \n",
       "18   {asians|racedesc} {born|dob} in the {80's|time...   \n",
       "19   find me the {asians|racedesc} {born|dob} {betw...   \n",
       "20   get me {accountants|position} {born|dob} {afte...   \n",
       "21   who are our {90's|time_interval} {born|dob} {I...   \n",
       "22   {15|sys_number} {most|extreme} recently {fired...   \n",
       "23   {fifteen|sys_number} {most|extreme} recently {...   \n",
       "24   Which employees {joined|employment_action} the...   \n",
       "25   Give me a list of employees that were {hired|e...   \n",
       "26   Give me a list of folks {fired|employment_acti...   \n",
       "27   Which employees did we {get rid of|employment_...   \n",
       "28    Which employees are {born|dob} in {May|sys_time}   \n",
       "29   Give me a list of employees that have a {birth...   \n",
       "30   Which employees were {born|dob} in the month o...   \n",
       "31   Give me all the employees that have a {birthda...   \n",
       "..                                                 ...   \n",
       "272                                                NaN   \n",
       "273                                                NaN   \n",
       "274                                                NaN   \n",
       "275                                                NaN   \n",
       "276                                                NaN   \n",
       "277                                                NaN   \n",
       "278                                                NaN   \n",
       "279                                                NaN   \n",
       "280                                                NaN   \n",
       "281                                                NaN   \n",
       "282                                                NaN   \n",
       "283                                                NaN   \n",
       "284                                                NaN   \n",
       "285                                                NaN   \n",
       "286                                                NaN   \n",
       "287                                                NaN   \n",
       "288                                                NaN   \n",
       "289                                                NaN   \n",
       "290                                                NaN   \n",
       "291                                                NaN   \n",
       "292                                                NaN   \n",
       "293                                                NaN   \n",
       "294                                                NaN   \n",
       "295                                                NaN   \n",
       "296                                                NaN   \n",
       "297                                                NaN   \n",
       "298                                                NaN   \n",
       "299                                                NaN   \n",
       "300                                                NaN   \n",
       "301                                                NaN   \n",
       "\n",
       "                                         get_hierarchy  \n",
       "2              Who is {Mia|name}'s {manager|manager}?   \n",
       "3    Which employees have {Julia|name} as their {ma...  \n",
       "4    What is the name of {Julia|name}'s {manager|ma...  \n",
       "5           Who is {Michael|name}'s {manager|manager}?  \n",
       "6       Who is {John Reeder|name}'s {manager|manager}?  \n",
       "7         Who is {Mia Brown|name}'s {manager|manager}?  \n",
       "8          Who is the {manager|manager} for {Bob|name}  \n",
       "9       What is {Mia|name}'s {manager|manager}'s name?  \n",
       "10         Who {reports|manager} into {Nan Singh|name}  \n",
       "11   can i have the names of employees who report t...  \n",
       "12   Which employees are {under|comparator} the {Ma...  \n",
       "13            who {works for|manager} {Nan Singh|name}  \n",
       "14   Tell who is {working under|manager} {Mr. Singh...  \n",
       "15   employee list with {manager|manager} being {Na...  \n",
       "16   {Nan singh|name} is the {manager|manager} of w...  \n",
       "17   which employees is {Nan singh|name} the {manag...  \n",
       "18   for which employees is {Nan singh|name} the {s...  \n",
       "19   {nan singh|name} is the {manager|manager} for ...  \n",
       "20   which of our employees have {nan singh|name} a...  \n",
       "21   get me a list of all of the employees that are...  \n",
       "22   employees that directly {report|manager} to {M...  \n",
       "23   who is Ms. {Amy Dunn|name} {reporting|manager} to  \n",
       "24   Does {Amy Dunn|name} have a {manager|manager},...  \n",
       "25   I want to know the name of the {manager|manage...  \n",
       "26                   {Amy Dunn|name} {manager|manager}  \n",
       "27              {amy dunn|name} {manager|manager} name  \n",
       "28       {manager|manager} name for ms {amy dunn|name}  \n",
       "29   get me ms. {dunn|name}'s {manager|manager} ful...  \n",
       "30   is there anyone {reporting|manager} to Ms. {Am...  \n",
       "31                {manager|manager} of {amy dunn|name}  \n",
       "..                                                 ...  \n",
       "272                                                NaN  \n",
       "273                                                NaN  \n",
       "274                                                NaN  \n",
       "275                                                NaN  \n",
       "276                                                NaN  \n",
       "277                                                NaN  \n",
       "278                                                NaN  \n",
       "279                                                NaN  \n",
       "280                                                NaN  \n",
       "281                                                NaN  \n",
       "282                                                NaN  \n",
       "283                                                NaN  \n",
       "284                                                NaN  \n",
       "285                                                NaN  \n",
       "286                                                NaN  \n",
       "287                                                NaN  \n",
       "288                                                NaN  \n",
       "289                                                NaN  \n",
       "290                                                NaN  \n",
       "291                                                NaN  \n",
       "292                                                NaN  \n",
       "293                                                NaN  \n",
       "294                                                NaN  \n",
       "295                                                NaN  \n",
       "296                                                NaN  \n",
       "297                                                NaN  \n",
       "298                                                NaN  \n",
       "299                                                NaN  \n",
       "300                                                NaN  \n",
       "301                                                NaN  \n",
       "\n",
       "[300 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_augment(df, uniq):\n",
    "    df = intent_txt\n",
    "    for col in df:\n",
    "        augment = []\n",
    "        print(col.upper() + \"=============================================================\")\n",
    "        idx = 2\n",
    "        nan = is_nan(df[col][idx])\n",
    "        l_dict = {}\n",
    "        while(idx < len(df)):\n",
    "                if(is_nan(df[col][idx])): break\n",
    "                #print(idx)\n",
    "                sentence = df[col][idx]\n",
    "                labels, pos = get_labels(sentence)\n",
    "                for i in range(3): augment.append(entity_swap(sentence, pos, uniq))\n",
    "                idx += 1\n",
    "        # Create files\n",
    "        #augment = set(augment)\n",
    "        #if((250 - idx) < len(augment)): augment = random.sample(augment, 250 - idx)\n",
    "        print(\"Augmented Lines Generated: \" + str(len(augment)))\n",
    "        with open('data_augment/' + col + \".txt\", 'w+') as filehandle:  \n",
    "            filehandle.writelines(\"%s\\n\" % line for line in augment)\n",
    "\n",
    "#data_augment(intent_txt, uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/mindmeld/_version.py:64: MindMeldVersionWarning: Current mindmeld (4.1.1) does not satisfy mindmeld==4.1.0 in pip requirements caused by (mindmeld 4.1.1 (/anaconda3/envs/mindmeld2/lib/python3.6/site-packages), Requirement.parse('mindmeld==4.1.0'))\n",
      "  warnings.warn(error_msg, category=MindMeldVersionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting domain classifier\n",
      "Loading raw queries from file ./hr_assistant/domains/date/get_date/train.txt\n",
      "Loading raw queries from file ./hr_assistant/domains/date/get_date_range_aggregate/train.txt\n",
      "Loading raw queries from file ./hr_assistant/domains/date/get_date_range_employees/train.txt\n",
      "Loading raw queries from file ./hr_assistant/domains/general/get_aggregate/train.txt\n",
      "Loading raw queries from file ./hr_assistant/domains/general/get_employees/train.txt\n",
      "Loading raw queries from file ./hr_assistant/domains/general/get_info/train.txt\n",
      "Loading raw queries from file ./hr_assistant/domains/hierarchy/get_hierarchy/train.txt\n",
      "Loading raw queries from file ./hr_assistant/domains/salary/get_salary/train.txt\n",
      "Loading raw queries from file ./hr_assistant/domains/salary/get_salary_aggregate/train.txt\n",
      "Loading raw queries from file ./hr_assistant/domains/salary/get_salary_employees/train.txt\n",
      "Loading raw queries from file ./hr_assistant/domains/unsupported/unsupported/train.txt\n",
      "Loading queries from file ./hr_assistant/domains/date/get_date/train.txt\n",
      "Loading queries from file ./hr_assistant/domains/date/get_date_range_aggregate/train.txt\n",
      "Loading queries from file ./hr_assistant/domains/date/get_date_range_employees/train.txt\n",
      "Loading queries from file ./hr_assistant/domains/general/get_aggregate/train.txt\n",
      "Loading queries from file ./hr_assistant/domains/general/get_employees/train.txt\n",
      "Unknown entity 'race' found in query 'show me multi-racial employees'\n",
      "Loading queries from file ./hr_assistant/domains/general/get_info/train.txt\n",
      "Loading queries from file ./hr_assistant/domains/hierarchy/get_hierarchy/train.txt\n",
      "Loading queries from file ./hr_assistant/domains/salary/get_salary/train.txt\n",
      "Loading queries from file ./hr_assistant/domains/salary/get_salary_aggregate/train.txt\n",
      "Loading queries from file ./hr_assistant/domains/salary/get_salary_employees/train.txt\n",
      "Loading queries from file ./hr_assistant/domains/unsupported/unsupported/train.txt\n",
      "Fitting intent classifier: domain='date'\n",
      "Selecting hyperparameters using k-fold cross-validation with 5 splits\n",
      "Best accuracy: 98.63%, params: {'C': 100, 'class_weight': {0: 0.8130522088353414, 1: 1.9378205128205128, 2: 0.8793650793650793}, 'fit_intercept': True}\n",
      "Fitting entity recognizer: domain='date', intent='get_date'\n",
      "No entity model configuration set. Using default.\n",
      "Selecting hyperparameters using k-fold cross-validation with 5 splits\n",
      "Best accuracy: 95.90%, params: {'C': 100, 'penalty': 'l2'}\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "Fitting role classifier: domain='date', intent='get_date', entity_type='dob'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_dob'\n",
      "Elasticsearch index 'synonym_dob' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_dob'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 53.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document\n",
      "Fitting role classifier: domain='date', intent='get_date', entity_type='name'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_name'\n",
      "Elasticsearch index 'synonym_name' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_name'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 245/245 [00:00<00:00, 907.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 245 documents\n",
      "Fitting role classifier: domain='date', intent='get_date', entity_type='sys_time'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='date', intent='get_date', entity_type='employment_action'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_employment_action'\n",
      "Elasticsearch index 'synonym_employment_action' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employment_action'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 54.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='date', intent='get_date', entity_type='sys_duration'\n",
      "No role model configuration set. Using default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting entity recognizer: domain='date', intent='get_date_range_employees'\n",
      "No entity model configuration set. Using default.\n",
      "Selecting hyperparameters using k-fold cross-validation with 5 splits\n",
      "Best accuracy: 92.88%, params: {'C': 100, 'penalty': 'l1'}\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "Fitting role classifier: domain='date', intent='get_date_range_employees', entity_type='state'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_state'\n",
      "Elasticsearch index 'synonym_state' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_state'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 470.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28 documents\n",
      "Fitting role classifier: domain='date', intent='get_date_range_employees', entity_type='dob'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_dob'\n",
      "Elasticsearch index 'synonym_dob' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_dob'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document\n",
      "Fitting role classifier: domain='date', intent='get_date_range_employees', entity_type='sys_time'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='date', intent='get_date_range_employees', entity_type='sys_number'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='date', intent='get_date_range_employees', entity_type='racedesc'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_racedesc'\n",
      "Elasticsearch index 'synonym_racedesc' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_racedesc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 165.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 documents\n",
      "Fitting role classifier: domain='date', intent='get_date_range_employees', entity_type='employment_action'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_employment_action'\n",
      "Elasticsearch index 'synonym_employment_action' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employment_action'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 78.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='date', intent='get_date_range_employees', entity_type='citizendesc'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_citizendesc'\n",
      "Elasticsearch index 'synonym_citizendesc' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_citizendesc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 104.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "Fitting role classifier: domain='date', intent='get_date_range_employees', entity_type='sys_interval'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='date', intent='get_date_range_employees', entity_type='sex'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_sex'\n",
      "Elasticsearch index 'synonym_sex' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_sex'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 49.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='date', intent='get_date_range_employees', entity_type='sys_duration'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='date', intent='get_date_range_employees', entity_type='comparator'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_comparator'\n",
      "Elasticsearch index 'synonym_comparator' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_comparator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 129.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 documents\n",
      "Fitting role classifier: domain='date', intent='get_date_range_employees', entity_type='position'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_position'\n",
      "Elasticsearch index 'synonym_position' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_position'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 24/24 [00:00<00:00, 290.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 documents\n",
      "Fitting role classifier: domain='date', intent='get_date_range_employees', entity_type='extreme'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_extreme'\n",
      "Elasticsearch index 'synonym_extreme' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_extreme'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 50.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='date', intent='get_date_range_employees', entity_type='maritaldesc'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_maritaldesc'\n",
      "Elasticsearch index 'synonym_maritaldesc' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_maritaldesc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 52.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 documents\n",
      "Fitting role classifier: domain='date', intent='get_date_range_employees', entity_type='date_compare'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_date_compare'\n",
      "Elasticsearch index 'synonym_date_compare' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_date_compare'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 27.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='date', intent='get_date_range_employees', entity_type='time_interval'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_time_interval'\n",
      "Elasticsearch index 'synonym_time_interval' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_time_interval'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 255.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 documents\n",
      "Fitting role classifier: domain='date', intent='get_date_range_employees', entity_type='department'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_department'\n",
      "Elasticsearch index 'synonym_department' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_department'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 112.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 documents\n",
      "Fitting entity recognizer: domain='date', intent='get_date_range_aggregate'\n",
      "No entity model configuration set. Using default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting hyperparameters using k-fold cross-validation with 5 splits\n",
      "Best accuracy: 91.42%, params: {'C': 1000000, 'penalty': 'l2'}\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "Fitting role classifier: domain='date', intent='get_date_range_aggregate', entity_type='state'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_state'\n",
      "Elasticsearch index 'synonym_state' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_state'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 602.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28 documents\n",
      "Fitting role classifier: domain='date', intent='get_date_range_aggregate', entity_type='dob'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_dob'\n",
      "Elasticsearch index 'synonym_dob' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_dob'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document\n",
      "Fitting role classifier: domain='date', intent='get_date_range_aggregate', entity_type='sys_time'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='date', intent='get_date_range_aggregate', entity_type='sys_number'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='date', intent='get_date_range_aggregate', entity_type='employment_action'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_employment_action'\n",
      "Elasticsearch index 'synonym_employment_action' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employment_action'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 73.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='date', intent='get_date_range_aggregate', entity_type='sex'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_sex'\n",
      "Elasticsearch index 'synonym_sex' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_sex'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 58.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='date', intent='get_date_range_aggregate', entity_type='comparator'\n",
      "No role model configuration set. Using default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing synonym data to synonym index 'synonym_comparator'\n",
      "Elasticsearch index 'synonym_comparator' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_comparator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 189.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 documents\n",
      "Fitting role classifier: domain='date', intent='get_date_range_aggregate', entity_type='sys_duration'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='date', intent='get_date_range_aggregate', entity_type='function'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_function'\n",
      "Elasticsearch index 'synonym_function' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_function'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 122.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 documents\n",
      "Fitting role classifier: domain='date', intent='get_date_range_aggregate', entity_type='date_compare'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_date_compare'\n",
      "Elasticsearch index 'synonym_date_compare' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_date_compare'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 63.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='date', intent='get_date_range_aggregate', entity_type='time_interval'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_time_interval'\n",
      "Elasticsearch index 'synonym_time_interval' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_time_interval'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 202.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting intent classifier: domain='general'\n",
      "Selecting hyperparameters using k-fold cross-validation with 5 splits\n",
      "Best accuracy: 98.71%, params: {'C': 1, 'class_weight': {0: 1.105, 1: 0.906276150627615, 2: 1.0173267326732673}, 'fit_intercept': True}\n",
      "Fitting entity recognizer: domain='general', intent='get_info'\n",
      "No entity model configuration set. Using default.\n",
      "Selecting hyperparameters using k-fold cross-validation with 5 splits\n",
      "Best accuracy: 95.16%, params: {'C': 100, 'penalty': 'l2'}\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "Fitting role classifier: domain='general', intent='get_info', entity_type='reason_for_termination'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_reason_for_termination'\n",
      "Elasticsearch index 'synonym_reason_for_termination' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_reason_for_termination'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 461.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 17 documents\n",
      "Fitting role classifier: domain='general', intent='get_info', entity_type='state'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_state'\n",
      "Elasticsearch index 'synonym_state' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_state'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 28/28 [00:00<00:00, 719.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28 documents\n",
      "Fitting role classifier: domain='general', intent='get_info', entity_type='age'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_age'\n",
      "Elasticsearch index 'synonym_age' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_age'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 39/39 [00:00<00:00, 698.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 39 documents\n",
      "Fitting role classifier: domain='general', intent='get_info', entity_type='employee_source'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_employee_source'\n",
      "Elasticsearch index 'synonym_employee_source' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employee_source'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 489.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 documents\n",
      "Fitting role classifier: domain='general', intent='get_info', entity_type='name'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_name'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch index 'synonym_name' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_name'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:00<00:00, 1029.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 245 documents\n",
      "Fitting role classifier: domain='general', intent='get_info', entity_type='citizendesc'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_citizendesc'\n",
      "Elasticsearch index 'synonym_citizendesc' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_citizendesc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 79.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "Fitting role classifier: domain='general', intent='get_info', entity_type='racedesc'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_racedesc'\n",
      "Elasticsearch index 'synonym_racedesc' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_racedesc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 158.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 documents\n",
      "Fitting role classifier: domain='general', intent='get_info', entity_type='employment_action'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_employment_action'\n",
      "Elasticsearch index 'synonym_employment_action' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employment_action'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 51.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='general', intent='get_info', entity_type='performance_score'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_performance_score'\n",
      "Elasticsearch index 'synonym_performance_score' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_performance_score'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 144.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7 documents\n",
      "Fitting role classifier: domain='general', intent='get_info', entity_type='sex'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_sex'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch index 'synonym_sex' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_sex'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 72.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='general', intent='get_info', entity_type='position'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_position'\n",
      "Elasticsearch index 'synonym_position' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_position'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 24/24 [00:00<00:00, 432.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 documents\n",
      "Fitting role classifier: domain='general', intent='get_info', entity_type='maritaldesc'\n",
      "No role model configuration set. Using default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing synonym data to synonym index 'synonym_maritaldesc'\n",
      "Elasticsearch index 'synonym_maritaldesc' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_maritaldesc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 98.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 documents\n",
      "Fitting role classifier: domain='general', intent='get_info', entity_type='employment_status'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_employment_status'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch index 'synonym_employment_status' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employment_status'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 122.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 documents\n",
      "Fitting role classifier: domain='general', intent='get_info', entity_type='department'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_department'\n",
      "Elasticsearch index 'synonym_department' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_department'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 150.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 documents\n",
      "Fitting entity recognizer: domain='general', intent='get_aggregate'\n",
      "No entity model configuration set. Using default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting hyperparameters using k-fold cross-validation with 5 splits\n",
      "Best accuracy: 93.77%, params: {'C': 100, 'penalty': 'l1'}\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='employment_action'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_employment_action'\n",
      "Elasticsearch index 'synonym_employment_action' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employment_action'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 76.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='performance_score'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_performance_score'\n",
      "Elasticsearch index 'synonym_performance_score' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_performance_score'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 172.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7 documents\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='position'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_position'\n",
      "Elasticsearch index 'synonym_position' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_position'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 24/24 [00:00<00:00, 639.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 documents\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='manager'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_manager'\n",
      "Elasticsearch index 'synonym_manager' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_manager'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='citizendesc'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_citizendesc'\n",
      "Elasticsearch index 'synonym_citizendesc' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_citizendesc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 82.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='extreme'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_extreme'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch index 'synonym_extreme' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_extreme'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 80.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='function'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_function'\n",
      "Elasticsearch index 'synonym_function' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_function'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 96.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 documents\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='employee_source'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_employee_source'\n",
      "Elasticsearch index 'synonym_employee_source' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employee_source'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 430.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 documents\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='state'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_state'\n",
      "Elasticsearch index 'synonym_state' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_state'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 28/28 [00:00<00:00, 657.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28 documents\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='racedesc'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_racedesc'\n",
      "Elasticsearch index 'synonym_racedesc' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_racedesc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 149.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 documents\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='comparator'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_comparator'\n",
      "Elasticsearch index 'synonym_comparator' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_comparator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 117.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 documents\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='maritaldesc'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_maritaldesc'\n",
      "Elasticsearch index 'synonym_maritaldesc' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_maritaldesc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 141.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 documents\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='age'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_age'\n",
      "Elasticsearch index 'synonym_age' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_age'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 39/39 [00:00<00:00, 774.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 39 documents\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='reason_for_termination'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_reason_for_termination'\n",
      "Elasticsearch index 'synonym_reason_for_termination' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_reason_for_termination'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 392.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 17 documents\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='dob'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_dob'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch index 'synonym_dob' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_dob'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 57.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='name'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_name'\n",
      "Elasticsearch index 'synonym_name' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_name'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 245/245 [00:00<00:00, 961.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 245 documents\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='sys_time'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='sys_number'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='sex'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_sex'\n",
      "Elasticsearch index 'synonym_sex' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_sex'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 48.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='employment_status'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_employment_status'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch index 'synonym_employment_status' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employment_status'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 137.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 documents\n",
      "Fitting role classifier: domain='general', intent='get_aggregate', entity_type='department'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_department'\n",
      "Elasticsearch index 'synonym_department' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_department'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 132.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 documents\n",
      "Fitting entity recognizer: domain='general', intent='get_employees'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No entity model configuration set. Using default.\n",
      "Selecting hyperparameters using k-fold cross-validation with 5 splits\n",
      "Best accuracy: 93.27%, params: {'C': 100, 'penalty': 'l1'}\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='employment_action'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_employment_action'\n",
      "Elasticsearch index 'synonym_employment_action' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employment_action'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 71.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='performance_score'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_performance_score'\n",
      "Elasticsearch index 'synonym_performance_score' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_performance_score'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 182.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7 documents\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='position'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_position'\n",
      "Elasticsearch index 'synonym_position' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_position'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 24/24 [00:00<00:00, 505.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 documents\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='manager'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_manager'\n",
      "Elasticsearch index 'synonym_manager' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_manager'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='citizendesc'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_citizendesc'\n",
      "Elasticsearch index 'synonym_citizendesc' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_citizendesc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 150.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='race'\n",
      "No role model configuration set. Using default.\n",
      "Entity data file not found at './hr_assistant/entities/race/gazetteer.txt'. Proceeding with empty entity data.\n",
      "Entity mapping file not found at './hr_assistant/entities/race/mapping.json'. Proceeding with empty entity data.\n",
      "Entity map file not found at ./hr_assistant/entities/race/mapping.json\n",
      "Importing synonym data to synonym index 'synonym_race'\n",
      "Elasticsearch index 'synonym_race' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_race'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='sys_duration'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='extreme'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_extreme'\n",
      "Elasticsearch index 'synonym_extreme' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_extreme'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 80.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='function'\n",
      "No role model configuration set. Using default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing synonym data to synonym index 'synonym_function'\n",
      "Elasticsearch index 'synonym_function' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_function'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 115.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 documents\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='date_compare'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_date_compare'\n",
      "Elasticsearch index 'synonym_date_compare' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_date_compare'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 67.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='sys_ordinal'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='employee_source'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_employee_source'\n",
      "Elasticsearch index 'synonym_employee_source' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employee_source'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 435.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 documents\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='state'\n",
      "No role model configuration set. Using default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing synonym data to synonym index 'synonym_state'\n",
      "Elasticsearch index 'synonym_state' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_state'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 575.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28 documents\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='racedesc'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_racedesc'\n",
      "Elasticsearch index 'synonym_racedesc' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_racedesc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 154.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 documents\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='comparator'\n",
      "No role model configuration set. Using default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing synonym data to synonym index 'synonym_comparator'\n",
      "Elasticsearch index 'synonym_comparator' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_comparator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 134.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 documents\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='maritaldesc'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_maritaldesc'\n",
      "Elasticsearch index 'synonym_maritaldesc' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_maritaldesc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 165.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='age'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_age'\n",
      "Elasticsearch index 'synonym_age' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_age'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 813.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 39 documents\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='reason_for_termination'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_reason_for_termination'\n",
      "Elasticsearch index 'synonym_reason_for_termination' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_reason_for_termination'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 433.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 17 documents\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='dob'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_dob'\n",
      "Elasticsearch index 'synonym_dob' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_dob'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='sys_time'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='sys_number'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='sex'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_sex'\n",
      "Elasticsearch index 'synonym_sex' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_sex'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 99.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='employment_status'\n",
      "No role model configuration set. Using default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing synonym data to synonym index 'synonym_employment_status'\n",
      "Elasticsearch index 'synonym_employment_status' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employment_status'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 128.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 documents\n",
      "Fitting role classifier: domain='general', intent='get_employees', entity_type='department'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_department'\n",
      "Elasticsearch index 'synonym_department' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_department'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 148.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 documents\n",
      "Fitting intent classifier: domain='salary'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting hyperparameters using k-fold cross-validation with 5 splits\n",
      "Best accuracy: 96.25%, params: {'C': 10, 'class_weight': {0: 0.9269058295964125, 1: 1.0489655172413792, 2: 1.0666666666666667}, 'fit_intercept': True}\n",
      "Fitting entity recognizer: domain='salary', intent='get_salary_employees'\n",
      "No entity model configuration set. Using default.\n",
      "Selecting hyperparameters using k-fold cross-validation with 5 splits\n",
      "Best accuracy: 93.92%, params: {'C': 10000, 'penalty': 'l2'}\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='employee_source'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_employee_source'\n",
      "Elasticsearch index 'synonym_employee_source' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employee_source'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 489.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='name'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_name'\n",
      "Elasticsearch index 'synonym_name' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_name'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 245/245 [00:00<00:00, 1110.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 245 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='sys_time'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='citizendesc'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_citizendesc'\n",
      "Elasticsearch index 'synonym_citizendesc' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_citizendesc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 121.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='sys_number'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='employment_action'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_employment_action'\n",
      "Elasticsearch index 'synonym_employment_action' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employment_action'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 77.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='racedesc'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_racedesc'\n",
      "Elasticsearch index 'synonym_racedesc' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_racedesc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 208.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='employment_status'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_employment_status'\n",
      "Elasticsearch index 'synonym_employment_status' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employment_status'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 143.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='sys_amount-of-money'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='sex'\n",
      "No role model configuration set. Using default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing synonym data to synonym index 'synonym_sex'\n",
      "Elasticsearch index 'synonym_sex' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_sex'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 49.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='comparator'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_comparator'\n",
      "Elasticsearch index 'synonym_comparator' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_comparator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 119.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='sys_duration'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='time_recur'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_time_recur'\n",
      "Elasticsearch index 'synonym_time_recur' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_time_recur'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 131.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='position'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_position'\n",
      "Elasticsearch index 'synonym_position' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_position'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 24/24 [00:00<00:00, 406.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='extreme'\n",
      "No role model configuration set. Using default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing synonym data to synonym index 'synonym_extreme'\n",
      "Elasticsearch index 'synonym_extreme' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_extreme'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 68.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='function'\n",
      "No role model configuration set. Using default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing synonym data to synonym index 'synonym_function'\n",
      "Elasticsearch index 'synonym_function' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_function'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 86.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='date_compare'\n",
      "No role model configuration set. Using default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing synonym data to synonym index 'synonym_date_compare'\n",
      "Elasticsearch index 'synonym_date_compare' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_date_compare'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 63.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='manager'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_manager'\n",
      "Elasticsearch index 'synonym_manager' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_manager'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='money'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_money'\n",
      "Elasticsearch index 'synonym_money' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_money'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document\n",
      "Fitting role classifier: domain='salary', intent='get_salary_employees', entity_type='department'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_department'\n",
      "Elasticsearch index 'synonym_department' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_department'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 126.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 documents\n",
      "Fitting entity recognizer: domain='salary', intent='get_salary'\n",
      "No entity model configuration set. Using default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting hyperparameters using k-fold cross-validation with 5 splits\n",
      "Best accuracy: 98.30%, params: {'C': 10000, 'penalty': 'l1'}\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "Fitting role classifier: domain='salary', intent='get_salary', entity_type='name'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_name'\n",
      "Elasticsearch index 'synonym_name' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_name'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:00<00:00, 1081.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 245 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary', entity_type='sys_time'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='salary', intent='get_salary', entity_type='sys_number'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='salary', intent='get_salary', entity_type='employment_action'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_employment_action'\n",
      "Elasticsearch index 'synonym_employment_action' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employment_action'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 50.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary', entity_type='time_recur'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_time_recur'\n",
      "Elasticsearch index 'synonym_time_recur' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_time_recur'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 118.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary', entity_type='sys_amount-of-money'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='salary', intent='get_salary', entity_type='comparator'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_comparator'\n",
      "Elasticsearch index 'synonym_comparator' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_comparator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 102.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary', entity_type='sys_duration'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='salary', intent='get_salary', entity_type='extreme'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_extreme'\n",
      "Elasticsearch index 'synonym_extreme' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_extreme'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 100.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary', entity_type='money'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_money'\n",
      "Elasticsearch index 'synonym_money' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_money'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document\n",
      "Fitting entity recognizer: domain='salary', intent='get_salary_aggregate'\n",
      "No entity model configuration set. Using default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting hyperparameters using k-fold cross-validation with 5 splits\n",
      "Best accuracy: 93.22%, params: {'C': 10000, 'penalty': 'l2'}\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='employee_source'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_employee_source'\n",
      "Elasticsearch index 'synonym_employee_source' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employee_source'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 379.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='state'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_state'\n",
      "Elasticsearch index 'synonym_state' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_state'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 28/28 [00:00<00:00, 762.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='name'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_name'\n",
      "Elasticsearch index 'synonym_name' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_name'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 245/245 [00:00<00:00, 998.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 245 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='dob'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_dob'\n",
      "Elasticsearch index 'synonym_dob' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_dob'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 36.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='sys_time'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='sys_number'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='citizendesc'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_citizendesc'\n",
      "Elasticsearch index 'synonym_citizendesc' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_citizendesc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 88.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='employment_action'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_employment_action'\n",
      "Elasticsearch index 'synonym_employment_action' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_employment_action'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 63.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='time_recur'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_time_recur'\n",
      "Elasticsearch index 'synonym_time_recur' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_time_recur'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 104.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='sex'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_sex'\n",
      "Elasticsearch index 'synonym_sex' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_sex'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 65.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='comparator'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_comparator'\n",
      "Elasticsearch index 'synonym_comparator' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_comparator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 119.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='sys_duration'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='sys_amount-of-money'\n",
      "No role model configuration set. Using default.\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='position'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_position'\n",
      "Elasticsearch index 'synonym_position' for application 'hr_assistant' already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index 'synonym_position'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 541.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='extreme'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_extreme'\n",
      "Elasticsearch index 'synonym_extreme' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_extreme'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 82.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='function'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_function'\n",
      "Elasticsearch index 'synonym_function' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_function'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 101.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='date_compare'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_date_compare'\n",
      "Elasticsearch index 'synonym_date_compare' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_date_compare'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 59.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='manager'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_manager'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch index 'synonym_manager' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_manager'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 43.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='money'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_money'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch index 'synonym_money' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_money'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 60.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document\n",
      "Fitting role classifier: domain='salary', intent='get_salary_aggregate', entity_type='department'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_department'\n",
      "Elasticsearch index 'synonym_department' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_department'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 141.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 documents\n",
      "Fitting entity recognizer: domain='hierarchy', intent='get_hierarchy'\n",
      "No entity model configuration set. Using default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting hyperparameters using k-fold cross-validation with 5 splits\n",
      "Best accuracy: 96.67%, params: {'C': 1, 'penalty': 'l2'}\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "No entity_resolution model configuration set. Using default.\n",
      "Fitting role classifier: domain='hierarchy', intent='get_hierarchy', entity_type='manager'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_manager'\n",
      "Elasticsearch index 'synonym_manager' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_manager'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 53.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document\n",
      "Fitting role classifier: domain='hierarchy', intent='get_hierarchy', entity_type='name'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_name'\n",
      "Elasticsearch index 'synonym_name' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_name'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 245/245 [00:00<00:00, 1177.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 245 documents\n",
      "Fitting role classifier: domain='hierarchy', intent='get_hierarchy', entity_type='comparator'\n",
      "No role model configuration set. Using default.\n",
      "Importing synonym data to synonym index 'synonym_comparator'\n",
      "Elasticsearch index 'synonym_comparator' for application 'hr_assistant' already exists!\n",
      "Loading index 'synonym_comparator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 163.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 documents\n",
      "Fitting entity recognizer: domain='unsupported', intent='unsupported'\n",
      "No entity model configuration set. Using default.\n",
      "There are no labels in this label set, so we don't fit the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mindmeld import configure_logs; configure_logs()\n",
    "from mindmeld.components.nlp import NaturalLanguageProcessor\n",
    "nlp = NaturalLanguageProcessor(app_path='./hr_assistant')\n",
    "nlp.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The application package hr_assistant is already imported.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/mindmeld/_version.py:64: MindMeldVersionWarning: Current mindmeld (4.1.1) does not satisfy mindmeld==4.1.0 in pip requirements caused by (mindmeld 4.1.1 (/anaconda3/envs/mindmeld2/lib/python3.6/site-packages), Requirement.parse('mindmeld==4.1.0'))\n",
      "  warnings.warn(error_msg, category=MindMeldVersionWarning)\n"
     ]
    }
   ],
   "source": [
    "from mindmeld.components.dialogue import Conversation\n",
    "conv = Conversation(nlp=nlp, app_path='../hr_assistant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['get_info', 'get_aggregate', 'get_employees', 'get_salary',\n",
       "       'get_salary_aggregate', 'get_salary_employees', 'get_date',\n",
       "       'get_date_range_aggregate', 'get date_range_employees',\n",
       "       'get_hierarchy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = intent_txt\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The application package hr_assistant is already imported.\n",
      "GET_HIERARCHY=============================================================\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 809.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 923.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 852.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 667.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 650.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 974.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/logging/__init__.py\", line 994, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/logging/__init__.py\", line 840, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/logging/__init__.py\", line 577, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/logging/__init__.py\", line 338, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n",
      "    handle._run()\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n",
      "    self.run()\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-28-0aae05b6c9c1>\", line 17, in <module>\n",
      "    try: conv.say(q)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/mindmeld/components/dialogue.py\", line 769, in say\n",
      "    response = self.process(text, params=params)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/mindmeld/components/dialogue.py\", line 832, in process\n",
      "    frame=self.frame, history=self.history)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/mindmeld/app_manager.py\", line 173, in parse\n",
      "    dm_response = self.dialogue_manager.apply_handler(request, response, **dm_params)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/mindmeld/components/dialogue.py\", line 326, in apply_handler\n",
      "    dialogue_state = self._get_dialogue_state(request, target_dialogue_state)\n",
      "  File \"/anaconda3/envs/mindmeld2/lib/python3.6/site-packages/mindmeld/components/dialogue.py\", line 363, in _get_dialogue_state\n",
      "    self.logger.info(msg, request)\n",
      "Message: 'Failed to find dialogue state for hierarchy.get_hierarchy'\n",
      "Arguments: (Request(domain='hierarchy', intent='get_hierarchy', entities=({'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}},), history=({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia Brown', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 150.54138, 'top_synonym': 'mia brown'}, {'cname': 'Thelma Petrowsky', 'score': 11.059677, 'top_synonym': 'petrowsky'}, {'cname': 'Brooke Oliver', 'score': 11.015316, 'top_synonym': 'brooke'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 15}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 17, 'end': 23}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brannon Miller is John Kretschmer's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'John Kretschmer', 'manager': 'Brannon Miller'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'John', 'type': 'name', 'role': None, 'value': [{'cname': 'John Kretschmer', 'score': 66.90112, 'top_synonym': 'john'}, {'cname': 'Yen Johnston', 'score': 13.28422, 'top_synonym': 'johnston'}, {'cname': 'Noelle Johnson', 'score': 12.120192, 'top_synonym': 'johnson'}], 'span': {'start': 7, 'end': 10}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 19, 'end': 25}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Janet King is Michael Albert's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Michael Albert', 'manager': 'Janet King'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Michael', 'type': 'name', 'role': None, 'value': [{'cname': 'Michael Albert', 'score': 68.577934, 'top_synonym': 'michael'}, {'cname': 'Rachael Baczenski', 'score': 14.260977, 'top_synonym': 'rachael'}, {'cname': 'Michelle Carter', 'score': 11.62064, 'top_synonym': 'michelle'}, {'cname': 'Bartholemew Khemmich', 'score': 11.62064, 'top_synonym': 'khemmich'}, {'cname': 'Bianca Roehrich', 'score': 11.059677, 'top_synonym': 'roehrich'}, {'cname': 'Beatrice Chace', 'score': 11.059677, 'top_synonym': 'chace'}, {'cname': 'Richard Newman', 'score': 10.9205475, 'top_synonym': 'richard'}, {'cname': 'Donovan Chang', 'score': 10.082616, 'top_synonym': 'chang'}, {'cname': 'Jenna Dietrich', 'score': 10.082616, 'top_synonym': 'dietrich'}, {'cname': 'Lin Chan', 'score': 9.67027, 'top_synonym': 'chan'}], 'span': {'start': 7, 'end': 13}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 15, 'end': 21}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 20, 'end': 24}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 26, 'end': 32}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 21, 'end': 25}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 36, 'end': 42}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}},), 'text': 'Which employees have Julia as their manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}), 'text': 'What is the name of Julia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 21, 'end': 25}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 36, 'end': 42}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}},), 'text': 'Which employees have Julia as their manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}), 'text': 'Who is Michael manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 20, 'end': 24}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 26, 'end': 32}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 21, 'end': 25}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 36, 'end': 42}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}},), 'text': 'Which employees have Julia as their manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}), 'text': 'What is the name of Julia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 21, 'end': 25}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 36, 'end': 42}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}},), 'text': 'Which employees have Julia as their manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}), 'text': 'Who is John Reeder manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Janet King is Michael Albert's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Michael Albert', 'manager': 'Janet King'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Michael', 'type': 'name', 'role': None, 'value': [{'cname': 'Michael Albert', 'score': 68.577934, 'top_synonym': 'michael'}, {'cname': 'Rachael Baczenski', 'score': 14.260977, 'top_synonym': 'rachael'}, {'cname': 'Michelle Carter', 'score': 11.62064, 'top_synonym': 'michelle'}, {'cname': 'Bartholemew Khemmich', 'score': 11.62064, 'top_synonym': 'khemmich'}, {'cname': 'Bianca Roehrich', 'score': 11.059677, 'top_synonym': 'roehrich'}, {'cname': 'Beatrice Chace', 'score': 11.059677, 'top_synonym': 'chace'}, {'cname': 'Richard Newman', 'score': 10.9205475, 'top_synonym': 'richard'}, {'cname': 'Donovan Chang', 'score': 10.082616, 'top_synonym': 'chang'}, {'cname': 'Jenna Dietrich', 'score': 10.082616, 'top_synonym': 'dietrich'}, {'cname': 'Lin Chan', 'score': 9.67027, 'top_synonym': 'chan'}], 'span': {'start': 7, 'end': 13}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 15, 'end': 21}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 20, 'end': 24}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 26, 'end': 32}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 21, 'end': 25}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 36, 'end': 42}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}},), 'text': 'Which employees have Julia as their manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}), 'text': 'What is the name of Julia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 21, 'end': 25}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 36, 'end': 42}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}},), 'text': 'Which employees have Julia as their manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}), 'text': 'Who is Michael manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 20, 'end': 24}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 26, 'end': 32}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 21, 'end': 25}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 36, 'end': 42}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}},), 'text': 'Which employees have Julia as their manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}), 'text': 'What is the name of Julia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 21, 'end': 25}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 36, 'end': 42}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}},), 'text': 'Which employees have Julia as their manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}), 'text': 'Who is Mia Brown manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brannon Miller is John Kretschmer's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'John Kretschmer', 'manager': 'Brannon Miller'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'John', 'type': 'name', 'role': None, 'value': [{'cname': 'John Kretschmer', 'score': 66.90112, 'top_synonym': 'john'}, {'cname': 'Yen Johnston', 'score': 13.28422, 'top_synonym': 'johnston'}, {'cname': 'Noelle Johnson', 'score': 12.120192, 'top_synonym': 'johnson'}], 'span': {'start': 7, 'end': 10}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 19, 'end': 25}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Janet King is Michael Albert's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Michael Albert', 'manager': 'Janet King'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Michael', 'type': 'name', 'role': None, 'value': [{'cname': 'Michael Albert', 'score': 68.577934, 'top_synonym': 'michael'}, {'cname': 'Rachael Baczenski', 'score': 14.260977, 'top_synonym': 'rachael'}, {'cname': 'Michelle Carter', 'score': 11.62064, 'top_synonym': 'michelle'}, {'cname': 'Bartholemew Khemmich', 'score': 11.62064, 'top_synonym': 'khemmich'}, {'cname': 'Bianca Roehrich', 'score': 11.059677, 'top_synonym': 'roehrich'}, {'cname': 'Beatrice Chace', 'score': 11.059677, 'top_synonym': 'chace'}, {'cname': 'Richard Newman', 'score': 10.9205475, 'top_synonym': 'richard'}, {'cname': 'Donovan Chang', 'score': 10.082616, 'top_synonym': 'chang'}, {'cname': 'Jenna Dietrich', 'score': 10.082616, 'top_synonym': 'dietrich'}, {'cname': 'Lin Chan', 'score': 9.67027, 'top_synonym': 'chan'}], 'span': {'start': 7, 'end': 13}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 15, 'end': 21}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 20, 'end': 24}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 26, 'end': 32}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 21, 'end': 25}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 36, 'end': 42}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}},), 'text': 'Which employees have Julia as their manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}), 'text': 'What is the name of Julia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 21, 'end': 25}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 36, 'end': 42}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}},), 'text': 'Which employees have Julia as their manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}), 'text': 'Who is Michael manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 20, 'end': 24}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 26, 'end': 32}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 21, 'end': 25}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 36, 'end': 42}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}},), 'text': 'Which employees have Julia as their manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}), 'text': 'What is the name of Julia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 21, 'end': 25}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 36, 'end': 42}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}},), 'text': 'Which employees have Julia as their manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}), 'text': 'Who is John Reeder manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Janet King is Michael Albert's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Michael Albert', 'manager': 'Janet King'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Michael', 'type': 'name', 'role': None, 'value': [{'cname': 'Michael Albert', 'score': 68.577934, 'top_synonym': 'michael'}, {'cname': 'Rachael Baczenski', 'score': 14.260977, 'top_synonym': 'rachael'}, {'cname': 'Michelle Carter', 'score': 11.62064, 'top_synonym': 'michelle'}, {'cname': 'Bartholemew Khemmich', 'score': 11.62064, 'top_synonym': 'khemmich'}, {'cname': 'Bianca Roehrich', 'score': 11.059677, 'top_synonym': 'roehrich'}, {'cname': 'Beatrice Chace', 'score': 11.059677, 'top_synonym': 'chace'}, {'cname': 'Richard Newman', 'score': 10.9205475, 'top_synonym': 'richard'}, {'cname': 'Donovan Chang', 'score': 10.082616, 'top_synonym': 'chang'}, {'cname': 'Jenna Dietrich', 'score': 10.082616, 'top_synonym': 'dietrich'}, {'cname': 'Lin Chan', 'score': 9.67027, 'top_synonym': 'chan'}], 'span': {'start': 7, 'end': 13}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 15, 'end': 21}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 20, 'end': 24}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 26, 'end': 32}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 21, 'end': 25}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 36, 'end': 42}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}},), 'text': 'Which employees have Julia as their manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}), 'text': 'What is the name of Julia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 21, 'end': 25}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 36, 'end': 42}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}},), 'text': 'Which employees have Julia as their manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}), 'text': 'Who is Michael manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 20, 'end': 24}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 26, 'end': 32}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 21, 'end': 25}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 36, 'end': 42}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}},), 'text': 'Which employees have Julia as their manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}), 'text': 'What is the name of Julia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Eric Dougall is Julia Soto's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Julia Soto', 'manager': 'Eric Dougall'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Julia', 'type': 'name', 'role': None, 'value': [{'cname': 'Julia Soto', 'score': 64.2731, 'top_synonym': 'julia'}, {'cname': 'Mike Guilianno', 'score': 11.757732, 'top_synonym': 'guilianno'}, {'cname': 'Debra Houlihan', 'score': 11.757732, 'top_synonym': 'houlihan'}, {'cname': 'Jacquelyn Williams', 'score': 11.059677, 'top_synonym': 'williams'}, {'cname': 'Libby Fidelia', 'score': 10.742377, 'top_synonym': 'fidelia'}, {'cname': 'Julissa Hunts', 'score': 10.353767, 'top_synonym': 'julissa'}, {'cname': 'William LaRotonda', 'score': 8.616255, 'top_synonym': 'william'}, {'cname': 'Lisa Galia', 'score': 8.616255, 'top_synonym': 'galia'}], 'span': {'start': 21, 'end': 25}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 36, 'end': 42}}), 'history': ({'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}},), 'text': 'Which employees have Julia as their manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}, {'directives': [{'name': 'reply', 'type': 'view', 'payload': {'text': \"Brandon R. LeBlanc is Mia Brown's manager\"}}], 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'dialogue_state': 'heirarchy', 'slots': {'name': 'Mia Brown', 'manager': 'Brandon R. LeBlanc'}, 'request': {'domain': 'hierarchy', 'intent': 'get_hierarchy', 'entities': ({'text': 'Mia', 'type': 'name', 'role': None, 'value': [{'cname': 'Mia Brown', 'score': 62.84209, 'top_synonym': 'mia'}, {'cname': 'Jeremiah Semizoglou', 'score': 9.67027, 'top_synonym': 'jeremiah'}], 'span': {'start': 7, 'end': 9}}, {'text': 'manager', 'type': 'manager', 'role': None, 'value': [{'cname': 'manager', 'score': 34.709923, 'top_synonym': 'manager'}], 'span': {'start': 11, 'end': 17}}), 'history': (), 'text': 'Who is Mia manager', 'frame': {}, 'params': {'allowed_intents': (), 'target_dialogue_state': None, 'time_zone': None, 'timestamp': 0, 'dynamic_resource': {}}, 'context': {}, 'confidences': {}, 'nbest_transcripts_text': (), 'nbest_transcripts_entities': (), 'nbest_aligned_entities': ()}}), text='Who is the manager for Bob', frame=<immutables.Map({}) at 0x14252e3a8>, params=FrozenParams(allowed_intents=(), target_dialogue_state=None, time_zone=None, timestamp=0, dynamic_resource=<immutables.Map({}) at 0x1422f6708>), context=<immutables.Map({}) at 0x14252e5a0>, confidences=<immutables.Map({}) at 0x14252e630>, nbest_transcripts_text=(), nbest_transcripts_entities=(), nbest_aligned_entities=()),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 587.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 912.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 917.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 954.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 845.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 662.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 949.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 795.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 817.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 885.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 656.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 820.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 700.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 876.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 826.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 857.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 793.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 895.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 923.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n",
      "Elasticsearch index 'user_data' for application 'hr_assistant' already exists!\n",
      "Loading index 'user_data'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 301/301 [00:00<00:00, 850.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 301 documents\n"
     ]
    }
   ],
   "source": [
    "orig_conv = Conversation(nlp=nlp, app_path='../hr_assistant')\n",
    "\n",
    "issues = []\n",
    "#for col in df:\n",
    "col = 'get_hierarchy'\n",
    "#if col not in ['get_info', 'get_aggregate', 'get_employees']:\n",
    "print(col.upper() + \"=============================================================\")\n",
    "idx = 2\n",
    "nan = is_nan(df[col][idx])\n",
    "while(idx < len(df)):\n",
    "        if(is_nan(df[col][idx])): break\n",
    "        #print(idx)\n",
    "        sentence = df[col][idx]\n",
    "        labels, pos = get_labels(sentence)\n",
    "        q = entity_label_remove(sentence, pos, uniq)\n",
    "        conv = orig_conv\n",
    "        try: conv.say(q)\n",
    "        except: \n",
    "            print(q)\n",
    "            issues.append(q)\n",
    "\n",
    "        idx += 1\n",
    "print(issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(issues))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
